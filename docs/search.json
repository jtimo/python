[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Python for Engineers and Scientists (v1.5)",
    "section": "",
    "text": "Preface\nPython is an indispensable tool for engineers and scientists due to its simplicity, versatility, and powerful libraries. This book, Python for Engineers and Scientists, aims to provide a decent introduction to Python. The contents of this book is designed to guide you through the essentials of Python. We will cover fundamental concepts, from basic syntax to advanced topics, ensuring a good foundation for further application.",
    "crumbs": [
      "Home",
      "Preface"
    ]
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "Python for Engineers and Scientists (v1.5)",
    "section": "Installation",
    "text": "Installation\nIf you are completely new to Python, then the following instructions will help you install Python in your Desktop or PC. The beginner - friendly method for learning to program with Python is using the Jupyter Notebook to write Python code. The Jupyter Notebook is a web-browser application in which Python code and normal text can be written. The file format of a Jupyter Notebook is .ipynb. Several online programming environments are also based on this format. If you have a google account, then you have free access to the google colab framework. Using google colab you can start writing programs using python directly in the browser. The following steps will help you obtain the latest version of the Jupyter Notebook on your system and you can start programming in a few minutes !\n\n\n\n\n\nflowchart LR\n    A[Download] --&gt; B[Install]\n    B --&gt; C[Open Anaconda Navigator]\n    C --&gt; D[Launch Jupyter Notebook]\n\n\n\n\n\n\n\nDownload Anacoda from the following link: https://www.anaconda.com/products/distribution#Downloads. This is a set of tools that includes Python, a set of IDEs (Interactive Development Environments) and third-party packages (to help you perform specialized computations like image processing, numerical analysis, machine learning etc.)\nAfter installation, open the Anaconda Navigator ! And launch the Jupyter Notebook application from the main page. A web browser will be initiated.\nIf you already use Spyder or PyCharm or any other IDE (Interactive Development Environment) you can skip the next subsection !\n\nUsing the following instructions, you can create your first Jupyter Notebook !\n\n\n\n\n\nflowchart LR\n    A[New] --&gt; B[Chose ipykernel]\n    B --&gt; C[Install Anaconda]\n    C --&gt; D[Write code]\n\n\n\n\n\n\n\nIn the Jupyter Notebook, the main page will display the root folder system. You can navigate to the folder of your choice where you want to store your Jupyter Notebooks or you can create a new folder at the location of your choice.\nAfter navigating to the folder of your choice, now you can at the top right-hand side you will find a new button. Click on that button and choose ipykernel. This will create a new Jupyter Notebook.\n\nJupyter notebook consists of cells. In these cells you can type in python code and normal text using Markdown. You can choose the type of cell from the dropdown menu in the menu bar. Click Help to get help on the user interface. Now write the following python code print('my first python code in Jupyter') as follows:\n\nprint('my first python code in Jupyter')\n\nmy first python code in Jupyter\n\n\nIf you see the above output then you have sucessfully written your first code in Jupyter using the Python language.\n\nAlternatives to Jupyter and Anaconda\nIn addition to Anaconda and Jupyter, there are several other options for installing and using Python. Here are some alternatives:\n\nOfficial Python Distribution:\n\nDownload the latest version of Python from the official Python website. This method allows you to install Python directly on your system without any additional packages.\n\nIntegrated Development Environments (IDEs):\n\nPyCharm: A powerful IDE developed by JetBrains, PyCharm offers professional and community editions. It provides features like code completion, debugging, and an integrated terminal.\nVisual Studio Code: A lightweight but powerful source code editor by Microsoft, which supports Python through extensions. It offers features such as IntelliSense, debugging, and Git integration.\nSpyder: An open-source IDE specifically designed for data science and engineering. It integrates well with scientific libraries like NumPy, SciPy, and Matplotlib.\n\nPython Distributions for Scientific Computing:\n\nMiniconda: A smaller, lightweight alternative to Anaconda, Miniconda allows you to install only the packages you need. It is suitable for creating a customized Python environment.\nWinPython: A portable distribution of Python for Windows, designed for scientific and educational usage. It includes a wide range of useful libraries and tools.\n\nOnline Python Environments:\n\nGoogle Colab: A free, cloud-based Jupyter notebook environment provided by Google. It is especially useful for collaborative projects and running code without any local setup.\nBinder: An open-source service that allows you to create sharable, interactive, and reproducible Python environments from GitHub repositories.\nKaggle Kernels: Online notebooks provided by Kaggle, which come pre-configured with many popular data science libraries and free GPU support.\n\n\nThese alternatives offer various advantages depending on your specific needs and preferences. Whether you prefer a lightweight setup or a comprehensive IDE, you can choose the option that best fits your workflow.",
    "crumbs": [
      "Home",
      "Preface"
    ]
  },
  {
    "objectID": "index.html#further-reading",
    "href": "index.html#further-reading",
    "title": "Python for Engineers and Scientists (v1.5)",
    "section": "Further Reading",
    "text": "Further Reading\n\nPython: https://www.python.org\nAnaconda Tutorials: https://docs.anaconda.com/free/navigator/tutorials/index.html\nJupyter: https://docs.jupyter.org/en/latest/",
    "crumbs": [
      "Home",
      "Preface"
    ]
  },
  {
    "objectID": "07_visualization_using_matplotlib.html",
    "href": "07_visualization_using_matplotlib.html",
    "title": "7  Visualization",
    "section": "",
    "text": "7.1 Libraries for Visualization using Python\nSome of the visualization tools available in Python include:",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "07_visualization_using_matplotlib.html#libraries-for-visualization-using-python",
    "href": "07_visualization_using_matplotlib.html#libraries-for-visualization-using-python",
    "title": "7  Visualization",
    "section": "",
    "text": "Matplotlib: The foundational library for creating static plots in Python. It provides extensive control over plot appearance and is highly customizable.\nSeaborn: Built on top of Matplotlib, Seaborn simplifies the creation of attractive and informative statistical graphics. It integrates well with pandas data structures and enhances Matplotlib’s capabilities.\nPlotly: Known for creating interactive plots, Plotly is used for producing high-quality graphs that can be embedded in web applications. Will not be discussed in the course and can be studied from resources.\nBokeh: Another library for creating interactive plots, Bokeh is particularly useful for large datasets and creating dashboards.\n\n\n7.1.1 Matplotlib\nMatplotlib is a popular Python library used for creating high-quality, publication-ready visualizations such as graphs, charts, and plots. It was developed in the early 2000s by John D. Hunter.\nAs usual, we start by importing the necessary libraries. Then using the plot function, we can plot the data.\n\n%matplotlib inline \nimport matplotlib.pyplot as plt   \nimport numpy as np\n\nThe most common type of data that is visualized are functions. A function \\(f(x) = \\sin (x)\\) takes in \\(x\\) and outputs \\(f\\). To plot functions, we provide a range of input values that the function takes and outputs a range of values. A simple matlabesque plot can be generated using the following command.\n\nx = np.linspace(0, 2*np.pi, 2000)\nplt.figure(figsize=(4, 4))\nplt.plot(x, np.sin(x))\n\n\n\n\n\n\n\n\nWhile this might be a quick way to generate figures, the object-oriented framework of matplotlib is more powerful and flexible.\n\n\n7.1.2 Bokeh\nBokeh is another popular library for creating interactive visualizations in Python. It is designed for creating web-based plots and dashboards that can be viewed in a web browser. Bokeh provides a high-level interface for creating interactive plots with a wide range of features and customization options. It is basically powered by JavaScript.\n\nimport numpy as np\nimport pandas as pd\n\nfrom bokeh.palettes import tol\nfrom bokeh.plotting import figure, show\nfrom bokeh.io import output_notebook\n\nN = 10\ndf = pd.DataFrame(np.random.randint(10, 100, size=(15, N))).add_prefix('y')\n\noutput_notebook()\np = figure(x_range=(0, len(df)-1), y_range=(0, 800))\np.grid.minor_grid_line_color = '#eeeeee'\n\nnames = [f\"y{i}\" for i in range(N)]\np.varea_stack(stackers=names, x='index', color=tol['Sunset'][N], legend_label=names, source=df)\n\np.legend.orientation = \"horizontal\"\np.legend.background_fill_color = \"#fafafa\"\n\nshow(p)\n\n    \n    \n        \n        Loading BokehJS ...",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "07_visualization_using_matplotlib.html#the-object-oriented-framework-of-matplotlib",
    "href": "07_visualization_using_matplotlib.html#the-object-oriented-framework-of-matplotlib",
    "title": "7  Visualization",
    "section": "7.2 The Object-Oriented Framework of Matplotlib",
    "text": "7.2 The Object-Oriented Framework of Matplotlib\nSince its release, Matplotlib has become the de facto standard for data visualization in Python, and it is widely used in various scientific and engineering fields, as well as in industry and academia. One of the key features of Matplotlib is its flexibility, which allows users to create a wide range of visualizations with a high degree of customization.\nMatplotlib is built on top of the NumPy and SciPy libraries, which provide the numerical and scientific computing capabilities necessary for data analysis and visualization. It also integrates well with other popular data analysis libraries in the Python ecosystem, such as pandas and seaborn.\nOver the years, Matplotlib has undergone significant improvements and enhancements, with the latest release offering new features such as 3D plotting, interactive plotting, and improved performance. With its ease of use, extensive documentation, and broad community support, Matplotlib remains a powerful tool for data visualization in Python.\nMatplotlib is a powerful plotting library in Python that allows for the creation of static, animated, and interactive visualizations. While Matplotlib provides a scripting interface (often via pyplot), understanding its object-oriented (OO) approach offers greater control and customization over plots. This introduction will help you understand the fundamentals of the OO framework in Matplotlib with examples.\nThe Basics of the Object-Oriented Approach\nIn the OO approach, plots are treated as objects. The primary objects in Matplotlib are Figure and Axes. Here’s a brief overview:\n\nFigure: This is the entire window or page on which everything is drawn. It can contain multiple Axes.\nAxes: These are the actual plots within the Figure. A Figure can contain multiple Axes objects.\n\n\n7.2.1 A Basic Plot\nLet’s start with a simple example to illustrate the OO framework:\n\nimport matplotlib.pyplot as plt\n\n# Create a Figure object\nfig = plt.figure(figsize=(7, 7))\n\n# Add an Axes object to the Figure\nax = fig.add_axes([0.1, 0.1, 0.8, 0.8])  # [left, bottom, width, height]\n\n# Plotting data\nax.plot([1, 2, 3, 4], [10, 20, 25, 30])\n\n# Setting labels and title\nax.set_xlabel('X-axis')\nax.set_ylabel('Y-axis')\nax.set_title('Simple Plot')\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\n\n\nthe code fig = plt.figure() creates a Figure object. ax = fig.add_axes([0.1, 0.1, 0.8, 0.8]) adds an Axes object to the Figure. The list specifies the dimensions of the Axes (left, bottom, width, height) in relative units. ax.plot() is used to plot data. ax.set_xlabel(), ax.set_ylabel(), and ax.set_title() set the labels and title for the Axes.\n\n\n7.2.2 Adding Multiple Axes\nYou can add multiple Axes to a single Figure to create more detailed visualizations.\n\nimport matplotlib.pyplot as plt\n\n# Create a Figure object\nfig = plt.figure(figsize=(7, 7))\n\n# Add first Axes\nax1 = fig.add_axes([0.1, 0.1, 0.8, 0.8])\nax1.plot([1, 2, 3, 4], [10, 20, 25, 30])\nax1.set_title('Main Plot')\n\nax1.set_xlabel('X-axis')\nax1.set_ylabel('Y-axis')\n\n# Add second Axes\nax2 = fig.add_axes([0.2, 0.6, 0.25, 0.25])\nax2.plot([1, 2, 3, 4], [10, 20, 25, 30])\nax2.set_title('Inset Plot')\nax2.set_xlabel('X-axis')\nax2.set_ylabel('Y-axis')\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\n\n\nIn this example, ax2 is an inset plot within the main plot ax1.\n\n\n7.2.3 Using subplots for Multiple Plots\nA more convenient way to create multiple plots is by using the subplots method. Here instead of adding Axes manually, you can create a grid of Axes within a single Figure.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Sample data for each plot\ndata = [\n    ([1, 2, 3, 4], [10, 20, 25, 30], 'Plot 1'),\n    ([1, 2, 3, 4], [30, 25, 20, 10], 'Plot 2'),\n    ([1, 2, 3, 4], [10, 20, 10, 20], 'Plot 3'),\n    ([1, 2, 3, 4], [30, 20, 10, 30], 'Plot 4')\n]\n\n# Create a Figure with a 2x2 grid of Axes\nfig, axes = plt.subplots(2, 2, figsize=(7, 7))\n\n# Flatten the axes array for easy iteration\naxes_flat = axes.flatten()\n\n# Plot data on each Axes using a loop\nfor ax, (x, y, title) in zip(axes_flat, data):\n    ax.plot(x, y)\n    ax.set_title(title)\n    ax.set_xlabel('X-axis')\n    ax.set_ylabel('Y-axis')\n\n# Adjust layout to prevent overlap\nplt.tight_layout()\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\n\n\nHere, fig, axes = plt.subplots(2, 2) creates a Figure and a 2x2 grid of Axes. You can access each Axes using axes[row, col].\n\n\n7.2.4 Customizing Plots\nThe OO approach provides extensive methods to customize plots:\n\nimport matplotlib.pyplot as plt\n\n# Create a Figure and Axes\nfig, ax = plt.subplots(figsize=(7, 7))\n\n# Plot data\nax.plot([1, 2, 3, 4], [10, 20, 25, 30], label='Data $a$', linestyle='-.')\nax.plot([1, 2, 3, 4], [10, 10, 20, 25], label='Data $b$', linestyle='--')\nax.plot([1, 2, 3, 4], [20, 10, 30, 20], label='Data $c$', linestyle=':')\n\n# Customize plot\nax.set_xlabel('X-axis')\nax.set_ylabel('Y-axis')\nax.set_title('Plot Title')\nax.legend()\nax.grid(True)\n\n# Customize ticks\nax.set_xticks([1, 2, 3, 4])\nax.set_yticks([10, 20, 30])\n\n# Customize tick labels\nax.set_xticklabels(['One', 'Two', 'Three', 'Four'])\nax.set_yticklabels(['Ten', 'Twenty', 'Thirty'])\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\n\n\nIn this example, we customize labels, add a legend, enable grid lines, and set specific tick locations and labels.\nBy treating plots as objects, you gain more control over their appearance and behavior. Understanding this framework is essential for creating advanced visualizations that are both informative and visually appealing.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(0, 4*np.pi, 100)\n\n# Create a Figure and Axes\nfig, ax = plt.subplots(figsize=(7, 7))\n\n# Plot data\n\n# specify color by name\nax.plot(x, np.sin(x), color='blue',linestyle='-.') \n\n# short color code (rgbcmyk)\nax.plot(x, x*np.sin(x - 1), color='g',   linestyle='--') \n\n# Grayscale between 0 and 1\nax.plot(x, x*np.sin(x - 2), color='0.75',linestyle=':') \n\n# Hex code (RRGGBB from 00 to FF)\nax.plot(x, x*np.sin(x - 3), color='#FFDD44',linestyle='-')\n\n# RGB tuple, values 0 to 1\nax.plot(x, x*np.sin(x - 4), color=(1.0, 0.2, 0.3))\n\n# all HTML color names supported\nax.plot(x, x*np.sin(x - 5), color='chartreuse')\n\n# Customize plot\nax.set_xlabel('X-axis')\nax.set_ylabel('Y-axis')\nax.set_title('$\\sin$ curves')\nax.legend(['$sin(x)$', '$x sin(x-1)$', '$xsin(x-2)$', '$xsin(x-3)$', '$xsin(x-4)$', '$xsin(x-5)$'])\nax.grid(True)\n\n# Customize ticks\nax.set_xticks([0, np.pi, 2*np.pi, 3*np.pi, 4*np.pi])\n\n# Customize tick labels\nax.set_xticklabels(['0', '$\\pi$', '$2\\pi$', '$3\\pi$', '$4\\pi$'])\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\n\n\nList of all markers can be found here: https://matplotlib.org/stable/api/markers_api.html\n\n\n7.2.5 Scatter Plots\nA common scientific example of a dataset that can be plotted using a scatter plot in Python is a dataset of experimental measurements with two variables. For instance, consider an experiment where the aim is to investigate the relationship between two physical quantities, such as temperature and pressure.\nIn such an experiment, data is typically collected by measuring both temperature and pressure under various experimental conditions. Each data point in the dataset corresponds to a pair of temperature and pressure measurements obtained at a specific experimental condition.\nTo visualize this dataset, a scatter plot can be used to plot each data point as a point in a two-dimensional coordinate system, where one axis corresponds to temperature and the other axis corresponds to pressure. Each point in the scatter plot represents a specific experimental condition, and the location of the point corresponds to the temperature and pressure measurements obtained at that condition.\nThe scatter plot can then be used to visualize the relationship between the two variables. For instance, it may reveal whether there is a linear relationship between temperature and pressure, or whether the relationship is more complex. By visualizing the data in this way, it is easier to gain insights and draw conclusions about the experiment.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Generate some sample data\ntemperature = np.array([25, 30, 35, 40, 45])\npressure = np.array([100, 120, 130, 150, 170])\n\n# Create a Figure and Axes\nfig, ax = plt.subplots(figsize=(7, 7))\n\n# Create a scatter plot\nax.plot(temperature, pressure, 'o')  # 'o' indicates circular markers\n\n# Add labels and title\nax.set_xlabel('Temperature (Celsius)')\nax.set_ylabel('Pressure (kPa)')\nax.set_title('Temperature vs. Pressure')\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\nOften we also deal with uncorrelated data !\n\nrng = np.random.RandomState(seed=0) # A random number generator initialized with a certain state\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Generate some sample data\nnp.random.seed(0)  # For reproducibility\nx = np.random.rand(50) * 100  # Random data for x\ny = np.random.rand(50) * 100  # Random data for y (not correlated with x)\nz = np.random.rand(50) * 1000  # Data for scaling marker sizes\n\n# Create a Figure and Axes\nfig, ax = plt.subplots(figsize=(7, 6))\n\n# Create a scatter plot\nscatter = ax.scatter(x, y, s=z, c=z, alpha=0.5, cmap='Spectral')  \n# s=z scales the marker sizes, c=z maps the color to the data, alpha sets transparency\n\n# Add labels and title\nax.set_xlabel('X-axis (Random Data)')\nax.set_ylabel('Y-axis (Random Data)')\nax.set_title(' A colorful scatter plot')\n\n# Add color bar\ncbar = plt.colorbar(scatter, ax=ax)\ncbar.set_label('Values of Z')\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\nNotice that the color argument is automatically mapped to a color scale (shown here by the colorbar() command), and that the size argument is given in pixels. In this way, the color and size of points can be used to convey information in the visualization, in order to visualize multidimensional data.\nList of colormaps can be found here: https://matplotlib.org/stable/tutorials/colors/colormaps.html\n\n\n7.2.6 Multiple Subplots and Saving Plots\nMultiple plots can be generated by using the axes description ! Saving is automatically inferred !\n\nx_m = np.linspace(0, 10, 100) \ny_m = x_m * np.sin(x_m)\n\nax1 = plt.axes()  # standard axes\nax2 = plt.axes([0.5, 0.5, 0.2, 0.2])\n\nax1.plot(x_m, y_m, '.g')\nax2.plot(x_m, y_m, '-b')\n\nax1.set_xlabel('Time')\nax2.set_xlabel('Pressure')\n\nax1.set_ylabel('Amplitude')\nax2.set_ylabel('Temperature')\n\nplt.savefig('my_fig_1.png', dpi=120) # PNG Format of the figure is saved\nplt.show()\n\n\n\n\n\n\n\n\nUsing a sequential loop, multiple plots can be aligned and plotted together !\n\nfig = plt.figure(figsize=(7, 7))\n\nfig.subplots_adjust(hspace=0.4, wspace=0.4)\n\ncolor = iter(plt.cm.rainbow(np.linspace(0, 1, 4))) # To customize the colors\n\nxlabels = ['$a^{2} p$', 'a^{2} p', 'a^{2} p', 'a^{2} p']\nylabels = ['$y(x)$', '$y(x)$', '$y(x)$', '$y(x)$']\n\nfor i in range(1, 5):\n    \n    ax = fig.add_subplot(2, 2, i)\n    c = next(color)\n    \n    ax.plot(x_m, y_m, c=c)\n    \n    ax.text(0, 5, '$a(t)=t \\sin(t)$', fontsize=12);\n    ax.set_xlabel(xlabels[i-1])\n    ax.set_ylabel(ylabels[i-1])\n\nplt.savefig('my_fig.pdf', dpi=120) # PDF format of the figure is saved\n\n\n\n\n\n\n\n\n\n\n7.2.7 Visualizing a 3D function\nLet us first define a function that takes in two co-ordinates and gives the height data !\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\\[ z = sin(x)^{10} + cos(y)cos(x)  \\]\n\ndef f(x, y):\n    return np.sin(x) ** 10 + np.cos(y) * np.cos(x)\n\n\nx = np.linspace(0, 5, 100)\ny = np.linspace(0, 5, 100)\n\nX, Y = np.meshgrid(x, y)\n\n\nX\n\narray([[0.        , 0.05050505, 0.1010101 , ..., 4.8989899 , 4.94949495,\n        5.        ],\n       [0.        , 0.05050505, 0.1010101 , ..., 4.8989899 , 4.94949495,\n        5.        ],\n       [0.        , 0.05050505, 0.1010101 , ..., 4.8989899 , 4.94949495,\n        5.        ],\n       ...,\n       [0.        , 0.05050505, 0.1010101 , ..., 4.8989899 , 4.94949495,\n        5.        ],\n       [0.        , 0.05050505, 0.1010101 , ..., 4.8989899 , 4.94949495,\n        5.        ],\n       [0.        , 0.05050505, 0.1010101 , ..., 4.8989899 , 4.94949495,\n        5.        ]])\n\n\n\nZ = f(X, Y)\nZ\n\narray([[1.        , 0.99872489, 0.99490282, ..., 1.02487674, 0.98783019,\n        0.94108251],\n       [0.99872489, 0.99745141, 0.99363421, ..., 1.02464018, 0.98753068,\n        0.94072081],\n       [0.99490282, 0.99363421, 0.98983161, ..., 1.02393111, 0.98663291,\n        0.93963663],\n       ...,\n       [0.1855199 , 0.18528334, 0.18457427, ..., 0.87377447, 0.79651651,\n        0.71004531],\n       [0.23489055, 0.23459104, 0.23369327, ..., 0.88293371, 0.80811321,\n        0.72404989],\n       [0.28366219, 0.28330049, 0.28221631, ..., 0.89198182, 0.81956921,\n        0.73788456]])\n\n\nContour plots can be made using the height data.\n\nfig, ax = plt.subplots(figsize=(7, 7))\nax.contour(X, Y, Z, colors='blue')\n\n\n\n\n\n\n\n\nWhen a single color is used, negative values are represented by dashed lines, and positive values by solid lines. Futher options for colormaps can be found here: https://matplotlib.org/stable/tutorials/colors/colormaps.html\nIn case we want more lines (levels) to be drawn we can specify this in the command !\n\nax.contour(X, Y, Z, levels=30, cmap='Spectral')\n\nAlso imshow can be used as it directly plots array data.\n\nax.imshow() does not need the grid data as the matrix position is implicit in the height grid. The x and y coordinates have to be explicitly specified using extent [xmin, xmax, ymin, ymax] of the image on the plot.\nax.imshow() by default plots with the origin in the upper left ! Use the\n\n\nZ\n\narray([[1.        , 0.99872489, 0.99490282, ..., 1.02487674, 0.98783019,\n        0.94108251],\n       [0.99872489, 0.99745141, 0.99363421, ..., 1.02464018, 0.98753068,\n        0.94072081],\n       [0.99490282, 0.99363421, 0.98983161, ..., 1.02393111, 0.98663291,\n        0.93963663],\n       ...,\n       [0.1855199 , 0.18528334, 0.18457427, ..., 0.87377447, 0.79651651,\n        0.71004531],\n       [0.23489055, 0.23459104, 0.23369327, ..., 0.88293371, 0.80811321,\n        0.72404989],\n       [0.28366219, 0.28330049, 0.28221631, ..., 0.89198182, 0.81956921,\n        0.73788456]])\n\n\n\nimg = ax.imshow(Z, cmap='Spectral', origin='lower')\nfig.colorbar(img, ax=ax)\n\nContour labels can be included using clabel !\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# Create a figure and axes using the object-oriented approach\nfig, ax = plt.subplots(figsize=(7, 7))\n\n# Create the contour plot\ncontours = ax.contour(X, Y, Z, 5, colors='black')\nax.clabel(contours, inline=True, fontsize=12)\n\n# Display the image\nimg = ax.imshow(Z, extent=[0, 5, 0, 5], origin='lower', cmap='Spectral', alpha=0.8)\n\n# Add a colorbar\nfig.colorbar(img, ax=ax)\n\n# Show the plot\nplt.show()",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "07_visualization_using_matplotlib.html#visualizing-statistics",
    "href": "07_visualization_using_matplotlib.html#visualizing-statistics",
    "title": "7  Visualization",
    "section": "7.3 Visualizing Statistics",
    "text": "7.3 Visualizing Statistics\nIn 1774, Laplace’s first law posited that the frequency of errors can be described by an exponential function of the absolute value of the error, giving rise to the Laplace distribution. This distribution often models data in economics and health sciences more effectively than the traditional Gaussian distribution. The Laplace distribution is characterized by two parameters: the location parameter \\(\\mu\\) (mean) and the scale parameter \\(b\\) (standard deviation).\n\\[f(x\\mid\\mu,b) = \\frac{1}{2b} \\exp \\left( -\\frac{|x-\\mu|}{b} \\right)\\]\nLet us generate two sets samples from the Laplace distribution !\n\nimport numpy as np\nmu, b = 10, 1\n\ndata_1 = np.random.laplace(mu, b, 10000)\ndata_2 = np.random.laplace(mu*2, b, 10000)\n\n\nplt.plot(data_2)\nplt.show()\n\n\n\n\n\n\n\n\nThe histogram i.e. the frequency of the data in a certain bin can be visualized using the following command !\n\ncount, bins, ignored = plt.hist(data_1, bins=50, histtype='stepfilled', alpha=0.5, edgecolor='black')\ncount, bins, ignored = plt.hist(data_2, bins=50, histtype='stepfilled', alpha=0.5, edgecolor='red')\nplt.xlabel('Time')\nplt.ylabel('counts')\n\nText(0, 0.5, 'counts')\n\n\n\n\n\n\n\n\n\n\nbins\n\narray([11.99227956, 12.34213864, 12.69199772, 13.04185681, 13.39171589,\n       13.74157497, 14.09143405, 14.44129314, 14.79115222, 15.1410113 ,\n       15.49087038, 15.84072946, 16.19058855, 16.54044763, 16.89030671,\n       17.24016579, 17.59002488, 17.93988396, 18.28974304, 18.63960212,\n       18.9894612 , 19.33932029, 19.68917937, 20.03903845, 20.38889753,\n       20.73875662, 21.0886157 , 21.43847478, 21.78833386, 22.13819294,\n       22.48805203, 22.83791111, 23.18777019, 23.53762927, 23.88748836,\n       24.23734744, 24.58720652, 24.9370656 , 25.28692468, 25.63678377,\n       25.98664285, 26.33650193, 26.68636101, 27.0362201 , 27.38607918,\n       27.73593826, 28.08579734, 28.43565643, 28.78551551, 29.13537459,\n       29.48523367])",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "07_visualization_using_matplotlib.html#two-dimensional-histograms",
    "href": "07_visualization_using_matplotlib.html#two-dimensional-histograms",
    "title": "7  Visualization",
    "section": "7.4 Two-Dimensional Histograms",
    "text": "7.4 Two-Dimensional Histograms\nThe multivariate normal, multinormal or Gaussian distribution is a generalization of the one-dimensional normal distribution to higher dimensions. Such a distribution is specified by its mean and covariance matrix. These parameters are analogous to the mean (average or “center”) and variance (standard deviation, or “width,” squared) of the one-dimensional normal distribution.\nCovariance indicates the level to which two variables vary together.\n\nmean = [0, 0]\ncovariance = [[1, 0], [0, 1]]\nx, y = np.random.multivariate_normal(mean, covariance, 10000).T\n\nplt.hexbin(x, y, gridsize=50, cmap='BuPu')\n\ncb = plt.colorbar()\ncb.set_label('counts in bin')",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "07_visualization_using_matplotlib.html#animations-chaotic-dynamics-of-a-double-pendulum",
    "href": "07_visualization_using_matplotlib.html#animations-chaotic-dynamics-of-a-double-pendulum",
    "title": "7  Visualization",
    "section": "7.5 Animations: Chaotic Dynamics of a Double Pendulum",
    "text": "7.5 Animations: Chaotic Dynamics of a Double Pendulum\nThe double pendulum is a simple physical system that exhibits chaotic behavior. The double pendulum consists of two pendulums connected by a hinge. The motion of the double pendulum is governed by a set of coupled differential equations that are highly sensitive to initial conditions. This sensitivity to initial conditions is what leads to chaotic behavior. Below is the code to simulate the dynamics of a double pendulum using Python. The animation shows the chaotic motion of the double penduluum and has been computed using the Runge-Kutta and saved as a GIF using the Pillow library.\nThe governing equations for the double pendulum are given as:\n\\[\n\\mathbf{A}\\left(\\begin{array}{c}\n\\dot{\\theta}_{1}\\\\\n\\dot{\\theta}_{2}\n\\end{array}\\right)+\\mathbf{B}\\left(\\begin{array}{c}\n\\ddot{\\theta}_{1}\\\\\n\\ddot{\\theta}_{2}\n\\end{array}\\right)-\\mathbf{r}=0\n\\]\nWhere, \\[\n\\mathbf{A}=\\left[\\begin{array}{cc}\n-m_{2}l_{1}l_{2}\\dot{\\theta}_{2}sin\\left(\\theta_{1}-\\theta_{2}\\right) & m_{2}l_{1}l_{2}\\dot{\\theta}_{2}sin\\left(\\theta_{1}-\\theta_{2}\\right)\\\\\n-m_{2}l_{1}l_{2}\\dot{\\theta}_{1}sin\\left(\\theta_{1}-\\theta_{2}\\right) & m_{2}l_{1}l_{2}\\dot{\\theta}_{1}sin\\left(\\theta_{1}-\\theta_{2}\\right)\n\\end{array}\\right]\\label{eq:16}\n\\]\nand\n\\[\n\\mathbf{B}=\\left[\\begin{array}{cc}\n\\left(m_{1}+m_{2}\\right)l_{1}^{2} & m_{2}l_{1}l_{2}cos\\left(\\theta_{1}-\\theta_{2}\\right)\\\\\nm_{2}l_{1}l_{2}cos\\left(\\theta_{1}-\\theta_{2}\\right) & m_{2}l_{2}^{2}\n\\end{array}\\right]\\label{eq:17}\n\\]\nwith\n\\[\n\\mathbf{r}=\\left[\\begin{array}{c}\n-l_{1}g\\left(m_{1}+m_{2}\\right)sin\\theta_{1}-m_{2}l_{1}l_{2}\\dot{\\theta}_{1}\\dot{\\theta}_{2}sin\\left(\\theta_{1}-\\theta_{2}\\right)\\\\\nm_{2}l_{1}l_{2}\\dot{\\theta}_{1}\\dot{\\theta}_{2}sin\\left(\\theta_{1}-\\theta_{2}\\right)-l_{2}m_{2}g\\,sin\\theta_{2}\n\\end{array}\\right]\\label{eq:18}\n\\]\nAssuming \\(\\frac{d\\theta_1}{dt} = z_1\\) and \\(\\frac{d\\theta_2}{dt}= z_2\\) we can implement the Runge-Kutta method to solve the ODEs.\n\n\nDynamics of a Double Pendulum\n\n\n\n\n\nShow the code\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\n\n# Parameters\ng = 9.81  # acceleration due to gravity\nL1 = 1.0  # length of the first pendulum\nL2 = 1.0  # length of the second pendulum\nm1 = 1.0  # mass of the first pendulum\nm2 = 1.0  # mass of the second pendulum\n\ndef derivatives(state, t):\n    theta1, z1, theta2, z2 = state\n    delta = theta2 - theta1\n\n    denominator1 = (m1 + m2) * L1 - m2 * L1 * np.cos(delta) ** 2\n    denominator2 = (L2 / L1) * denominator1\n\n    dydx = np.zeros_like(state)\n    dydx[0] = z1\n    dydx[1] = (m2 * L1 * z1 ** 2 * np.sin(delta) * np.cos(delta) +\n               m2 * g * np.sin(theta2) * np.cos(delta) +\n               m2 * L2 * z2 ** 2 * np.sin(delta) -\n               (m1 + m2) * g * np.sin(theta1)) / denominator1\n    dydx[2] = z2\n    dydx[3] = (-m2 * L2 * z2 ** 2 * np.sin(delta) * np.cos(delta) +\n               (m1 + m2) * g * np.sin(theta1) * np.cos(delta) -\n               (m1 + m2) * L1 * z1 ** 2 * np.sin(delta) -\n               (m1 + m2) * g * np.sin(theta2)) / denominator2\n    return dydx\n\ndef runge_kutta_step(func, y, t, dt):\n    k1 = dt * func(y, t)\n    k2 = dt * func(y + 0.5 * k1, t + 0.5 * dt)\n    k3 = dt * func(y + 0.5 * k2, t + 0.5 * dt)\n    k4 = dt * func(y + k3, t + dt)\n    return y + (k1 + 2 * k2 + 2 * k3 + k4) / 6\n\n# Initial conditions\ntheta1 = np.pi / 2\ntheta2 = np.pi / 2\nz1 = 0.0\nz2 = 0.0\nstate = np.array([theta1, z1, theta2, z2])\n\n# Time parameters\nt = 0.0\ndt = 0.01\nt_final = 10.0\ntime = np.arange(t, t_final, dt)\n\n# Solve the ODE\nstates = np.zeros((len(time), 4))\nfor i, t in enumerate(time):\n    states[i] = state\n    state = runge_kutta_step(derivatives, state, t, dt)\n\n# Extract the angles\ntheta1 = states[:, 0]\ntheta2 = states[:, 2]\n\n# Calculate positions\nx1 = L1 * np.sin(theta1)\ny1 = -L1 * np.cos(theta1)\nx2 = x1 + L2 * np.sin(theta2)\ny2 = y1 - L2 * np.cos(theta2)\n\n\nThis guide explains how to create animations in Python using Matplotlib, specifically focusing on generating a GIF file. The provided code demonstrates the necessary steps to set up and animate a plot.\n\nImport Necessary Libraries First, ensure you have the necessary libraries installed:\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\n\n\nSet Up the Figure and Axis Create a figure and axis, and configure the limits and appearance:\n\n\nfig, ax = plt.subplots()\nax.set_xlim(-2, 2)\nax.set_ylim(-2, 2)\nline, = ax.plot([], [], lw=2)  # Line plot\nmarker1, = ax.plot([], [], 'bo', markersize=8)  # First marker\nmarker2, = ax.plot([], [], 'bo', markersize=8)  # Second marker\nax.hlines(y=0.0, xmin=-0.2, xmax=0.2, linewidth=10, color='gray')  # Horizontal line\n\n\n\n\n\n\n\n\nHide the axis spines and disable the axis:\n\nfor spine in ['top', 'right', 'left', 'bottom']:\n    ax.spines[spine].set_visible(False)\nax.set_axis_off()\n\n\nDefine the Initialization Function The init function initializes the plot components:\n\n\ndef init():\n    line.set_data([], [])\n    marker1.set_data([], [])\n    marker2.set_data([], [])\n    return line, marker1, marker2\n\n\nDefine the Update Function The update function updates the plot for each frame. It sets the data for the line and markers based on the current frame:\n\n\ndef update(frame):\n    line.set_data([0, x1[frame], x2[frame]], [0, y1[frame], y2[frame]])\n    marker1.set_data([x1[frame]], [y1[frame]])\n    marker2.set_data([x2[frame]], [y2[frame]])\n    return line, marker1, marker2\n\n\nCreate the Animation Use FuncAnimation to create the animation. Specify the figure, update function, number of frames, and initialization function:\n\n\nani = animation.FuncAnimation(fig, update, frames=len(time),\n                              init_func=init, blit=True)\n\n\nSave the Animation as a GIF Finally, save the animation using Pillow:\n\n\nani.save('data/double_pendulum.gif', writer='pillow', fps=30)\n\n\nClose the Plot Close the plot to avoid displaying it:\n\n\nplt.close()",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "07_visualization_using_matplotlib.html#exercises",
    "href": "07_visualization_using_matplotlib.html#exercises",
    "title": "7  Visualization",
    "section": "7.6 Exercises",
    "text": "7.6 Exercises\n\n7.6.1 Theory\n\nWhat is Matplotlib, and how is it used in Python?\nWhat are some of the different types of plots that can be created using Matplotlib?\nHow can the appearance of a plot be customized in Matplotlib?\nHow does Matplotlib integrate with other Python libraries such as NumPy and Pandas?\nHow can Matplotlib be used to create interactive plots and visualizations?\n\n\n\n7.6.2 Coding\n\nCreate a simple line plot using Matplotlib, where the x-axis represents time and the y-axis represents some quantity (such as temperature, stock prices, etc.). Customize the appearance of the plot, including the title, axis labels, and color.\nCreate a bar chart using Matplotlib to compare the performance of different models in a machine learning task. Customize the appearance of the chart to make it more visually appealing and informative.\nCreate a pie chart using Matplotlib to visualize the distribution of a categorical variable in a dataset. Add labels to the chart to show the percentage of each category.\nCreate a function and generate data using numpy. Plot this data using scatter plot.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "07_visualization_using_matplotlib.html#further-reading",
    "href": "07_visualization_using_matplotlib.html#further-reading",
    "title": "7  Visualization",
    "section": "7.7 Further Reading",
    "text": "7.7 Further Reading\n\nhttps://matplotlib.org/stable/tutorials/introductory/quick_start.html\n\nhttps://matplotlib.org/stable/gallery/subplots_axes_and_figures/index.html\nhttps://matplotlib.org/stable/gallery/statistics/index.html",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "08_scientific_computing_using_scipy.html",
    "href": "08_scientific_computing_using_scipy.html",
    "title": "8  Scientific Python (SciPy)",
    "section": "",
    "text": "8.1 Integration\nNumerical evaluation of a function of the type\n\\(\\displaystyle \\int_a^b \\int_a^b f(x, y) dxdy\\)\ncan be performed using numerical quadrature. In SciPy, for e.g. the quad function and dblquad among others, can be used for 1 variable and double integration respectively. Multiple variable integration is also available.\nfrom scipy.integrate import quad\n# define a simple function for the integrand\ndef f_1d(x, a, b):\n    \"\"\"\n    implements a simple quadratic function, with intercept at zero\n    \"\"\"\n    return (a**b)*x**2\nx_lower = 0 # the lower limit of x\nx_upper = 1 # the upper limit of x\n\nval, abserr = quad(f_1d, x_lower, x_upper, args=(1, 2))\nprint(val, abserr)\n\n0.3333333333333333 3.700743415417188e-15",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Scientific Python (SciPy)</span>"
    ]
  },
  {
    "objectID": "08_scientific_computing_using_scipy.html#ordinary-differential-equations-odes",
    "href": "08_scientific_computing_using_scipy.html#ordinary-differential-equations-odes",
    "title": "8  Scientific Python (SciPy)",
    "section": "8.2 Ordinary differential equations (ODEs)",
    "text": "8.2 Ordinary differential equations (ODEs)\nSciPy is often used to solve ODEs and system of coupled ODEs ! The odeint function is used to solve ODEs.\n\n8.2.1 Lotka-Volterra Equations\nLet’s solve a simple 2D system of ordinary differential equations (ODEs) and plot the results. We’ll use the solve_ivp function from SciPy’s integrate module.\nConsider the following system of ODEs:\n\\[ \\frac{dx}{dt} = f(x, y) \\] \\[ \\frac{dy}{dt} = g(x, y) \\]\nwhere \\(x\\) and \\(y\\) are the dependent variables, and \\(f(x, y)\\) and \\(g(x, y)\\) are functions that describe the rates of change of \\(x\\) and \\(y\\) with respect to time \\(t\\).\nFor this example, let’s use the Lotka-Volterra equations (predator-prey model):\n\\[ \\frac{dx}{dt} = \\alpha x - \\beta xy \\] \\[ \\frac{dy}{dt} = \\delta xy - \\gamma y \\]\nwhere \\(\\alpha\\), \\(\\beta\\), \\(\\gamma\\), and \\(\\delta\\) are constants.\nHere’s the Python code to solve this system and plot the results:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.integrate import solve_ivp\n\n# Define the Lotka-Volterra equations\ndef lotka_volterra(t, z, alpha, beta, delta, gamma):\n    x, y = z\n    dxdt = alpha * x - beta * x * y\n    dydt = delta * x * y - gamma * y\n    return [dxdt, dydt]\n\n# Parameters\nalpha = 1.0\nbeta = 0.1\ndelta = 0.075\ngamma = 1.5\n\n# Initial conditions: [prey population, predator population]\nz0 = [10, 5]\n\n# Time span\nt_span = (0, 10)\nt_eval = np.linspace(*t_span, 1000)\n\n# Solve the system of ODEs\nsolution = solve_ivp(lotka_volterra, t_span, z0, args=(alpha, beta, delta, gamma), t_eval=t_eval)\n\n# Extract the results\nt = solution.t\nx = solution.y[0]\ny = solution.y[1]\n\n# Plot the results\nfig, ax = plt.subplots(figsize=(6, 6))\n\n# Plot prey population\nax.plot(t, x, label='Prey (x)', color='blue')\n\n# Plot predator population\nax.plot(t, y, label='Predator (y)', color='red')\n\n# Add labels and legend\nax.set_xlabel('Time')\nax.set_ylabel('Population')\nax.legend()\nax.grid()\n\nplt.show()\n\n\n\n\n\n\n\n\nRunning this code will produce a plot showing the dynamics of the prey and predator populations over time according to the Lotka-Volterra model.\n\n\n8.2.2 Modelling Infection and recovery\nAt rate \\(\\beta\\), when a susceptible meets an infected, two infected persons exist. \\(S + I \\rightarrow 2 I\\) At rate \\(\\gamma\\) the infected recovers ! \\(I \\rightarrow R\\)\n\n\n\n\nR1\nR2\n\n\n\n\nS\n-1\n0\n\n\nI\n+1\n-1\n\n\nR\n0\n1\n\n\n\nLet us consider a simple epidemiological model that simulates the infection and recovery of a population ! The ordinary differential equations describing this is given by:\n\\[\\begin{aligned}\n& \\frac{dS}{dt} = - \\beta I S, \\\\\n& \\frac{dI}{dt} = \\beta I S- \\gamma I, \\\\\n& \\frac{dR}{dt} = \\gamma I,\n\\end{aligned}\\]\n.\n\nfrom scipy.integrate import odeint\n\nbeta = 0.01\ngamma = 0.5\n\n\ndef dx(x, t):\n    \"\"\"\n    The right-hand side of the model\n    \"\"\"\n    S = x[0]\n    I = x[1]\n    R = x[2]\n    \n    \n    dS = -beta*I*S*t\n    dI = beta*I*S -gamma*I\n    dR = gamma*I\n    \n    return [dS, dI, dR]\n\n\n# choose an initial state\nx0 = [90, 10, 0]\n\n\n# time coodinate to solve the ODE for: from 0 to 10 days\nt = np.linspace(0, 20, 350)\n\n\n# solve the ODE problem\nx = odeint(dx, x0, t)\n\n\nimport matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(figsize=(6, 6))\naxes.plot(t, x[:, 0], 'r', label='Susceptible')\naxes.plot(t, x[:, 1], 'b', label=\"Infected\")\naxes.plot(t, x[:, 2], 'g', label=\"Recovered\")\naxes.legend()\naxes.set_xlabel('days')\naxes.set_ylabel('Number')\nplt.show()",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Scientific Python (SciPy)</span>"
    ]
  },
  {
    "objectID": "08_scientific_computing_using_scipy.html#optimization",
    "href": "08_scientific_computing_using_scipy.html#optimization",
    "title": "8  Scientific Python (SciPy)",
    "section": "8.3 Optimization",
    "text": "8.3 Optimization\nLet us look at a few very simple cases of optimization. For a more detailed introduction to optimization with SciPy see: http://scipy-lectures.github.com/advanced/mathematical_optimization/index.html\n\nfrom scipy import optimize\n\n\n8.3.1 Finding a minima of a 1D function\nLet’s first look at how to find the minima of a simple function of a single variable:\n\ndef f(x):\n    \"\"\"\n    a function that returns the square of the input data\n    \"\"\"\n    return x**2\n\n\nfig, ax  = plt.subplots()\nx = np.linspace(-5, 3, 100)\nax.plot(x, f(x));\n\n\n\n\n\n\n\n\nWe can use the fmin_bfgs function to find the minima of a function:\n\nx_min = optimize.fmin_bfgs(f, -2)\nx_min \n\nOptimization terminated successfully.\n         Current function value: 0.000000\n         Iterations: 2\n         Function evaluations: 6\n         Gradient evaluations: 3\n\n\narray([-1.79994222e-08])\n\n\n\noptimize.fmin_bfgs(f, -5) \n\nOptimization terminated successfully.\n         Current function value: 0.000000\n         Iterations: 3\n         Function evaluations: 8\n         Gradient evaluations: 4\n\n\narray([-2.54405594e-08])\n\n\nWe can also use the brent or fminbound functions. They have a bit different syntax and use different algorithms.\n\n\n8.3.2 Optimization of a 2D function\nLet’s consider a common 2D objective function, the Rosenbrock function, which is often used to test optimization algorithms. The function is defined as:\n\\[f(x, y) = (a - x)^2 + b(y - x^2)^2 \\]\nwhere \\(a\\) and \\(b\\) are constants. For our example, let’s set \\(a = 1\\) and \\(b = 100\\).\nWe’ll use SciPy’s optimization capabilities to find the minimum of this function and create a contour plot with contour labels.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import minimize\n\n# Define the Rosenbrock function\ndef rosenbrock(x):\n    a = 1\n    b = 100\n    return (a - x[0])**2 + b * (x[1] - x[0]**2)**2\n\n# Perform the optimization\ninitial_guess = [0, 0]\nresult = minimize(rosenbrock, initial_guess, method='BFGS')\nopt_x, opt_y = result.x\n\n# Generate a grid of points\nx = np.linspace(-2, 2, 400)\ny = np.linspace(-1, 3, 400)\nX, Y = np.meshgrid(x, y)\nZ = (1 - X)**2 + 100 * (Y - X**2)**2\n\n\n# Plot the contour\nfig, ax = plt.subplots(figsize=(7, 7))\ncontour = ax.contour(X, Y, Z, levels=np.logspace(-1, 3, 20), cmap='viridis')\nax.clabel(contour, inline=True, fontsize=8)\nax.plot(opt_x, opt_y, 'r*', markersize=10, label='Optimum')\nax.set_xlabel('x')\nax.set_ylabel('y')\nax.legend()\n#plt.colorbar()\nplt.show()",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Scientific Python (SciPy)</span>"
    ]
  },
  {
    "objectID": "08_scientific_computing_using_scipy.html#further-reading",
    "href": "08_scientific_computing_using_scipy.html#further-reading",
    "title": "8  Scientific Python (SciPy)",
    "section": "8.4 Further reading",
    "text": "8.4 Further reading\nHere are some of the most frequently used functions from the SciPy library:\nscipy.integrate.quad: Computes a definite integral of a function from a to b using Gaussian quadrature.\n\nscipy.optimize.minimize: Finds the minimum of a function using various optimization algorithms.\n\nscipy.stats.norm: Provides functions for working with normal (Gaussian) distributions, including PDF, CDF, and random number generation.\n\nscipy.linalg.eig: Computes the eigenvalues and eigenvectors of a square matrix.\n\nscipy.signal.convolve: Computes the convolution of two signals.\n\nscipy.fft.fft: Computes the one-dimensional discrete Fourier Transform.\n\nscipy.special.gamma: Computes the gamma function and related functions.\n\nscipy.interpolate.interp1d: Interpolates a one-dimensional function.\n\nscipy.spatial.distance.pdist: Computes pairwise distances between observations in a dataset.\n\nscipy.cluster.hierarchy.linkage: Computes hierarchical clusters from a distance matrix.\n\nhttp://www.scipy.org\nhttps://docs.scipy.org/doc/scipy/tutorial/index.html#user-guide",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Scientific Python (SciPy)</span>"
    ]
  },
  {
    "objectID": "05a_coupled_differential_equations.html",
    "href": "05a_coupled_differential_equations.html",
    "title": "9  Dynamics of Coupled Differential Equations",
    "section": "",
    "text": "9.1 The Runge-Kutta Method\nThe Runge-Kutta method is a powerful technique for solving ODEs numerically. It is an iterative method that provides an approximate solution by advancing the solution in small steps, calculating intermediate points to achieve higher accuracy. Among the various forms of the Runge-Kutta method, the most commonly used is the fourth-order Runge-Kutta method, often simply referred to as “RK4”.\nFor a differential equation of the form\\(\\frac{dy}{dt} = f(y, t)\\), the Runge-Kutta method can be used to approximate the solution\\(y(t)\\)at time\\(t + \\Delta t\\)as follows:\n\\[\ny_{n+1} = y_n + \\frac{1}{6} (k_1 + 2k_2 + 2k_3 + k_4)\n\\]\nwhere\\(k_1 = \\Delta t \\cdot f(y_n, t_n)\\),\\(k_2 = \\Delta t \\cdot f(y_n + \\frac{1}{2} k_1, t_n + \\frac{1}{2} \\Delta t)\\),\\(k_3 = \\Delta t \\cdot f(y_n + \\frac{1}{2} k_2, t_n + \\frac{1}{2} \\Delta t)\\), and\\(k_4 = \\Delta t \\cdot f(y_n + k_3, t_n + \\Delta t)\\).\nBelow is the Python code for a single step of the fourth-order Runge-Kutta method:\ndef runge_kutta_step(func, y, t, dt):\n    k1 = dt * func(y, t)\n    k2 = dt * func(y + 0.5 * k1, t + 0.5 * dt)\n    k3 = dt * func(y + 0.5 * k2, t + 0.5 * dt)\n    k4 = dt * func(y + k3, t + dt)\n    return y + (k1 + 2 * k2 + 2 * k3 + k4) / 6",
    "crumbs": [
      "Home",
      "Part 3: Applications",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Dynamics of Coupled Differential Equations</span>"
    ]
  },
  {
    "objectID": "05a_coupled_differential_equations.html#the-runge-kutta-method",
    "href": "05a_coupled_differential_equations.html#the-runge-kutta-method",
    "title": "9  Dynamics of Coupled Differential Equations",
    "section": "",
    "text": "9.1.1 How It Works\n\nInitialization:\n\nfunc: The function representing the ODE, which takes the current value y and time t as inputs and returns the derivative dy/dt.\ny: The current value of the dependent variable.\nt: The current time.\ndt: The time step size.\n\nIntermediate Steps:\n\nk1 is the slope at the beginning of the interval.\nk2 is the slope at the midpoint of the interval, estimated using k1.\nk3 is another slope at the midpoint of the interval, but estimated using k2.\nk4 is the slope at the end of the interval, estimated using k3.\n\nCombination of Slopes:\n\nThe final value of y is updated using a weighted average of these slopes. This weighted sum ensures that the method achieves fourth-order accuracy, meaning the error per step is proportional to (dt^5).\n\n\n\n\n9.1.2 How to Use the above Code\nTo solve an ODE using the Runge-Kutta method, we repeatedly apply the runge_kutta_step function over the desired time range. Here is an example of how to use the method to solve a simple ODE:\n\nimport numpy as np\n\n# Example ODE function: dy/dt = -2y\ndef dydt(y, t):\n    return -2 * y\n\n# Initial conditions\ny0 = 1\nt0 = 0\ntf = 5\ndt = 0.1\n\n# Time array\nt = np.arange(t0, tf, dt)\n\n# Array to store solution\nys = [y0]\n\n# Solving the ODE\ny = y0\nfor ti in t[:-1]:\n    y = runge_kutta_step(dydt, y, ti, dt)\n    ys.append(y)\n\n# Convert ys to a numpy array for easier handling\nys = np.array(ys)\n\n# Plotting the result (optional)\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(7, 3))\nplt.plot(t, ys, label='Numerical Solution')\nplt.xlabel('t')\nplt.ylabel('$y(t)$')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nIn this example, we define a simple ODE, set the initial conditions, and use a loop to apply the runge_kutta_step function repeatedly. The result is a numerical approximation of the solution over the specified time range.",
    "crumbs": [
      "Home",
      "Part 3: Applications",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Dynamics of Coupled Differential Equations</span>"
    ]
  },
  {
    "objectID": "05a_coupled_differential_equations.html#visualization-functions-for-ode-solutions",
    "href": "05a_coupled_differential_equations.html#visualization-functions-for-ode-solutions",
    "title": "9  Dynamics of Coupled Differential Equations",
    "section": "9.2 Visualization Functions for ODE Solutions",
    "text": "9.2 Visualization Functions for ODE Solutions\nBelow are two functions that can be used to visualize the solutions of ODEs. The plot_main_curves function for plotting the main fields over time and the plot_phase_plots function for generating phase plots.\n\n\nShow the code\nimport matplotlib.pyplot as plt\n\ndef plot_main_curves(t, y, field_labels):\n    \n    plt.figure(figsize=(7, 3))\n\n    for i in range(len(field_labels)):\n        plt.plot(t, y[:, i], label=field_labels[i])\n\n    plt.xlabel('Time')\n    plt.ylabel('Fields')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\n\n\n\nShow the code\ndef plot_phase_plots(y, field_labels):\n\n    # Determine the number of components and phase plots\n    num_components = y.shape[1]\n    num_phase_plots = num_components * (num_components - 1) // 2\n\n    # Determine the number of columns and rows for phase plots\n    num_columns = min(3, num_components)\n    num_rows = (num_phase_plots + num_columns - 1) // num_columns\n\n    fig, axs = plt.subplots(num_rows, num_columns, figsize=(7, 3 * num_rows))\n\n    # Ensure axs is always a 2D array\n    if num_rows == 1:\n        axs = [axs]  # Ensure axs is always a 2D array\n    if num_columns == 1:\n        axs = [[ax] for ax in axs]  # Ensure axs is always a 2D array\n\n    plot_index = 0\n    for i in range(num_components):\n        for j in range(i + 1, num_components):\n            row = plot_index // num_columns\n            col = plot_index % num_columns\n            axs[row][col].plot(y[:, i], y[:, j], label=f'{field_labels[i]} vs {field_labels[j]}', color='gray')\n            axs[row][col].set_title(f'{field_labels[i]} vs {field_labels[j]}')\n            axs[row][col].set_xlabel(field_labels[i])\n            axs[row][col].set_ylabel(field_labels[j])\n            axs[row][col].legend()\n            axs[row][col].grid(True)\n            plot_index += 1\n\n    # Remove empty subplots\n    for k in range(plot_index, num_rows * num_columns):\n        fig.delaxes(axs.flatten()[k])\n\n    plt.tight_layout()\n    plt.show()",
    "crumbs": [
      "Home",
      "Part 3: Applications",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Dynamics of Coupled Differential Equations</span>"
    ]
  },
  {
    "objectID": "05a_coupled_differential_equations.html#lotka-volterra-predator-prey-model-with-competition",
    "href": "05a_coupled_differential_equations.html#lotka-volterra-predator-prey-model-with-competition",
    "title": "9  Dynamics of Coupled Differential Equations",
    "section": "9.3 Lotka-Volterra Predator-Prey Model with Competition",
    "text": "9.3 Lotka-Volterra Predator-Prey Model with Competition\nThe Lotka-Volterra equations describe the dynamics of biological systems in which two species interact, one as a predator and the other as prey. The model captures the essential features of predator-prey relationships, such as population growth, predation, and competition for resources.\nIn ecological modeling, the primary motivation is to understand the intricate interactions within an ecosystem. This model helps ecologists predict changes in species populations over time, taking into account factors like predation and competition. Such predictions are crucial for conservation efforts, as they assist in managing wildlife reserves and studying the impact of invasive species on native populations.\nIn the field of epidemiology, the Lotka-Volterra model is used to simulate the spread of diseases among different populations, such as susceptible, infected, and recovered individuals. This application is vital for studying disease dynamics and evaluating the effectiveness of vaccination programs. It plays a crucial role in public health planning and developing strategies for disease control, ensuring that health officials can respond effectively to potential outbreaks.\nIn economics, the Lotka-Volterra model is employed to analyze competition and cooperation in market dynamics. By modeling competing companies or products, economists can predict market shares over time and understand competitive behaviors. This application is particularly useful for strategic business planning, allowing companies to anticipate market trends and make informed decisions to enhance their competitive edge.\nFor a complex system involving three species with both predation and competition, the equations are:\n\\[\n\\begin{aligned}\n\\frac{dx}{dt} &= \\alpha x - \\beta xy - \\gamma xz \\\\\n\\frac{dy}{dt} &= -\\delta y + \\epsilon xy - \\eta yz \\\\\n\\frac{dz}{dt} &= \\theta z - \\iota xz - \\kappa yz\n\\end{aligned}\n\\]\nRewriting these equations in matrix-vector form:\n\\[\n\\frac{d}{dt}\n\\begin{pmatrix}\nx \\\\\ny \\\\\nz\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\alpha & -\\beta y & -\\gamma z \\\\\n\\epsilon x & -\\delta & -\\eta z \\\\\n-\\iota x & -\\kappa y & \\theta\n\\end{pmatrix}\n\\begin{pmatrix}\nx \\\\\ny \\\\\nz\n\\end{pmatrix}\n\\]\nIn this form:\n\\[\n\\mathbf{y} =\n\\begin{pmatrix}\nx \\\\\ny \\\\\nz\n\\end{pmatrix}\n\\quad \\text{and} \\quad\nA(\\mathbf{y}) =\n\\begin{pmatrix}\n\\alpha & -\\beta y & -\\gamma z \\\\\n\\epsilon x & -\\delta & -\\eta z \\\\\n-\\iota x & -\\kappa y & \\theta\n\\end{pmatrix}\n\\]\nTypical Parameter Ranges:\n\n\\(\\alpha\\): Growth rate of prey (0.01 to 1)\n\\(\\beta\\): Predation rate coefficient (0.001 to 0.1)\n\\(\\gamma\\): Competition rate coefficient for \\(x\\) (0.001 to 0.1)\n\\(\\delta\\): Death rate of predator (0.01 to 1)\n\\(\\epsilon\\): Growth rate coefficient for predator due to prey (0.001 to 0.1)\n\\(\\eta\\): Competition rate coefficient for \\(y\\) (0.001 to 0.1)\n\\(\\theta\\): Growth rate of the third species (0.01 to 1)\n\\(\\iota\\): Competition rate coefficient for \\(z\\) (0.001 to 0.1)\n\\(\\kappa\\): Competition rate coefficient for \\(y\\) on \\(z\\) (0.001 to 0.1)\n\n\n\nShow the code\nimport numpy as np\n\ndef lotka_volterra(y, t):\n    alpha, beta, gamma = 0.1, 0.02, 0.01\n    delta, epsilon, eta = 0.1, 0.01, 0.01\n    theta, iota, kappa = 0.1, 0.01, 0.01\n    x, y, z = y\n    dxdt = alpha * x - beta * x * y - gamma * x * z\n    dydt = -delta * y + epsilon * x * y - eta * y * z\n    dzdt = theta * z - iota * x * z - kappa * y * z\n    return np.array([dxdt, dydt, dzdt])\n\n# Initial conditions and time setup\ny0 = np.array([40, 9, 3])\nt0, tf, dt = 0, 200, 0.1\nt = np.arange(t0, tf, dt)\n\n# Solving the ODE\nys = [y0]\nfor ti in t[:-1]:\n    y_next = runge_kutta_step(lotka_volterra, ys[-1], ti, dt)\n    ys.append(y_next)\nys = np.array(ys)\n\nfield_labels = ['$x(t)$', '$y(t)$', '$z(t)$']\n\nplot_main_curves(t, ys, field_labels)\n\n\n\n\nDynamics of a Predator-Prey-Competition Model\n\n\n\n\n\n\n\nShow the code\nplot_phase_plots(ys, field_labels)\n\n\n\n\nPhase Dynamics of the Predator-Prey-Competition Model",
    "crumbs": [
      "Home",
      "Part 3: Applications",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Dynamics of Coupled Differential Equations</span>"
    ]
  },
  {
    "objectID": "05a_coupled_differential_equations.html#competition-for-resources-model",
    "href": "05a_coupled_differential_equations.html#competition-for-resources-model",
    "title": "9  Dynamics of Coupled Differential Equations",
    "section": "9.4 Competition for Resources Model",
    "text": "9.4 Competition for Resources Model\nThe three-species competing model describes the dynamics of three species competing for the same limited resources. It is used in several domains due to its ability to capture the dynamics of competition among multiple species or entities sharing common resources.\nIn ecological modeling, the motivation behind using this model is to understand the competitive interactions between multiple species within an ecosystem. By simulating how species compete for limited resources, the model helps ecologists predict changes in population sizes and the potential outcomes of competition. This understanding is crucial for ecosystem management and conservation biology, enabling the development of strategies to preserve biodiversity and maintain ecological balance.\nIn agricultural science, the model is used to study the competition between different crops or between crops and weeds. The primary motivation here is to optimize crop yields and develop effective weed control strategies. By modeling these interactions, agricultural scientists can determine the best practices for crop rotation, planting schedules, and the use of herbicides, ultimately leading to more sustainable and productive farming systems.\nIn sociology and economics, the three-species competing model can be applied to analyze competition between different social groups or businesses for shared resources. The motivation in this context is to understand the dynamics of competitive interactions and predict the outcomes of such competition. This application is particularly valuable for market analysis and strategic business planning, as it provides insights into how different entities compete, adapt, and coexist within a shared environment. By leveraging these insights, businesses and policymakers can make informed decisions to foster healthy competition and optimize resource allocation.\nThe three-species competing model consists of three species, each with its growth rate and carrying capacity, competing for shared resources. The model captures the interactions between species and how they influence each other’s population dynamics.\nThe equations are:\n\\[\n\\begin{aligned}\n\\frac{du}{dt} &= r_1 u \\left( 1 - \\frac{u}{K_1} - \\alpha \\frac{v}{K_1} - \\beta \\frac{w}{K_1} \\right) \\\\\n\\frac{dv}{dt} &= r_2 v \\left( 1 - \\frac{v}{K_2} - \\gamma \\frac{u}{K_2} - \\delta \\frac{w}{K_2} \\right) \\\\\n\\frac{dw}{dt} &= r_3 w \\left( 1 - \\frac{w}{K_3} - \\epsilon \\frac{u}{K_3} - \\zeta \\frac{v}{K_3} \\right)\n\\end{aligned}\n\\]\nRewriting these equations in matrix-vector form:\n\\[\n\\frac{d}{dt}\n\\begin{pmatrix}\nu \\\\\nv \\\\\nw\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nr_1 \\left( 1 - \\frac{u}{K_1} - \\alpha \\frac{v}{K_1} - \\beta \\frac{w}{K_1} \\right) \\\\\nr_2 \\left( 1 - \\frac{v}{K_2} - \\gamma \\frac{u}{K_2} - \\delta \\frac{w}{K_2} \\right) \\\\\nr_3 \\left( 1 - \\frac{w}{K_3} - \\epsilon \\frac{u}{K_3} - \\zeta \\frac{v}{K_3} \\right)\n\\end{pmatrix}\n\\]\nThis can be represented as:\n\\[\n\\frac{d}{dt}\n\\mathbf{y} =\n\\mathbf{R} \\odot \\left( \\mathbf{1} - \\frac{1}{\\mathbf{K}} \\mathbf{B} \\mathbf{y} \\right) \\odot \\mathbf{y}\n\\]\nwhere: \\[\n\\mathbf{y} =\n\\begin{pmatrix}\nu \\\\\nv \\\\\nw\n\\end{pmatrix},\n\\quad\n\\mathbf{R} =\n\\begin{pmatrix}\nr_1 \\\\\nr_2 \\\\\nr_3\n\\end{pmatrix},\n\\quad\n\\mathbf{K} =\n\\begin{pmatrix}\nK_1 \\\\\nK_2 \\\\\nK_3\n\\end{pmatrix},\n\\quad\n\\mathbf{B} =\n\\begin{pmatrix}\n1 & \\alpha & \\beta \\\\\n\\gamma & 1 & \\delta \\\\\n\\epsilon & \\zeta & 1\n\\end{pmatrix}\n\\]\nHere, \\(\\odot\\) denotes element-wise multiplication.\nTypical Parameter Ranges:\n\n\\(r_1, r_2, r_3\\): Growth rates of species (0.01 to 1)\n\\(K_1, K_2, K_3\\): Carrying capacities (500 to 2000)\n\\(\\alpha, \\beta, \\gamma, \\delta, \\epsilon, \\zeta\\): Competition coefficients (0.001 to 0.1)\n\nParameter Descriptions:\n\n\\(r_1, r_2, r_3\\): Intrinsic growth rates of the species \\(u\\), \\(v\\), and \\(w\\), respectively.\n\\(K_1, K_2, K_3\\): Carrying capacities of the species \\(u\\), \\(v\\), and \\(w\\), representing the maximum sustainable population in the absence of competitors.\n\\(\\alpha, \\beta, \\gamma, \\delta, \\epsilon, \\zeta\\): Competition coefficients representing the impact of one species on another:\n\n\\(\\alpha\\): Effect of species \\(v\\) on species \\(u\\)\n\\(\\beta\\): Effect of species \\(w\\) on species \\(u\\)\n\\(\\gamma\\): Effect of species \\(u\\) on species \\(v\\)\n\\(\\delta\\): Effect of species \\(w\\) on species \\(v\\)\n\\(\\epsilon\\): Effect of species \\(u\\) on species \\(w\\)\n\\(\\zeta\\): Effect of species \\(v\\) on species \\(w\\)\n\n\n\n\nShow the code\ndef competing_species(y, t):\n    r1, r2, r3 = 0.1, 0.1, 0.1\n    K1, K2, K3 = 1000, 1000, 1000\n    alpha, beta, gamma = 0.01, 0.01, 0.01\n    delta, epsilon, zeta = 0.01, 0.01, 0.01\n    u, v, w = y\n    dudt = r1 * u * (1 - u / K1 - alpha * v / K1 - beta * w / K1)\n    dvdt = r2 * v * (1 - v / K2 - gamma * u / K2 - delta * w / K2)\n    dwdt = r3 * w * (1 - w / K3 - epsilon * u / K3 - zeta * v / K3)\n    return np.array([dudt, dvdt, dwdt])\n\ny0 = np.array([50, 3, 20])\nt0, tf, dt = 0, 200, 0.1\nt = np.arange(t0, tf, dt)\n\nys = [y0]\nfor ti in t[:-1]:\n    y_next = runge_kutta_step(competing_species, ys[-1], ti, dt)\n    ys.append(y_next)\nys = np.array(ys)\n\nfield_labels = ['$u(t)$', '$v(t)$', '$w(t)$']\nplot_main_curves(t, ys, field_labels)\n\n\n\n\nDynamics of the 3-species Model\n\n\n\n\n\n\n\nShow the code\nplot_phase_plots(ys, field_labels)\n\n\n\n\nPhases of the 3-species Model",
    "crumbs": [
      "Home",
      "Part 3: Applications",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Dynamics of Coupled Differential Equations</span>"
    ]
  },
  {
    "objectID": "05a_coupled_differential_equations.html#coupled-oscillators-model",
    "href": "05a_coupled_differential_equations.html#coupled-oscillators-model",
    "title": "9  Dynamics of Coupled Differential Equations",
    "section": "9.5 Coupled Oscillators Model",
    "text": "9.5 Coupled Oscillators Model\nThe coupled oscillators model describes the dynamics of multiple oscillators that are interconnected, influencing each other’s motion.\nIn mechanical systems, the primary motivation for using this model is to understand the behavior of interconnected mechanical oscillators, such as coupled pendulums or masses connected by springs. By analyzing the interactions between these oscillators, engineers can predict the dynamic responses of complex mechanical systems. This understanding is essential for designing stable and efficient structures, machinery, and vehicles, ensuring that they can withstand vibrations and other dynamic forces.\nIn electrical circuits, the three-oscillators model is used to study the behavior of coupled electrical oscillators, such as LC circuits that interact through mutual inductance or capacitance. The motivation here is to design and analyze electronic devices like filters, oscillators, and signal processors. By modeling the interactions between these electrical components, engineers can optimize the performance of electronic circuits and systems, enhancing their functionality and reliability in various applications, from communications to consumer electronics.\nIn biological systems, the model is applied to understand the behavior of coupled biological oscillators, such as neurons in the brain or circadian rhythms in living organisms. The motivation is to gain insights into how biological systems synchronize and maintain their rhythmic activities. This application is crucial in fields like neuroscience, where understanding the synchronization of neuronal oscillations can shed light on brain function and disorders. In chronobiology, the model helps researchers study the mechanisms underlying biological clocks, contributing to the development of treatments for sleep disorders and optimizing schedules for shift workers.\nFor three coupled oscillators, the equations are:\n\\[\n\\begin{aligned}\n\\frac{d^2 x_1}{dt^2} &= -k_1 x_1 + k_2 (x_2 - x_1) + k_3 (x_3 - x_1) \\\\\n\\frac{d^2 x_2}{dt^2} &= -k_2 x_2 + k_1 (x_1 - x_2) + k_3 (x_3 - x_2) \\\\\n\\frac{d^2 x_3}{dt^2} &= -k_3 x_3 + k_1 (x_1 - x_3) + k_2 (x_2 - x_3)\n\\end{aligned}\n\\]\nRewriting these equations in matrix-vector form, we have:\n\\[\n\\mathbf{M} \\frac{d^2 \\mathbf{x}}{dt^2} = \\mathbf{K} \\mathbf{x}\n\\]\nwhere:\n\\[\n\\mathbf{x} =\n\\begin{pmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3\n\\end{pmatrix},\n\\quad\n\\mathbf{M} =\n\\begin{pmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix},\n\\quad\n\\mathbf{K} =\n\\begin{pmatrix}\n-k_1 - k_2 - k_3 & k_2 & k_3 \\\\\nk_1 & -k_1 - k_2 - k_3 & k_3 \\\\\nk_1 & k_2 & -k_1 - k_2 - k_3\n\\end{pmatrix}\n\\]\nTypical Parameter Ranges:\n\n\\(k_1, k_2, k_3\\): Coupling constants (0.1 to 10)\n\nParameter Descriptions:\n\n\\(k_1, k_2, k_3\\): Coupling constants representing the strength of the interaction between oscillators.\n\n\\(k_1\\): Coupling between \\(x_1\\) and \\(x_2\\)\n\\(k_2\\): Coupling between \\(x_2\\) and \\(x_3\\)\n\\(k_3\\): Coupling between \\(x_1\\) and \\(x_3\\)\n\n\n\n\nShow the code\ndef coupled_oscillators(y, t):\n    k1, k2, k3 = 1.0, 1.0, 1.0\n    x1, x2, x3, v1, v2, v3 = y\n    dx1dt = v1\n    dx2dt = v2\n    dx3dt = v3\n    dv1dt = -k1 * x1 + k2 * (x2 - x1) + k3 * (x3 - x1)\n    dv2dt = -k2 * x2 + k1 * (x1 - x2) + k3 * (x3 - x2)\n    dv3dt = -k3 * x3 + k1 * (x1 - x3) + k2 * (x2 - x3)\n    return np.array([dx1dt, dx2dt, dx3dt, dv1dt, dv2dt, dv3dt])\n\ny0 = np.array([1, 0.5, -1, 0, 0, 0])\nt0, tf, dt = 0, 100, 0.1\nt = np.arange(t0, tf, dt)\n\nys = [y0]\nfor ti in t[:-1]:\n    y_next = runge_kutta_step(coupled_oscillators, ys[-1], ti, dt)\n    ys.append(y_next)\n\nys = np.array(ys)\n\nfield_labels_displacements = ['$u_1$', '$u_2$', '$u_3$']\nplot_main_curves(t, ys[:, 0:3], field_labels)\n\n\n\n\nDynamics of the Coupled Oscillators Model\n\n\n\n\n\n\n\nShow the code\nfield_labels_all = ['$u_1$', '$u_2$', '$u_3$', '$v_1$', '$v_2$', '$v_3$']\nplot_phase_plots(ys, field_labels_all)\n\n\n\n\nPhases of the Coupled Oscillators Model",
    "crumbs": [
      "Home",
      "Part 3: Applications",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Dynamics of Coupled Differential Equations</span>"
    ]
  },
  {
    "objectID": "05a_coupled_differential_equations.html#sir-model-with-immunization-and-birth-rate",
    "href": "05a_coupled_differential_equations.html#sir-model-with-immunization-and-birth-rate",
    "title": "9  Dynamics of Coupled Differential Equations",
    "section": "9.6 SIR Model with Immunization and Birth Rate",
    "text": "9.6 SIR Model with Immunization and Birth Rate\nThe SIR model (Susceptible, Infected, Recovered) is a foundational tool in epidemiology and public health, used to describe the spread of infectious diseases within a population. Its applications extend to various fields where understanding the dynamics of disease transmission is crucial.\nIn epidemiology, the primary motivation for using the SIR model is to understand how infectious diseases propagate through populations. By dividing the population into three compartments—susceptible (S), infected (I), and recovered (R)—the model helps predict the course of an epidemic and the potential outcomes of different intervention strategies. This is vital for public health planning, as it allows health officials to estimate the impact of measures such as vaccination, quarantine, and social distancing. The SIR model aids in the development of effective disease control strategies, helping to minimize the spread and impact of infectious diseases.\nIn public health, the SIR model is used to evaluate the effectiveness of public health interventions and inform policy decisions. The motivation here is to assess how interventions like immunization programs and public awareness campaigns can alter the course of an epidemic. By simulating various scenarios, public health officials can optimize resource allocation and response strategies to better manage outbreaks. This application is crucial for preparing and responding to epidemics and pandemics, ensuring that public health systems are equipped to protect communities effectively.\nIn population biology, the SIR model helps researchers study disease dynamics in animal populations. The motivation is to understand how diseases spread among wildlife and livestock, which can have significant implications for conservation and agriculture. By modeling the transmission of diseases within and between animal species, researchers can develop strategies to manage outbreaks, prevent the spread of zoonotic diseases to humans, and protect endangered species. This application is essential for maintaining healthy ecosystems and sustainable agricultural practices.\nThe SIR model with immunization and birth rate describes the dynamics of an infectious disease within a population. The population is divided into three compartments: susceptible (S), infected (I), and recovered (R). The equations are:\n\\[\n\\begin{aligned}\n\\frac{dS}{dt} &= \\mu (S + I + R) - \\beta SI - \\mu S \\\\\n\\frac{dI}{dt} &= \\beta SI - (\\gamma + \\mu) I \\\\\n\\frac{dR}{dt} &= \\gamma I - \\mu R\n\\end{aligned}\n\\]\nRewriting these equations in matrix-vector form:\n\\[\n\\frac{d}{dt}\n\\begin{pmatrix}\nS \\\\\nI \\\\\nR\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n-\\beta I - \\mu & 0 & 0 \\\\\n\\beta S & -(\\gamma + \\mu) & 0 \\\\\n0 & \\gamma & -\\mu\n\\end{pmatrix}\n\\begin{pmatrix}\nS \\\\\nI \\\\\nR\n\\end{pmatrix}\n+\n\\begin{pmatrix}\n\\mu (S + I + R) \\\\\n0 \\\\\n0\n\\end{pmatrix}\n\\]\nIn this form:\n\\[\n\\mathbf{y} =\n\\begin{pmatrix}\nS \\\\\nI \\\\\nR\n\\end{pmatrix}\n\\quad \\text{and} \\quad\nA(\\mathbf{y}) =\n\\begin{pmatrix}\n-\\beta I - \\mu & 0 & 0 \\\\\n\\beta S & -(\\gamma + \\mu) & 0 \\\\\n0 & \\gamma & -\\mu\n\\end{pmatrix}\n\\]\nTypical Parameter Ranges:\n\n\\(\\beta\\): Transmission rate (0.1 to 1)\n\\(\\gamma\\): Recovery rate (0.01 to 0.5)\n\\(\\mu\\): Birth/Death rate (0.001 to 0.01)\n\nParameter Descriptions:\n\n\\(\\beta\\): Transmission rate, representing the rate at which susceptible individuals become infected upon contact with infected individuals.\n\\(\\gamma\\): Recovery rate, representing the rate at which infected individuals recover and move to the recovered compartment.\n\\(\\mu\\): Birth/Death rate, representing the rate at which individuals are born into the susceptible compartment and the natural death rate across all compartments.\n\n\n\nShow the code\ndef sir_model(y, t):\n    mu, beta, gamma = 0.01, 0.3, 0.1\n    S, I, R = y\n    dSdt = mu * (S + I + R) - beta * S * I - mu * S\n    dIdt = beta * S * I - (gamma + mu) * I\n    dRdt = gamma * I - mu * R\n    return np.array([dSdt, dIdt, dRdt])\n\ny0 = np.array([0.99, 0.01, 0.0])\nt0, tf, dt = 0, 160, 0.1\nt = np.arange(t0, tf, dt)\n\nys = [y0]\nfor ti in t[:-1]:\n    y_next = runge_kutta_step(sir_model, ys[-1], ti, dt)\n    ys.append(y_next)\nys = np.array(ys)\nfield_labels = ['$S(t)$', '$I(t)$', '$R(t)$']\nplot_main_curves(t, ys, field_labels)\n\n\n\n\nDynamics of the SIR Model with Immunization and Birth Rate\n\n\n\n\n\n\n\nShow the code\nplot_phase_plots(ys, field_labels)\n\n\n\n\nPhases of the SIR Model with Immunization and Birth Rate",
    "crumbs": [
      "Home",
      "Part 3: Applications",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Dynamics of Coupled Differential Equations</span>"
    ]
  },
  {
    "objectID": "05a_coupled_differential_equations.html#conclusion",
    "href": "05a_coupled_differential_equations.html#conclusion",
    "title": "9  Dynamics of Coupled Differential Equations",
    "section": "9.7 Conclusion",
    "text": "9.7 Conclusion\nOrdinary Differential Equations (ODEs) are a powerful tool for understanding the world around us. While fitting empirical data is useful for some purposes, ODEs offer a deeper, more insightful way to study complex systems. They are excellent at showing how things change over time and how different variables interact with each other. ODEs help us understand not just the current state of a system but how it evolves. For example, Newton’s laws of motion, expressed as ODEs, explain how forces cause changes in the movement of objects. This level of understanding goes beyond what we can get from data points alone.\nOne of the strengths of ODEs is their ability to predict future behavior. Once we have an ODE model, we can use it to forecast what will happen under different conditions, even if we don’t have data for those scenarios. For instance, the Lotka-Volterra equations can predict how predator and prey populations will change over time, giving us insights into future population dynamics. ODE models are often very general and can be applied to various systems with similar principles. This means that a model developed for one situation can often be adapted for another. For example, the SIR model, which is used to study the spread of diseases, can be modified to apply to different diseases and populations, showing its versatility. Developing ODE models forces us to think deeply about the systems we are studying, often leading to new hypotheses and discoveries. For example, in ecology, ODEs that describe interactions between species can suggest new ideas about how species compete for resources or maintain ecological balance. This process of building and refining models is a key part of scientific discovery.\nComplex systems with many interacting parts and feedback loops can be difficult to understand with empirical data alone. ODEs provide a structured way to analyze these interactions and understand the overall behavior of the system. Climate models, for example, use ODEs to represent the interactions between the atmosphere, oceans, and land, helping us understand climate change. Empirical data can be limited by the conditions under which it was collected, and it may include noise or biases. While data fitting is helpful, it might not capture all the important dynamics of a system. ODEs, informed by empirical data but based on theoretical principles, offer a more robust framework for understanding and prediction. By using ODEs, we can move beyond mere observation to a deeper understanding and more effective management of the complex systems that shape our world.",
    "crumbs": [
      "Home",
      "Part 3: Applications",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Dynamics of Coupled Differential Equations</span>"
    ]
  },
  {
    "objectID": "08a_partial_differential_equations.html",
    "href": "08a_partial_differential_equations.html",
    "title": "10  Partial Differential Equations",
    "section": "",
    "text": "10.1 Diffusion and Reaction Problems\nThe Gray-Scott model is a well-known reaction-diffusion system used to simulate pattern formation. It describes the reaction and diffusion of two chemical species,\\(U\\)and\\(V\\). The governing equations are:\n\\[\\frac{\\partial U}{\\partial t} = D_U \\nabla^2 U - UV^2 + F(1 - U)\\] \\[\\frac{\\partial V}{\\partial t} = D_V \\nabla^2 V + UV^2 - (F + k)V\\]\nwhere: -\\(U\\)and\\(V\\)are the concentrations of the two chemical species. -\\(D_U\\)and\\(D_V\\)are the diffusion coefficients for\\(U\\)and\\(V\\), respectively. -\\(F\\)is the feed rate of species\\(U\\). -\\(k\\)is the kill rate or removal rate of species\\(V\\). -\\(\\nabla^2\\)represents the Laplacian operator, which accounts for the diffusion process.\nThe Gray-Scott model is motivated by the study of chemical reactions and the spontaneous formation of spatial patterns. Such models are important for understanding a wide range of natural phenomena, including biological pattern formation (like animal coat patterns), chemical oscillations, and ecological systems. The model is particularly noted for its ability to produce complex and diverse patterns from relatively simple equations.\nThe Gray-Scott model is particularly interesting because it can produce a variety of spatial patterns depending on the parameters\\(D_U\\),\\(D_V\\),\\(F\\), and\\(k\\). These patterns can range from spots and stripes to more complex and chaotic structures. The interplay between the reaction kinetics (how\\(U\\)and\\(V\\)react) and the diffusion process (how\\(U\\)and\\(V\\)spread out) leads to the emergence of these patterns.\nShow the code\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef reaction_diffusion(num_iterations, width, height):\n    feed = 0.055\n    kill = 0.062\n    diff_a = 1.0\n    diff_b = 0.5\n\n    a = np.ones((width, height))\n    b = np.zeros((width, height))\n\n    def initialize_pattern(a, b):\n        mid_x, mid_y = width // 2, height // 2\n        a[mid_x-10:mid_x+10, mid_y-10:mid_y+10] = 0.5\n        b[mid_x-10:mid_x+10, mid_y-10:mid_y+10] = 0.25\n    \n    initialize_pattern(a, b)\n\n    def laplacian(mat):\n        return (\n            -mat\n            + 0.2 * (np.roll(mat, 1, axis=0) + np.roll(mat, -1, axis=0) + np.roll(mat, 1, axis=1) + np.roll(mat, -1, axis=1))\n            + 0.05 * (np.roll(mat, (1, 1), axis=(0, 1)) + np.roll(mat, (1, -1), axis=(0, 1)) + np.roll(mat, (-1, 1), axis=(0, 1)) + np.roll(mat, (-1, -1), axis=(0, 1)))\n        )\n\n    for _ in range(num_iterations):\n        a_diff = laplacian(a)\n        b_diff = laplacian(b)\n        reaction = a * b * b\n        a += diff_a * a_diff - reaction + feed * (1 - a)\n        b += diff_b * b_diff + reaction - (kill + feed) * b\n        np.clip(a, 0, 1, out=a)\n        np.clip(b, 0, 1, out=b)\n\n    return a, b\n\nnum_iterations = 6000\nwidth, height = 200, 200\n\na, b = reaction_diffusion(num_iterations, width, height)\n\nplt.figure(figsize=(8, 4))\n\n# Plot for a\nplt.subplot(1, 2, 1)\nplt.imshow(a, cmap='Spectral')\nplt.title('$c_A(t)$')\nplt.axis('off')\n\n# Plot for b\nplt.subplot(1, 2, 2)\nplt.imshow(b, cmap='Spectral')\nplt.title('$c_B(t)$')\nplt.axis('off')\n\nplt.show()",
    "crumbs": [
      "Home",
      "Part 3: Applications",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Partial Differential Equations</span>"
    ]
  },
  {
    "objectID": "08a_partial_differential_equations.html#diffusion-and-reaction-problems",
    "href": "08a_partial_differential_equations.html#diffusion-and-reaction-problems",
    "title": "10  Partial Differential Equations",
    "section": "",
    "text": "Reaction Terms:\n\n\\(-UV^2\\): This term represents the reaction between the two species\\(U\\)and\\(V\\), where\\(U\\)is consumed and\\(V\\)is produced.\n\\(+F(1 - U)\\): This term represents the constant feed of species\\(U\\)into the system, maintaining its availability.\n\\(+UV^2\\): This term in the\\(V\\)equation represents the production of\\(V\\)from the reaction between\\(U\\)and\\(V\\).\n\\(-(F + k)V\\): This term represents the removal of species\\(V\\)from the system, either by natural decay or due to some removal process.\n\nDiffusion Terms:\n\n\\(D_U \\nabla^2 U\\): This term accounts for the diffusion of species\\(U\\)through the medium, allowing it to spread out.\n\\(D_V \\nabla^2 V\\): Similarly, this term accounts for the diffusion of species\\(V\\).\n\n\n\n\nInstability and Turing Patterns: When the parameters are chosen such that the homogeneous steady state becomes unstable, small perturbations grow, leading to the formation of patterns. This is related to Turing’s mechanism for pattern formation, where diffusion-driven instability can cause a uniform state to become unstable and evolve into a patterned state.\nParameter Sensitivity: The specific patterns formed are highly sensitive to the parameters\\(F\\)and\\(k\\). Slight changes in these parameters can result in significantly different patterns, which makes the model both rich and complex.",
    "crumbs": [
      "Home",
      "Part 3: Applications",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Partial Differential Equations</span>"
    ]
  },
  {
    "objectID": "08a_partial_differential_equations.html#wave-propagation-problems",
    "href": "08a_partial_differential_equations.html#wave-propagation-problems",
    "title": "10  Partial Differential Equations",
    "section": "10.2 Wave Propagation Problems",
    "text": "10.2 Wave Propagation Problems\nWave propagation in a medium can be described mathematically by the wave equation. This equation models the behavior of various types of waves, such as sound waves, light waves, and water waves. The wave equation is a second-order partial differential equation that describes how the wave amplitude evolves over time and space.\nWave Equation\nThe general form of the wave equation in a two-dimensional space is given by:\n\\[\\frac{\\partial^2 u}{\\partial t^2} = c^2 \\left( \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} \\right)\\]\nHere: -\\(u(x, y, t)\\)is the wave amplitude at position\\((x, y)\\)and time\\(t\\). -\\(c\\)is the speed of the wave in the medium. -\\(\\frac{\\partial^2 u}{\\partial t^2}\\)is the second partial derivative of\\(u\\)with respect to time, representing the acceleration of the wave. -\\(\\frac{\\partial^2 u}{\\partial x^2}\\)and\\(\\frac{\\partial^2 u}{\\partial y^2}\\)are the second partial derivatives of\\(u\\)with respect to the spatial coordinates, representing the spatial curvature of the wave.\nDiscretization\nTo simulate wave propagation on a computer, we discretize the wave equation using finite differences. The continuous spatial domain is divided into a grid of points, and time is divided into discrete steps.\nFor a grid with spacing\\(\\Delta x\\)and\\(\\Delta y\\)and time steps of size\\(\\Delta t\\), the finite difference approximation of the wave equation is:\n\\[\\frac{\\partial^2 u}{\\partial t^2} \\approx \\frac{u^{n+1}_{i,j} - 2u^n_{i,j} + u^{n-1}_{i,j}}{(\\Delta t)^2}\\]\n\\[\\frac{\\partial^2 u}{\\partial x^2} \\approx \\frac{u^n_{i+1,j} - 2u^n_{i,j} + u^n_{i-1,j}}{(\\Delta x)^2}\\]\n\\[\\frac{\\partial^2 u}{\\partial y^2} \\approx \\frac{u^n_{i,j+1} - 2u^n_{i,j} + u^n_{i,j-1}}{(\\Delta y)^2}\\]\nSubstituting these into the wave equation, we get the finite difference form:\n\\[\\frac{u^{n+1}_{i,j} - 2u^n_{i,j} + u^{n-1}_{i,j}}{(\\Delta t)^2} = c^2 \\left( \\frac{u^n_{i+1,j} - 2u^n_{i,j} + u^n_{i-1,j}}{(\\Delta x)^2} + \\frac{u^n_{i,j+1} - 2u^n_{i,j} + u^n_{i,j-1}}{(\\Delta y)^2} \\right)\\]\nSolving for\\(u^{n+1}_{i,j}\\):\n\\[u^{n+1}_{i,j} = 2u^n_{i,j} - u^{n-1}_{i,j} + \\frac{c^2 \\Delta t^2}{\\Delta x^2} \\left( u^n_{i+1,j} - 2u^n_{i,j} + u^n_{i-1,j} \\right) + \\frac{c^2 \\Delta t^2}{\\Delta y^2} \\left( u^n_{i,j+1} - 2u^n_{i,j} + u^n_{i,j-1} \\right)\\]\nLaplacian Approximation\nThe term\\(\\frac{c^2 \\Delta t^2}{\\Delta x^2} \\left( u^n_{i+1,j} - 2u^n_{i,j} + u^n_{i-1,j} \\right) + \\frac{c^2 \\Delta t^2}{\\Delta y^2} \\left( u^n_{i,j+1} - 2u^n_{i,j} + u^n_{i,j-1} \\right)\\)can be written compactly using the Laplacian operator:\n\\[\\nabla^2 u = \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2}\\]\nSo the finite difference approximation of the Laplacian is:\n\\[\\nabla^2 u \\approx \\frac{u^n_{i+1,j} + u^n_{i-1,j} + u^n_{i,j+1} + u^n_{i,j-1} - 4u^n_{i,j}}{(\\Delta x)^2}\\]\nReflective Boundary Conditions\nReflective boundary conditions are applied to simulate the effect of waves reflecting off the boundaries of the domain. This can be implemented by setting the wave amplitude to zero at the boundaries, which corresponds to a fixed boundary condition:\n\\[u(t, x=0) = u(t, x=L_x) = 0\\] \\[u(t, y=0) = u(t, y=L_y) = 0\\]\nCombining the finite difference approximation and the boundary conditions, the update equation for the wave field at each time step is:\n\\[\nu^{n+1}_{i,j} = 2u^n_{i,j} - u^{n-1}_{i,j} + \\left(\\frac{c \\Delta t}{\\Delta x}\\right)^2 \\left( u^n_{i+1,j} + u^n_{i-1,j} + u^n_{i,j+1} + u^n_{i,j-1} - 4u^n_{i,j} \\right)\n\\]\nThis equation is used in the update_wave function to compute the wave propagation at each time step.\nHere is the Python code implementing the above theory:",
    "crumbs": [
      "Home",
      "Part 3: Applications",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Partial Differential Equations</span>"
    ]
  },
  {
    "objectID": "08a_partial_differential_equations.html#fluid-dynamics-problems",
    "href": "08a_partial_differential_equations.html#fluid-dynamics-problems",
    "title": "10  Partial Differential Equations",
    "section": "10.3 Fluid Dynamics Problems",
    "text": "10.3 Fluid Dynamics Problems",
    "crumbs": [
      "Home",
      "Part 3: Applications",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Partial Differential Equations</span>"
    ]
  },
  {
    "objectID": "09_machine_learning_using_scikitlearn.html",
    "href": "09_machine_learning_using_scikitlearn.html",
    "title": "9  Scikit-Learn for Machine Learning",
    "section": "",
    "text": "9.1 Regression\nRegression is a fundamental concept in machine learning and statistics, primarily used for predicting continuous outcomes. It involves modeling the relationship between a dependent variable (often called the target or output) and one or more independent variables (called features or predictors). The goal of regression is to find a function that best describes the relationship between the input and output data, allowing us to make predictions on new, unseen data points.\nimport numpy as np\n#%matplotlib inline\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Scikit-Learn for Machine Learning</span>"
    ]
  },
  {
    "objectID": "09_machine_learning_using_scikitlearn.html#regression",
    "href": "09_machine_learning_using_scikitlearn.html#regression",
    "title": "9  Scikit-Learn for Machine Learning",
    "section": "",
    "text": "9.1.1 True Physics\nLet us assume that we have the true physical description of the process that relates the input and output data described by a certain function. Usually we do not have this. Here, we are using this just to find out how much far we are from the model that is predicted from just a few observations !\n\n# define the true physical process and draw some data\ninput_start = -1\ninput_end   = 5\n\ninput_true = np.linspace(start=input_start, stop=input_end, num=1000).reshape(-1, 1)\ninput_true.shape\n\n(1000, 1)\n\n\n\noutput_true = np.squeeze(input_true * np.sin(input_true)*np.cos(input_true)*np.tan(input_true))\n\n\noutput_true.shape\n\n(1000,)\n\n\n\nplt.figure(figsize=(3, 3))\nplt.plot(input_true, output_true, label='True Physics', linestyle=\"-\", color='black')\nplt.legend()\nplt.xlabel('input')\nplt.ylabel('output')\nplt.title('True Physics')\n\nText(0.5, 1.0, 'True Physics')\n\n\n\n\n\n\n\n\n\nThe generated true physics is quite complex. It is also strongly non-linear ! Now let us simulate the process of making experiments to generate outputs for a selected few inputs.\n\n\n9.1.2 Experimental measurements\n\navailable_measurements = 10\n\nLet us randomly extract 6 points from the true physical process. This is like performing 10 experiments at different locations. Right now these are random.\n\nrng = np.random.RandomState(0)\nmeasurement_indices = rng.choice(np.arange(input_true.size), size=available_measurements, replace=False)\nmeasurement_indices\n\narray([993, 859, 298, 553, 672, 971,  27, 231, 306, 706])\n\n\nAdd gaussian noise with a given standard deviation\n\nnoise_std = 0.15\n\ninput_measurement = input_true[measurement_indices]\noutput_measurement = output_true[measurement_indices] \ninput_measurement, output_measurement\n\n(array([[ 4.96396396],\n        [ 4.15915916],\n        [ 0.78978979],\n        [ 2.32132132],\n        [ 3.03603604],\n        [ 4.83183183],\n        [-0.83783784],\n        [ 0.38738739],\n        [ 0.83783784],\n        [ 3.24024024]]),\n array([ 4.65636706,  3.01087732,  0.39836331,  1.24154687,  0.03370267,\n         4.76322524, -0.46277436,  0.05528432,  0.46277436,  0.03142975]))\n\n\n\noutput_measurement = output_measurement + rng.normal(loc=0.0, scale=noise_std, size=output_measurement.shape)\n\n\noutput_measurement\n\narray([ 4.72151009,  3.09471209,  0.52477185,  1.45049338,  0.08883534,\n        4.47835002, -0.6925601 ,  0.06668465,  0.38367645,  0.00822619])\n\n\n\nplt.errorbar(input_measurement, output_measurement, noise_std, linestyle='None', color='tab:red', marker='.', \n             markersize=10,label='Measurements')\n\n\nplt.legend()\nplt.xlabel('input')\nplt.ylabel('output')\nplt.title('Measurements')\n\nText(0.5, 1.0, 'Measurements')\n\n\n\n\n\n\n\n\n\n\nCHALLENGE: Using just the above experimental measurements, try to predict the true physics using machine learning!\n\n\n\n9.1.3 Kernel Ridge Regression\nKernel Ridge Regression (KRR) is a versatile and powerful regression technique that combines the advantages of ridge regression and kernel methods. It extends the linear ridge regression model by mapping the input features into a higher-dimensional space using a kernel function, which allows it to capture complex, non-linear relationships between the input variables and the target variable. The kernel function, such as the Gaussian (RBF), polynomial, or linear kernel, plays a crucial role in transforming the data and enabling the model to perform well on a wide range of problems. By incorporating a regularization term in the objective function, KRR mitigates overfitting and enhances the model’s generalization capabilities. This makes it particularly useful in scenarios where the relationship between the predictors and the response variable is highly non-linear, and the risk of overfitting is significant.\n\nfrom sklearn.gaussian_process.kernels import RBF\nkernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))\n\n\noutput_measurement\n\narray([ 4.72151009,  3.09471209,  0.52477185,  1.45049338,  0.08883534,\n        4.47835002, -0.6925601 ,  0.06668465,  0.38367645,  0.00822619])\n\n\n\nfrom sklearn.kernel_ridge import KernelRidge\nkrr = KernelRidge(kernel = kernel, alpha=noise_std**2)\n\nkrr.fit(input_measurement, output_measurement)\n\nKernelRidge(alpha=0.0225, kernel=1**2 * RBF(length_scale=1))In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KernelRidgeKernelRidge(alpha=0.0225, kernel=1**2 * RBF(length_scale=1))\n\n\nMake predictions\n\nnew_input_measurements = np.linspace(input_start, input_end, 20).reshape(-1, 1)\nnew_input_measurements\n\narray([[-1.        ],\n       [-0.68421053],\n       [-0.36842105],\n       [-0.05263158],\n       [ 0.26315789],\n       [ 0.57894737],\n       [ 0.89473684],\n       [ 1.21052632],\n       [ 1.52631579],\n       [ 1.84210526],\n       [ 2.15789474],\n       [ 2.47368421],\n       [ 2.78947368],\n       [ 3.10526316],\n       [ 3.42105263],\n       [ 3.73684211],\n       [ 4.05263158],\n       [ 4.36842105],\n       [ 4.68421053],\n       [ 5.        ]])\n\n\n\noutput_krr_prediction = krr.predict(new_input_measurements)\noutput_krr_prediction\n\narray([-0.70798005, -0.61099339, -0.45894208, -0.28280242, -0.07891206,\n        0.19921947,  0.59910269,  1.09662668,  1.55288221,  1.75860386,\n        1.56486146,  1.01988242,  0.40230558,  0.10014448,  0.39719416,\n        1.30458386,  2.54799936,  3.71159639,  4.43808167,  4.56633603])\n\n\n\n# Plot the results\nplt.figure()\nplt.errorbar(input_measurement, output_measurement, noise_std, linestyle='None', color='tab:red', marker='.', \n             markersize=10,label='Measurements')\nplt.scatter(new_input_measurements, output_krr_prediction, color='green', label='Prediction')\nplt.plot(input_true, output_true, label='True Physics', linestyle=\"-\", color='black')\nplt.xlabel('input')\nplt.ylabel('output')\nplt.title('Kernel Ridge Regression')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n9.1.4 Gaussian Process Regression\nGaussian Process Regression (GPR) is a non-parametric, Bayesian approach to regression that provides a flexible and powerful framework for modeling complex data. Unlike traditional parametric models, GPR does not assume a fixed form for the underlying function, instead, it defines a distribution over possible functions directly. This is achieved through the use of a Gaussian process, which is a collection of random variables, any finite number of which have a joint Gaussian distribution. A key component of GPR is the kernel function, which determines the covariance structure of the data and allows the model to capture intricate patterns and correlations. By integrating out the parameters, GPR naturally incorporates uncertainty in the predictions, offering not only point estimates but also a measure of confidence in these predictions. This probabilistic nature makes GPR particularly well-suited for applications where quantifying uncertainty is important, such as in Bayesian optimization, time-series forecasting, and spatial data analysis. The flexibility and robustness of GPR make it an essential tool for tackling complex regression tasks in various scientific and engineering domains.\n\nfrom sklearn.gaussian_process import GaussianProcessRegressor\n\n\n#help(GaussianProcessRegressor)\ngaussian_process = GaussianProcessRegressor(kernel=kernel, alpha=noise_std**2, n_restarts_optimizer=9)\ngaussian_process.fit(input_measurement, output_measurement)\n\nGaussianProcessRegressor(alpha=0.0225, kernel=1**2 * RBF(length_scale=1),\n                         n_restarts_optimizer=9)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GaussianProcessRegressorGaussianProcessRegressor(alpha=0.0225, kernel=1**2 * RBF(length_scale=1),\n                         n_restarts_optimizer=9)\n\n\nMake predictions\n\nnew_input_measurements = np.linspace(input_start, input_end, 50).reshape(-1, 1)\ngpr_mean_prediction, gpr_std_prediction = gaussian_process.predict(new_input_measurements, return_std=True)\n\n\nplt.plot(input_true, output_true, label='True Physics', linestyle='-', color='black')\nplt.errorbar(input_measurement, output_measurement, noise_std, linestyle='None', color='tab:red', marker='.', \n             markersize=10,label=\"Observations\")\n\nplt.scatter(new_input_measurements, gpr_mean_prediction, label='Mean prediction', color='green')\n\nplt.fill_between(\n    new_input_measurements.ravel(),\n    gpr_mean_prediction - 1.96 * gpr_std_prediction,\n    gpr_mean_prediction + 1.96 * gpr_std_prediction,\n    color='tab:green',\n    alpha=0.5,\n    label=r'95% confidence interval',)\n\nplt.legend()\nplt.xlabel('$input$')\nplt.ylabel('$output$')\nplt.title('Measurements and Model predictions')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n9.1.5 Decision Tree Regression\nDecision Tree Regression is a non-linear regression technique that models the relationship between input features and a continuous target variable through a tree-like structure of decisions. This method involves recursively partitioning the feature space into distinct and non-overlapping regions by making binary decisions at each node of the tree. Each split is chosen to maximize the homogeneity of the target variable within the resulting regions, typically using criteria such as mean squared error reduction. The final prediction is made by averaging the target variable within each region, corresponding to the leaf nodes of the tree. Decision Tree Regression is highly interpretable, as the hierarchical structure of the tree can be easily visualized and understood. It is capable of capturing complex interactions between features without requiring any specific assumptions about the underlying data distribution. However, decision trees can be prone to overfitting, especially when the tree grows too deep, which can be mitigated through techniques like pruning or by using ensemble methods such as Random Forests or Gradient Boosting. This makes Decision Tree Regression a versatile and powerful tool for various regression tasks, particularly when interpretability and the ability to model non-linear relationships are crucial.\n\nfrom sklearn.tree import DecisionTreeRegressor\n\n\n# Fit regression model\ndtr_1 = DecisionTreeRegressor(max_depth=2)\ndtr_2 = DecisionTreeRegressor(max_depth=5)\ndtr_3 = DecisionTreeRegressor(max_depth=7)\n\ndtr_1.fit(input_measurement, output_measurement)\ndtr_2.fit(input_measurement, output_measurement)\ndtr_3.fit(input_measurement, output_measurement)\n\nDecisionTreeRegressor(max_depth=7)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.DecisionTreeRegressorDecisionTreeRegressor(max_depth=7)\n\n\nMake predictions\n\nnew_input_measurements = np.linspace(input_start, input_end, 50).reshape(-1, 1)\n\ndtr_prediction_1 = dtr_1.predict(new_input_measurements)\ndtr_prediction_2 = dtr_2.predict(new_input_measurements)\ndtr_prediction_3 = dtr_3.predict(new_input_measurements)\n\n\n# Plot the results\nplt.figure()\n#plt.plot(input_true, output_true, label='True Physics', linestyle=\"-\", color='black')\nplt.errorbar(input_measurement, output_measurement, noise_std, linestyle='None', color='tab:red', marker='.', \n             markersize=10,label='Measurements')\nplt.plot(new_input_measurements, dtr_prediction_1, color='orange', label='max_depth=2', linewidth=2, linestyle=':')\nplt.plot(new_input_measurements, dtr_prediction_2, color='blue', label='max_depth=5', linewidth=2, linestyle='-.')\nplt.plot(new_input_measurements, dtr_prediction_3, color='green', label='max_depth=7', linewidth=2, linestyle='--')\nplt.xlabel('input')\nplt.ylabel('output')\nplt.title('Decision Tree Regression')\nplt.legend()\nplt.show()",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Scikit-Learn for Machine Learning</span>"
    ]
  },
  {
    "objectID": "09_machine_learning_using_scikitlearn.html#classification",
    "href": "09_machine_learning_using_scikitlearn.html#classification",
    "title": "9  Scikit-Learn for Machine Learning",
    "section": "9.2 Classification",
    "text": "9.2 Classification\nThere are many different classification methods available for classifying datasets. Here are a few examples:\n\nLogistic Regression: A statistical model that predicts the probability of an event occurring, given a set of independent variables.\nDecision Tree: A tree-like model of decisions and their possible consequences, used to classify data by assigning them to one of several categories.\nRandom Forest: An ensemble method that combines multiple decision trees to improve classification accuracy.\nSupport Vector Machines (SVM): A type of supervised learning algorithm that can be used for classification, regression, and outlier detection.\nNaive Bayes: A probabilistic classifier based on Bayes’ theorem that assumes independence between features.\nk-Nearest Neighbors (k-NN): A non-parametric algorithm that classifies data points based on the k closest training examples in the feature space.\nNeural Networks: A machine learning model inspired by the structure and function of the human brain, consisting of interconnected nodes that process information and produce output.\n\n\n# import libraries\nimport numpy as np\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score\n\n\n# generate toy dataset\nX, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=3, random_state=42)\n\n\nX\n\narray([[-2.56891645, -0.25740861, -2.67935708, ..., -1.21337007,\n        -1.47310497, -0.84638564],\n       [ 0.62286056,  0.53454361,  0.01828302, ..., -1.09353229,\n        -0.46979071, -0.18802193],\n       [-0.17125115, -0.49627753,  1.61334708, ...,  0.71453069,\n         3.47599878,  0.6233862 ],\n       ...,\n       [ 1.49733849, -1.14885141, -0.78734187, ..., -0.99204356,\n         0.71868115, -0.45139203],\n       [-0.17397319,  0.16781324,  2.60761116, ..., -0.2693521 ,\n         0.65157292, -0.31914351],\n       [-1.58610983,  0.89359204, -1.30742057, ..., -0.05661209,\n        -0.54079228, -1.0986882 ]])\n\n\n\ny\n\narray([1, 1, 0, 1, 0, 0, 2, 2, 1, 2, 0, 0, 1, 1, 0, 2, 1, 1, 0, 1, 0, 1,\n       1, 2, 0, 1, 2, 1, 2, 0, 2, 0, 0, 1, 0, 1, 2, 2, 0, 1, 1, 2, 0, 0,\n       1, 0, 2, 0, 1, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2, 0, 1, 0, 0, 0, 2, 2,\n       0, 2, 2, 1, 0, 2, 2, 0, 2, 2, 2, 2, 0, 1, 0, 0, 2, 2, 0, 0, 1, 0,\n       2, 2, 0, 0, 0, 2, 0, 2, 2, 2, 0, 1, 1, 2, 2, 1, 0, 0, 2, 0, 1, 1,\n       2, 0, 1, 2, 0, 2, 1, 1, 0, 0, 1, 1, 1, 0, 2, 1, 1, 2, 0, 2, 0, 1,\n       2, 0, 0, 0, 2, 0, 1, 2, 0, 2, 2, 2, 2, 0, 1, 0, 2, 2, 1, 1, 2, 1,\n       1, 0, 0, 1, 0, 1, 2, 2, 0, 0, 1, 2, 0, 2, 2, 1, 1, 1, 2, 1, 1, 1,\n       1, 1, 0, 2, 1, 2, 0, 0, 0, 0, 1, 1, 0, 2, 2, 0, 0, 0, 1, 0, 0, 2,\n       0, 2, 2, 0, 1, 0, 1, 2, 2, 2, 1, 0, 1, 1, 2, 2, 1, 1, 0, 2, 1, 2,\n       0, 2, 1, 0, 2, 2, 0, 1, 0, 0, 2, 0, 1, 1, 1, 2, 0, 1, 0, 2, 1, 2,\n       1, 0, 0, 2, 2, 2, 1, 2, 0, 1, 0, 0, 2, 2, 1, 2, 0, 2, 2, 1, 0, 0,\n       0, 2, 2, 1, 0, 2, 1, 1, 2, 2, 1, 0, 2, 2, 0, 0, 2, 1, 2, 0, 2, 0,\n       2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 2, 1, 0, 0, 2, 0, 0, 0, 2, 2, 2,\n       1, 1, 1, 2, 0, 0, 2, 1, 2, 1, 1, 2, 0, 2, 1, 2, 2, 0, 1, 2, 2, 1,\n       2, 2, 0, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 0, 2, 0, 0, 2, 2, 1, 0, 2,\n       1, 2, 2, 2, 0, 0, 1, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 1, 1, 1, 2, 0,\n       2, 1, 1, 1, 0, 1, 1, 2, 1, 2, 1, 0, 1, 2, 2, 0, 1, 0, 0, 0, 1, 0,\n       2, 0, 2, 2, 1, 2, 1, 2, 0, 1, 2, 2, 2, 1, 0, 1, 0, 2, 1, 1, 0, 0,\n       1, 1, 0, 2, 2, 2, 2, 0, 2, 2, 2, 1, 0, 2, 1, 1, 2, 0, 1, 0, 0, 2,\n       2, 2, 1, 1, 1, 0, 1, 1, 2, 1, 0, 0, 1, 2, 1, 2, 2, 0, 0, 1, 1, 0,\n       1, 0, 2, 1, 2, 1, 0, 0, 2, 1, 0, 2, 2, 0, 2, 2, 1, 1, 0, 1, 2, 1,\n       2, 1, 2, 0, 0, 1, 2, 0, 1, 0, 2, 1, 0, 0, 2, 1, 1, 1, 1, 0, 0, 2,\n       0, 1, 0, 0, 0, 1, 2, 2, 0, 2, 0, 0, 2, 0, 0, 2, 1, 2, 0, 0, 1, 1,\n       1, 0, 0, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 0, 2, 1, 1, 1, 1, 1, 1, 0,\n       2, 2, 2, 0, 1, 1, 1, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 2, 2,\n       1, 2, 0, 2, 1, 2, 0, 1, 0, 2, 0, 1, 0, 1, 0, 2, 2, 2, 2, 0, 2, 1,\n       1, 0, 2, 1, 1, 1, 2, 0, 0, 0, 1, 2, 2, 2, 0, 0, 2, 0, 1, 2, 1, 2,\n       2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 2, 0, 1, 1, 0, 0, 0, 2, 2, 1, 1, 1,\n       1, 1, 2, 2, 0, 2, 2, 0, 1, 1, 0, 2, 1, 0, 0, 2, 2, 0, 0, 0, 1, 2,\n       1, 2, 0, 0, 1, 0, 2, 1, 1, 0, 2, 2, 1, 2, 1, 2, 0, 1, 1, 0, 0, 2,\n       1, 1, 1, 2, 0, 2, 0, 2, 2, 0, 2, 2, 1, 0, 0, 0, 1, 0, 0, 1, 2, 2,\n       2, 2, 0, 0, 2, 0, 2, 2, 0, 2, 2, 1, 1, 2, 0, 0, 1, 0, 1, 1, 1, 1,\n       1, 0, 1, 1, 2, 1, 2, 1, 0, 0, 2, 2, 2, 1, 1, 1, 0, 2, 2, 1, 0, 1,\n       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 2, 1, 1, 2, 2, 1, 0, 2, 0, 1, 1, 1,\n       0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 1, 1, 2, 1, 1, 0, 1, 2, 0, 0, 2, 1,\n       2, 0, 2, 1, 0, 0, 0, 0, 2, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 2,\n       0, 0, 0, 2, 2, 2, 2, 1, 0, 1, 2, 0, 1, 0, 0, 0, 2, 2, 1, 0, 2, 2,\n       2, 1, 2, 1, 1, 1, 0, 1, 2, 2, 0, 0, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1,\n       1, 1, 0, 1, 1, 0, 0, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 0,\n       0, 1, 2, 2, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 2, 0, 1, 0, 0, 0,\n       2, 1, 2, 0, 2, 2, 1, 1, 0, 0, 1, 2, 0, 2, 1, 2, 0, 0, 1, 1, 1, 2,\n       2, 1, 1, 1, 0, 0, 0, 0, 2, 1, 2, 1, 1, 1, 0, 0, 0, 2, 1, 1, 0, 0,\n       0, 2, 0, 1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 0, 2, 2, 2, 0, 0, 2, 0, 2,\n       2, 1, 1, 0, 0, 1, 1, 1, 2, 0, 0, 2, 2, 0, 1, 2, 2, 0, 1, 0, 1, 1,\n       1, 2, 1, 1, 1, 2, 1, 0, 0, 1])\n\n\n\n# split dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n\n# initialize models\nmodels = {\n    'Logistic Reg': LogisticRegression(random_state=42),\n    'Decision Tree': DecisionTreeClassifier(random_state=42),\n    'Random Forest': RandomForestClassifier(random_state=42),\n    'SVM': SVC(random_state=42),\n    'Naive Bayes': GaussianNB(),\n    'k-NN': KNeighborsClassifier(),\n    'Neural Network': MLPClassifier(random_state=42)\n}\n\n\n# fit and evaluate models\nresults = {}\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    results[name] = accuracy\n\n/Users/jt_official/Documents/programming/Python-GIT/.venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning:\n\nStochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n\n\n\n\nresults\n\n{'Logistic Reg': 0.72,\n 'Decision Tree': 0.7766666666666666,\n 'Random Forest': 0.86,\n 'SVM': 0.86,\n 'Naive Bayes': 0.7666666666666667,\n 'k-NN': 0.8433333333333334,\n 'Neural Network': 0.8666666666666667}",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Scikit-Learn for Machine Learning</span>"
    ]
  },
  {
    "objectID": "09_machine_learning_using_scikitlearn.html#unsupervised-learning",
    "href": "09_machine_learning_using_scikitlearn.html#unsupervised-learning",
    "title": "9  Scikit-Learn for Machine Learning",
    "section": "9.3 Unsupervised Learning",
    "text": "9.3 Unsupervised Learning\nUnsupervised learning is a type of machine learning where the algorithm is trained on unlabeled data. Unlike supervised learning, unsupervised learning doesn’t have a predefined target variable, which means that the algorithm tries to find patterns and relationships in the data without any explicit guidance.\nThe goal of unsupervised learning is to identify hidden structures or groupings in the data, which can help in data exploration and feature extraction. Unsupervised learning algorithms work by clustering similar data points together, based on the underlying structure or distribution of the data.\nOne popular unsupervised learning algorithm is k-means clustering, which involves dividing a dataset into k clusters, based on the similarity of their features. Another example is principal component analysis (PCA), which is used to reduce the dimensionality of high-dimensional data by finding the most important features that explain the majority of the variation in the data.\nUnsupervised learning has several advantages, including the ability to discover hidden patterns and relationships in the data, without the need for explicit labels or target variables. It can also help in feature selection and data compression, which can be useful for reducing the computational complexity of machine learning algorithms.\nUnsupervised learning is widely used in many applications, including image segmentation, anomaly detection, and market segmentation. It is a powerful technique for exploring and understanding complex datasets, without the need for human supervision or guidance.\n\n9.3.1 Clustering\nThere are many methods for clustering using Python, here are some of the most popular ones:\n\nK-Means Clustering: It is a popular unsupervised machine learning algorithm that partitions data points into K clusters based on similarity. The K-Means algorithm aims to minimize the sum of squared distances between data points and their respective cluster centers. The Scikit-learn library provides an implementation of K-Means clustering in Python.\nHierarchical Clustering: This algorithm builds a hierarchy of clusters by either merging smaller clusters into larger ones (agglomerative) or splitting larger clusters into smaller ones (divisive). The hierarchy can be represented as a tree-like diagram called a dendrogram. The Scikit-learn library provides an implementation of hierarchical clustering in Python.\nDBSCAN Clustering: This algorithm groups together points that are closely packed together while leaving out points that are far away from the clusters. The algorithm does not require specifying the number of clusters beforehand, and it can handle noisy data. The Scikit-learn library provides an implementation of DBSCAN clustering in Python.\nGaussian Mixture Model (GMM) Clustering: This algorithm models the probability distribution of the data using a mixture of Gaussian distributions. The algorithm determines the optimal number of clusters and their parameters by maximizing the likelihood of the data. The Scikit-learn library provides an implementation of GMM clustering in Python.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\nfrom sklearn.mixture import GaussianMixture\n\n\n# Generate a toy dataset with 100 data points and 5 clusters\nX, y = make_blobs(n_samples=100, centers=5, random_state=42)\n\n\nX\n\narray([[ -6.2927701 ,  -4.68965397],\n       [  2.03530213,   5.61498563],\n       [ -2.97261532,   8.54855637],\n       [  0.64463087,   3.22362652],\n       [ -8.73867639,   6.82004726],\n       [ -7.22234171,  -7.68238686],\n       [  5.00151486,   1.32804993],\n       [  4.1607046 ,   1.78751071],\n       [  4.6040528 ,   3.53781334],\n       [ -3.10983631,   8.72259238],\n       [ -3.6601912 ,   9.38998415],\n       [ -6.87451373,  -7.11469673],\n       [  1.17550652,   2.64660433],\n       [ -2.62484591,   8.71318243],\n       [  5.45240466,   3.32940971],\n       [ -8.31638619,   7.62050759],\n       [  1.57578528,   5.01785035],\n       [  0.95140774,   4.64392397],\n       [ -7.40938739,  -6.36684216],\n       [ -6.97255325,   7.79735584],\n       [ -7.87495163,   7.73630384],\n       [  6.11777288,   1.45489947],\n       [ -2.26723535,   7.10100588],\n       [ -5.73680438,  -6.12817656],\n       [ -9.81300943,   8.11060752],\n       [ -7.67973218,   6.5028406 ],\n       [  2.08050895,   3.01848126],\n       [  1.13278581,   3.34564127],\n       [  2.19548116,   4.54676894],\n       [  4.98349713,   0.21012953],\n       [ -4.99344129,  -6.70553178],\n       [ -8.61086782,   8.63066567],\n       [  1.77691212,   3.40771539],\n       [  1.1384428 ,   4.31517666],\n       [  2.02013373,   2.79507219],\n       [ -8.54525528,   6.6091715 ],\n       [ -2.97867201,   9.55684617],\n       [ -3.11090424,  10.86656431],\n       [ -3.05358035,   9.12520872],\n       [  3.96295684,   2.58484597],\n       [ -7.58168029,  -7.20777174],\n       [  4.42020695,   2.33028226],\n       [  4.97114227,   2.94871481],\n       [  3.53354386,   0.77696306],\n       [ -8.57844496,   8.10534579],\n       [ -1.77073104,   9.18565441],\n       [ -3.98771961,   8.29444192],\n       [ -6.91433896,  -8.04878763],\n       [ -8.58783491,   7.66997112],\n       [  3.10535148,   5.21525361],\n       [  1.79883745,   4.87545205],\n       [  5.55528095,   2.30192079],\n       [  4.7269259 ,   1.67416233],\n       [ -8.29499793,  -7.30075492],\n       [  4.56786871,   2.97670258],\n       [ -9.51835248,   7.55577661],\n       [  2.29899103,   4.9886348 ],\n       [  2.23639398,   2.91571278],\n       [ -3.4172217 ,   7.60198243],\n       [ -4.23411546,   8.4519986 ],\n       [  3.83138523,   1.47141264],\n       [ -3.52202874,   9.32853346],\n       [ -9.75775199,   8.87345732],\n       [ -7.27173534,  -8.34362454],\n       [-10.44581099,   7.50815677],\n       [ -6.81939698,  -4.41686748],\n       [  2.49553786,   4.08862264],\n       [  2.3800876 ,   4.72223608],\n       [ -7.07198816,  -6.57856225],\n       [  1.7576434 ,   6.88162072],\n       [-10.07527847,   6.0030663 ],\n       [ -6.78254964,  -5.9114646 ],\n       [ -8.79839841,  -6.90662347],\n       [ -7.0409129 ,  -6.47605874],\n       [  2.64796758,   3.304294  ],\n       [ -8.0162676 ,   9.2203159 ],\n       [  4.96396281,   1.5880874 ],\n       [-10.38899119,   7.39208589],\n       [  1.94519853,   4.50260353],\n       [ -5.47683288,  -8.28196066],\n       [  2.5373355 ,   4.67523751],\n       [ -6.6220768 ,  -6.95455551],\n       [ -9.90063147,   7.79711535],\n       [  5.00127444,   3.51120625],\n       [ -8.02481054,   6.0926586 ],\n       [ -2.30033403,   7.054616  ],\n       [-10.02963125,   7.98007652],\n       [ -1.68665271,   7.79344248],\n       [ -3.83738367,   9.21114736],\n       [ -2.44166942,   7.58953794],\n       [ -9.62158105,   7.0014614 ],\n       [ -2.96983639,  10.07140835],\n       [ -6.58350691,  -6.61905432],\n       [  4.73163961,  -0.01439923],\n       [ -6.08859524,  -7.78949705],\n       [ -1.04354885,   8.78850983],\n       [ -7.87016352,  -7.44640732],\n       [ -2.52269485,   7.9565752 ],\n       [  5.67087836,   2.9044498 ],\n       [  3.80066131,   1.66395731]])\n\n\n\ny\n\narray([2, 4, 0, 4, 3, 2, 1, 1, 1, 0, 0, 2, 4, 0, 1, 3, 4, 4, 2, 3, 3, 1,\n       0, 2, 3, 3, 4, 4, 4, 1, 2, 3, 4, 4, 1, 3, 0, 0, 0, 1, 2, 1, 1, 1,\n       3, 0, 0, 2, 3, 4, 4, 1, 1, 2, 1, 3, 4, 4, 0, 0, 1, 0, 3, 2, 3, 2,\n       4, 4, 2, 4, 3, 2, 2, 2, 4, 3, 1, 3, 4, 2, 4, 2, 3, 1, 3, 0, 3, 0,\n       0, 0, 3, 0, 2, 1, 2, 0, 2, 0, 1, 1])\n\n\n\n# Perform K-Means clustering\nkmeans = KMeans(n_clusters=5, random_state=42)\nkmeans_labels = kmeans.fit_predict(X)\n\n# Perform Hierarchical clustering\nhierarchical = AgglomerativeClustering(n_clusters=3)\nhierarchical_labels = hierarchical.fit_predict(X)\n\n# Perform DBSCAN clustering\ndbscan = DBSCAN(eps=0.5, min_samples=5)\ndbscan_labels = dbscan.fit_predict(X)\n\n# Perform GMM clustering\ngmm = GaussianMixture(n_components=3)\ngmm_labels = gmm.fit_predict(X)\n\n/Users/jt_official/Documents/programming/Python-GIT/.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning:\n\nThe default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n\n\n\n\nkmeans_labels\n\narray([1, 4, 3, 4, 2, 1, 0, 0, 0, 3, 3, 1, 4, 3, 0, 2, 4, 4, 1, 2, 2, 0,\n       3, 1, 2, 2, 4, 4, 4, 0, 1, 2, 4, 4, 4, 2, 3, 3, 3, 0, 1, 0, 0, 0,\n       2, 3, 3, 1, 2, 4, 4, 0, 0, 1, 0, 2, 4, 4, 3, 3, 0, 3, 2, 1, 2, 1,\n       4, 4, 1, 4, 2, 1, 1, 1, 4, 2, 0, 2, 4, 1, 4, 1, 2, 0, 2, 3, 2, 3,\n       3, 3, 2, 3, 1, 0, 1, 3, 1, 3, 0, 0], dtype=int32)\n\n\n\n# Plot the clustering results\nplt.figure(figsize=(15, 4))\nplt.subplot(141)\nplt.scatter(X[:, 0], X[:, 1], c=kmeans_labels)\nplt.title('K-Means')\nplt.subplot(142)\nplt.scatter(X[:, 0], X[:, 1], c=hierarchical_labels)\nplt.title('Hierarchical')\nplt.subplot(143)\nplt.scatter(X[:, 0], X[:, 1], c=dbscan_labels)\nplt.title('DBSCAN')\nplt.subplot(144)\nplt.scatter(X[:, 0], X[:, 1], c=gmm_labels)\nplt.title('GMM')\nplt.show()",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Scikit-Learn for Machine Learning</span>"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Since 2021, the contents of this e-book has been offered as a short intensive course to PhD students at the Technical University of Munich (TUM) every semester. The course is updated every semester and please check back for the latest version. The course is designed to help students learn Python programming in a very short period and apply it to their research\nThe author is a Computational Engineer at the Centre for Building Materials, the Technical University of Munich. He has published over 80 scientific articles on computational modeling of materials and structures. His research focusses on the development and application of methods for multiscale modeling and simulation of materials and structures.",
    "crumbs": [
      "Home",
      "About"
    ]
  },
  {
    "objectID": "01_introduction.html",
    "href": "01_introduction.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Programming\nBefore we dive into Python specifically, let’s first discuss how programs work in general.\nProgramming languages can be classified into two categories:\nPython is a high-level language, which means that it is more abstract than low-level languages such as assembly or machine code. This abstraction makes it easier to write and read Python code, but it also means that Python programs may run slower than programs written in lower-level languages.\nPython programs are typically executed using an interpreter. An interpreter is a program that reads and executes code written in a particular programming language. The Python interpreter is installed on most modern computers, so you don’t need to install anything special to run Python code.\nWhen you write a Python program, you save it in a text file with a .py extension. This file contains the code that the Python interpreter will execute. To run the program, you simply type python followed by the name of the file in the command line.\nPython code can also be compiled into a binary executable file, which can be run directly without the need for an interpreter. However, this is less common than using the interpreter, especially for small programs.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_introduction.html#programming",
    "href": "01_introduction.html#programming",
    "title": "1  Introduction",
    "section": "",
    "text": "A program is simply a set of instructions that a computer can follow to perform a specific task.\nThese instructions are written in a programming language, such as Python.\n\n\n\nhigh-level languages and low-level languages.\nHigh-level languages are designed to be easier for humans to read and write, while low-level languages are closer to the machine language that a computer understands.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_introduction.html#jupyter-notebook",
    "href": "01_introduction.html#jupyter-notebook",
    "title": "1  Introduction",
    "section": "1.2 Jupyter Notebook",
    "text": "1.2 Jupyter Notebook\nJupyter Notebook is an interactive computing environment that allows you to create and share documents that contain live code, equations, visualizations, and narrative text. It is widely used for data science, machine learning, and scientific computing because of its ability to combine code, text, and visualizations in one place.\nIn Jupyter Notebook, code is executed in a separate process called a kernel. When you run a code cell, the code is sent to the kernel for execution. The kernel runs the code and sends the output back to the Notebook interface, where it is displayed. The kernel can be connected to different programming languages such as Python, R, Julia, and many more.\n\n\nJupyter Notebook Interface\n\n\n\nWhen you open a Jupyter Notebook, you are actually launching a web application that communicates with the kernel running in the background. The Notebook interface provides a web-based environment where you can create and edit notebooks, run code, and visualize the output.\nOne of the main advantages of using Jupyter Notebook is that you can edit and run code in small chunks, called cells. This allows you to test and debug your code incrementally, which can save you a lot of time and effort in the long run. You can also add narrative text, equations, and visualizations to your notebook to help explain your thought process and results.\nJupyter Notebook supports a wide variety of programming languages, and you can switch between them by selecting the appropriate kernel for your notebook. Each kernel has its own set of commands and syntax, but the overall Notebook interface remains the same.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_introduction.html#kernel-vs-interpreter",
    "href": "01_introduction.html#kernel-vs-interpreter",
    "title": "1  Introduction",
    "section": "1.3 Kernel vs Interpreter",
    "text": "1.3 Kernel vs Interpreter\nAn interpreter and a kernel are two different components of a programming environment, and they serve different purposes.\nAn interpreter is a program that reads and executes code written in a particular programming language. It takes source code as input and runs it directly, interpreting each line of code as it encounters it. Interpreters are commonly used in scripting languages like Python, Perl, and Ruby, where code is typically executed line-by-line rather than compiled into a binary executable. When you run a Python program using an interpreter, the interpreter reads the source code and executes it directly, without the need for compilation. On the other hand, a kernel is a program that provides an execution environment for a particular programming language. It communicates with the application or interface that hosts it and manages the execution of code within that environment. In the context of Jupyter Notebook, a kernel is a separate process that runs the code you write in a notebook cell. When you run a cell in Jupyter Notebook, the code in the cell is sent to the kernel for execution, and the results are returned to the notebook interface.\n\n\n\n\n\nflowchart LR\n      A1[Start: User Input] --&gt; B1[Kernel Receives Input]\n      B1 --&gt; C1[Kernel Parses Input]\n      C1 --&gt; D1[Kernel Executes Code]\n      D1 --&gt; E1[Kernel Sends Output]\n      E1 --&gt; F1[Display Output to User]\n\n\n\n\n\n\nSo, while both an interpreter and a kernel are involved in the execution of code, they operate at different levels of abstraction. An interpreter is responsible for executing code line-by-line, while a kernel provides a runtime environment for executing code within an application or interface. Interpreters are typically used with scripting languages, while kernels are commonly used with interactive computing environments like Jupyter Notebook.\n\n\n\n\n\nflowchart LR\n      A2[Start: User Input] --&gt; B2[Interpreter Receives Input]\n      B2 --&gt; C2[Interpreter Parses Input]\n      C2 --&gt; D2[Interpreter Executes Code]\n      D2 --&gt; E2[Display Output to User]\n\n\n\n\n\n\nIn the context of computing, a kernel is a program or a part of an operating system that serves as a bridge between software and hardware. It provides an abstraction layer that allows software to interact with hardware without having to worry about the specifics of the underlying hardware.\nIn the context of Jupyter Notebook, a kernel is a program that provides an execution environment for a particular programming language. It is responsible for interpreting and executing code written in that language, managing variables and memory, and returning results to the notebook interface. Each kernel runs in a separate process, isolated from the rest of the system, which makes it more secure and stable.\nAn execution environment is a runtime environment in which code is executed. It includes all the resources needed for the code to run, such as memory, processor time, and input/output devices. The execution environment manages the allocation of these resources to the code as it runs, ensuring that it has everything it needs to complete its task.\nIn the context of Jupyter Notebook, the kernel provides the execution environment for the code you write in a notebook cell. When you run a cell, the code is sent to the kernel for execution, and the kernel manages the resources needed to execute the code. It keeps track of variables and their values, manages memory, and ensures that the code has access to any necessary libraries or modules.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_introduction.html#anatomy-of-a-python-program",
    "href": "01_introduction.html#anatomy-of-a-python-program",
    "title": "1  Introduction",
    "section": "1.4 Anatomy of a Python Program",
    "text": "1.4 Anatomy of a Python Program\nLet us look at a fully functional Python program. Here’s a Python code that generates a contour plot using the libraries (in python called packages) Matplotlib and NumPy: This code generates a contour plot of the function \\(\\sin(x^2 + y^2)\\) with 20 contour levels and uses the ‘viridis’ colormap, which is aesthetically pleasing and perceptually uniform. The plot includes axis labels and a title for better understanding.\n\n\nShow the code\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Create a grid of points\nx = np.linspace(-3, 3, 400)\ny = np.linspace(-3, 3, 400)\nX, Y = np.meshgrid(x, y)\n\n# Define a function for the contour plot\nZ = np.sin(X**2 + Y**2)\n\n# Create the figure\nplt.figure(figsize=(8, 6))\n\n# Display the image with a continuous color representation\nim = plt.imshow(Z, extent=[-3, 3, -3, 3], origin='lower', cmap='Spectral', alpha=0.8)\n\n# Create the contour plot\ncontour = plt.contour(X, Y, Z, levels=10, cmap='Spectral')\n\n# Add a colorbar for reference\ncbar = plt.colorbar(im, label='Z values')\n\n# Set labels and title\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\n\n# Show the plot\nplt.show()\n\n\n\n\nSin plot in polar coordinates\n\n\n\n\n\n\nImport Necessary Libraries:\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnumpy is a library used for numerical operations in Python, especially with arrays and matrices.\nmatplotlib.pyplot is a plotting library used for creating static, interactive, and animated visualizations in Python.\n\nCreate a Grid of Points:\nx = np.linspace(-3, 3, 400)\ny = np.linspace(-3, 3, 400)\nX, Y = np.meshgrid(x, y)\n\nnp.linspace(-3, 3, 400) generates 400 evenly spaced points between -3 and 3. This is done for both x and y to cover a range of values.\nnp.meshgrid(x, y) creates a grid of coordinates based on the x and y arrays. X and Y are matrices containing the x and y coordinates of each point in the grid, respectively.\n\nDefine a Function for the Contour Plot:\nZ = np.sin(X**2 + Y**2)\n\nThis defines a function \\(Z = \\sin(X^2 + Y^2)\\), which will be used to generate the contour plot. ** denotes exponentiation in Python.\n\nCreate the Contour Plot:\nplt.figure(figsize=(8, 6))\ncontour = plt.contour(X, Y, Z, levels=20, cmap='Spectral')\n\nplt.figure(figsize=(8, 6)) creates a new figure for plotting with a specified size (8 inches by 6 inches).\nplt.contour(X, Y, Z, levels=20, cmap='viridis') creates a contour plot using the X, Y, and Z matrices. levels=20 specifies that the plot should have 20 contour levels. cmap='viridis' specifies the colormap to use, which determines the colors of the contours.\n\nAdd a Colorbar for Reference:\nplt.colorbar(contour)\n\nplt.colorbar(contour) adds a colorbar to the plot, which provides a reference for the contour levels and their corresponding colors.\n\nSet Labels and Title:\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\n\nplt.xlabel('X-axis') and plt.ylabel('Y-axis') set the labels for the x and y axes.\nplt.title('Aesthetically Pleasing Contour Plot') sets the title of the plot.\n\nShow the Plot:\nplt.show()\n\nplt.show() displays the plot on the screen.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_introduction.html#coding-conventions",
    "href": "01_introduction.html#coding-conventions",
    "title": "1  Introduction",
    "section": "1.5 Coding Conventions",
    "text": "1.5 Coding Conventions\nThere are several coding conventions that are widely followed when programming in Python. The most important of these is the Python Enhancement Proposal (PEP) 8, which provides a set of guidelines for writing Python code that is easy to read, maintain, and understand. Here are some of the key coding conventions to keep in mind when programming in Python:\n\n\n\n\n\n\nImportant Conventions\n\n\n\n\nUse four spaces to indent code blocks. Do not use tabs.\nUse lowercase letters and underscores to name variables, functions, and modules.\nUse single quotes to enclose string literals, except when a string contains a single quote.\nUse descriptive and meaningful names for variables, functions, and classes.\nAvoid using single-character variable names, except for variables that represent mathematical values.\nWrite comments to explain your code and make it more readable.\nUse whitespace to make your code more readable. For example, put spaces around operators and after commas in function arguments.\nFollow the PEP 8 style guide for the layout and formatting of your code.\nUse consistent naming conventions for classes, with each word capitalized, and no underscores.\nAlways use parentheses to indicate the order of operations in expressions, even when they are not strictly necessary.\n\n\n\nThese are just a few of the coding conventions that are typically followed when programming in Python. Adhering to these conventions will help make your code more readable, easier to maintain, and more consistent with the wider Python community.\nFour spaces are preferred over tabs in Python because Python relies on indentation to define code blocks, such as loops, functions, and conditional statements. Consistency in indentation is crucial in Python code to make it more readable and easier to understand. The problem with using tabs for indentation is that the actual width of a tab can vary between different text editors and environments. In some cases, a tab might take up four spaces, while in others, it might take up eight spaces or more. This can lead to inconsistencies in the way code is indented, making it harder to read and understand. On the other hand, using four spaces ensures a consistent and predictable indentation size, regardless of the text editor or environment being used. This makes the code more readable and easier to maintain, especially when different programmers are working on the same codebase.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_introduction.html#further-reading",
    "href": "01_introduction.html#further-reading",
    "title": "1  Introduction",
    "section": "1.6 Further Reading",
    "text": "1.6 Further Reading\n\nhttps://www.python.org\nhttps://peps.python.org/pep-0020/",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "02_representing_data.html",
    "href": "02_representing_data.html",
    "title": "2  Data Representation",
    "section": "",
    "text": "Data Types",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Representation</span>"
    ]
  },
  {
    "objectID": "02_representing_data.html#data-and-variables",
    "href": "02_representing_data.html#data-and-variables",
    "title": "2  Data Representation",
    "section": "2.1 Data and Variables",
    "text": "2.1 Data and Variables\nData is the main ingredient in programming. This data is information. In general, a software program (also called code) involves processing data. Essentially, this data has to be input into the computer. Inside the computer, in a high-level programming language like Python, the data is given a name and this name is linked to the memory location of the data. These names can only contain alphanumeric characters (letters and numbers) and underscores. However, the first character of the name must be a letter or underscore. Spaces within a variable name are not permitted, and the variable names are case-sensitive (e.g., a and A will be considered different variables) !\nIn the following example, assume we have a certain number of experimental specimens with a value of 10 ! Let us assign this data a name called n_specimens !\n\nn_specimens = 10\n\n\nn_specimens\n\n10\n\n\nNow let us check if indeed the name n_specimens points to the data 10\n\nprint(n_specimens)\n\n10\n\n\nNow in case we have recieved information that the data has changed (e.g. miscommunication, failed specimens etc.), we do not have to create a new name. In case the number of specimens has increased by 5, then we can update this information as follows:\n\nn_specimens = n_specimens + 5\n\nWe can check if the value has been updated !\n\nn_specimens\n\n15\n\n\nAs the data i.e information that the name ‘n_specimens’ represents can vary, this is called a variable ! Henceforth in programming, a variable ‘contains’ data. You can remove a variable from the notebook using the del function. Typing del n_specimens will clear the variable n_specimens from the workspace. If you want to remove all the variables in the notebook, you can use the magic command %reset. This is unique to Jupyter. In case you use Spyder or another IDE, these commands are not valid.\n\n\n\n\n\n\nNote\n\n\n\nThe mathematical equation x=x+1 has no solution for any value of x. In programming, if we initialize the value of x to be 1, then the statement makes perfect sense. It means, “Add x and 1, which is 2, then assign that value to the variable x”. Note that this operation overwrites the previous value stored in x.\n\n\nThe Jupyter Notebook has its data list to store all the variables in the notebook. As a result of the previous example, you will see the variable ‘n_specimens’ in this data list. You can view a list of all the variables in the notebook using the magic command %whos.\n\n%whos\n\nVariable        Type                       Data/Info\n----------------------------------------------------\nLogNorm         type                       &lt;class 'matplotlib.colors.LogNorm'&gt;\nax              Axes                       Axes(0.125,0.11;0.62x0.77)\ncm              module                     &lt;module 'matplotlib.cm' f&lt;...&gt;ckages/matplotlib/cm.py'&gt;\ncmap            LinearSegmentedColormap    &lt;matplotlib.colors.Linear&lt;...&gt;ap object at 0x1213fd150&gt;\nfig             Figure                     Figure(1056x480)\ni               int                        201\nn_specimens     int                        15\nnorm            LogNorm                    &lt;matplotlib.colors.LogNorm object at 0x131b9fd10&gt;\nnp              module                     &lt;module 'numpy' from '/Us&lt;...&gt;kages/numpy/__init__.py'&gt;\nojs_define      function                   &lt;function ojs_define at 0x137c55800&gt;\nplt             module                     &lt;module 'matplotlib.pyplo&lt;...&gt;es/matplotlib/pyplot.py'&gt;\nprices_per_gb   ndarray                    203: 203 elems, type `float64`, 1624 bytes\nsm              ScalarMappable             &lt;matplotlib.cm.ScalarMapp&lt;...&gt;le object at 0x140359610&gt;\nyears           ndarray                    203: 203 elems, type `float64`, 1624 bytes\n\n\n\n\n\n\n\n\nCaution!\n\n\n\nYou can overwrite variables or functions that have been stored in Python.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Representation</span>"
    ]
  },
  {
    "objectID": "02_representing_data.html#data-types-and-data-structures",
    "href": "02_representing_data.html#data-types-and-data-structures",
    "title": "2  Data Representation",
    "section": "2.2 Data Types and Data Structures",
    "text": "2.2 Data Types and Data Structures\nFrom a computational point of view, it would be efficient if the information regarding the type of data is also included in the variable. The reason this information is required is because the data that the variable contains can vary. Hence this variable should be able to accomodate the possible variations. For example, an integer variable requires lesser memory than a real number. Hence, including this information is essential for storing and processing data. In python, the data type is automatically specified during variable creation. The basic data types are boolean, int, float, string, list, tuple, dictionary, set.\nLet us create an integer and a real number !\n\nan_integer = 1\na_real_number = 1.0\n\n\n%whos\n\nVariable        Type                       Data/Info\n----------------------------------------------------\nLogNorm         type                       &lt;class 'matplotlib.colors.LogNorm'&gt;\na_real_number   float                      1.0\nan_integer      int                        1\nax              Axes                       Axes(0.125,0.11;0.62x0.77)\ncm              module                     &lt;module 'matplotlib.cm' f&lt;...&gt;ckages/matplotlib/cm.py'&gt;\ncmap            LinearSegmentedColormap    &lt;matplotlib.colors.Linear&lt;...&gt;ap object at 0x1213fd150&gt;\nfig             Figure                     Figure(1056x480)\ni               int                        201\nn_specimens     int                        15\nnorm            LogNorm                    &lt;matplotlib.colors.LogNorm object at 0x131b9fd10&gt;\nnp              module                     &lt;module 'numpy' from '/Us&lt;...&gt;kages/numpy/__init__.py'&gt;\nojs_define      function                   &lt;function ojs_define at 0x137c55800&gt;\nplt             module                     &lt;module 'matplotlib.pyplo&lt;...&gt;es/matplotlib/pyplot.py'&gt;\nprices_per_gb   ndarray                    203: 203 elems, type `float64`, 1624 bytes\nsm              ScalarMappable             &lt;matplotlib.cm.ScalarMapp&lt;...&gt;le object at 0x140359610&gt;\nyears           ndarray                    203: 203 elems, type `float64`, 1624 bytes\n\n\nAs you can see, the type of a_real_number is float. Float is a type of data that can include decimal values. Given a variable, the type can be extracted using the function type().\n\ntype(an_integer)\n\nint\n\n\n\n2.2.1 Numeric\nThere are three numeric data types: integers, floating point numbers, and complex numbers. Information about the precision and internal representation of floating point numbers for the machine on which your program is running is available in sys.float_info. Complex numbers have a real and imaginary part, which are each a floating point number. To extract these parts from a complex number z, use z.real and z.imag.\nTo Summarize:\n\nint - holds signed integers.\nfloat- holds floating precision numbers and it’s accurate up to 15 decimal places.\ncomplex - holds complex numbers (with float representations of the real and imaginary part).\n\nThe constructors int(), float(), and complex() can be used to produce numbers of a specific type.\n\nimport sys\nsys.float_info\n\nsys.float_info(max=1.7976931348623157e+308, max_exp=1024, max_10_exp=308, min=2.2250738585072014e-308, min_exp=-1021, min_10_exp=-307, dig=15, mant_dig=53, epsilon=2.220446049250313e-16, radix=2, rounds=1)\n\n\nBecause we are limited by the resolution of the maschine to represent data, we are limited to what we can represent. In the above output from python, epsilon refers to the smallest resolution of the machine. This means that a value \\(\\delta = a-b &lt; epsilon / 2\\) cannot be represented.\nWe can test this using the following code !\n\n1 == 1\n\nTrue\n\n\n\n1*10**-16 + 1 == 1\n\nTrue\n\n\n\n0.7*2.220446049250313*10**-16 + 1 == 1\n\nFalse\n\n\nAll numeric types support the following operations:\n\n\n\n\n\n\n\nOperation\nResult\n\n\n\n\nx + y\nsum of x and y\n\n\nx - y\ndifference of x and y\n\n\nx * y\nproduct of x and y\n\n\nx / y\nquotient of x and y\n\n\nx // y\nfloored quotient of x and y\n\n\nx % y\nremainder of x / y\n\n\n-x\nx negated\n\n\n+x\nx unchanged\n\n\nabs(x)\nabsolute value or magnitude of x\n\n\nint(x)\nx converted to integer\n\n\nfloat(x)\nx converted to floating point\n\n\ncomplex(re, im)\na complex number with real part re, imaginary part im. im defaults to zero.\n\n\nc.conjugate()\nconjugate of the complex number c\n\n\ndivmod(x, y)\nthe pair (x // y, x % y)\n\n\npow(x, y)\nx to the power y\n\n\nx ** y\nx to the power y\n\n\n\nPlease note that the complex type does not support % and // operations !\n\n\n2.2.2 Boolean\nOne of the key components of programming is the use of testing the truth value of certain operations. The data type used to represent this is the bool data type. Boolean variable can either be True or False. Numeric data types can be converted to boolean data type using the bool() function. Except the value 0, all other numerical values would give True.\n\nstart_experiment = True # initializing a boolean variable\nspecimen_indicator = bool(n_specimens) # converting numeric to boolean type\nspecimen_indicator\n\nTrue\n\n\n\nprint(specimen_indicator)\n\nTrue\n\n\n\nbool(0)\n\nFalse\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThe keywords True and False must have an Upper Case first letter. Using a lowercase true returns an error.\n\n\nBoolean arithmetic is the arithmetic of true and false logic. A boolean or logical value can either be True or False. Boolean operators in Python include and, or, and not.\nThe boolean operators in Python are given below:\n\nor\nand\nnot\n== (equivalent)\n!= (not equivalent)\n\nGiven two boolean variables a and b, the following results are obtained for the aformentioned boolean logic !\n\n\n\na\nb\nnot a\nnot b\na == b\na != b\na or b\na and b\n\n\n\n\nT\nF\nF\nT\nF\nT\nT\nF\n\n\nF\nT\nT\nF\nF\nT\nT\nF\n\n\nT\nT\nF\nF\nT\nF\nT\nT\n\n\nF\nF\nT\nT\nT\nF\nF\nF\n\n\n\nTry it out: Test the boolean arithmetic for yourself.\n\n\n2.2.3 Strings\nAn important data type for representing textual data, especially when processing files etc. is the string data type. Strings can be sequences of letters, numbers, symbols, and spaces. In Python, strings can be almost any length and can also contain spaces. Strings are immutable, which means that you cannot change their characters. To create a string in Python, you can use single quotes (’’), double quotes (““) or triple quotes (”““).\n\nfilename = 'database_xmcv_21.csv'\nprint(filename)\n\ndatabase_xmcv_21.csv\n\n\n\ntype(filename)\n\nstr\n\n\nOne of the frequently used operation on strings is indexing and slicing. This is used to extract and manipulate string data.\n\nfilename[0] # first symbol\n\n'd'\n\n\n\nfilename[1] # second symbol\n\n'a'\n\n\n\nfilename[-2] # last symbol\n\n's'\n\n\n\nfilename[0:16:3] # [start:stop:step]\n\n'dasxv1'\n\n\n\nfilename[::-1] # reverse text\n\n'vsc.12_vcmx_esabatad'\n\n\n\nfilename.center(100)\n\n'                                        database_xmcv_21.csv                                        '\n\n\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\ncapitalize()\nConverts the first character to upper case\n\n\ncasefold()\nConverts string into lower case\n\n\ncenter()\nReturns a centered string\n\n\ncount()\nReturns the number of times a specified value occurs in a string\n\n\nencode()\nReturns an encoded version of the string\n\n\nendswith()\nReturns true if the string ends with the specified value\n\n\nexpandtabs()\nSets the tab size of the string\n\n\nfind()\nSearches the string for a specified value and returns the position of where it was found\n\n\nformat()\nFormats specified values in a string\n\n\nformat_map()\nFormats specified values in a string\n\n\nindex()\nSearches the string for a specified value and returns the position of where it was found\n\n\nisalnum()\nReturns True if all characters in the string are alphanumeric\n\n\nisalpha()\nReturns True if all characters in the string are in the alphabet\n\n\nisascii()\nReturns True if all characters in the string are ascii characters\n\n\nisdecimal()\nReturns True if all characters in the string are decimals\n\n\nisdigit()\nReturns True if all characters in the string are digits\n\n\nisidentifier()\nReturns True if the string is an identifier\n\n\nislower()\nReturns True if all characters in the string are lower case\n\n\nisnumeric()\nReturns True if all characters in the string are numeric\n\n\nisprintable()\nReturns True if all characters in the string are printable\n\n\nisspace()\nReturns True if all characters in the string are whitespaces\n\n\nistitle()\nReturns True if the string follows the rules of a title\n\n\nisupper()\nReturns True if all characters in the string are upper case\n\n\njoin()\nConverts the elements of an iterable into a string\n\n\nljust()\nReturns a left justified version of the string\n\n\nlower()\nConverts a string into lower case\n\n\nlstrip()\nReturns a left trim version of the string\n\n\nmaketrans()\nReturns a translation table to be used in translations\n\n\npartition()\nReturns a tuple where the string is parted into three parts\n\n\nreplace()\nReturns a string where a specified value is replaced with a specified value\n\n\nrfind()\nSearches the string for a specified value and returns the last position of where it was found\n\n\nrindex()\nSearches the string for a specified value and returns the last position of where it was found\n\n\nrjust()\nReturns a right justified version of the string\n\n\nrpartition()\nReturns a tuple where the string is parted into three parts\n\n\nrsplit()\nSplits the string at the specified separator, and returns a list\n\n\nrstrip()\nReturns a right trim version of the string\n\n\nsplit()\nSplits the string at the specified separator, and returns a list\n\n\nsplitlines()\nSplits the string at line breaks and returns a list\n\n\nstartswith()\nReturns true if the string starts with the specified value\n\n\nstrip()\nReturns a trimmed version of the string\n\n\nswapcase()\nSwaps cases, lower case becomes upper case and vice versa\n\n\ntitle()\nConverts the first character of each word to upper case\n\n\ntranslate()\nReturns a translated string\n\n\nupper()\nConverts a string into upper case\n\n\nzfill()\nFills the string with a specified number of 0 values at the beginning\n\n\n\n\n\n2.2.4 List, Tuples\nA list is an ordered collection of items. Lists are mutable, which means that their elements can be added, removed, or modified. To create a list in Python, you can use square brackets [] and separate the elements by commas. The contents of the list can be any of the aformentioned elementary data type.\n\ndata_discussed_so_far = [1, 1.5, True, filename]\ndata_discussed_so_far\n\n[1, 1.5, True, 'database_xmcv_21.csv']\n\n\n\ndata_discussed_so_far[3]\n\n'database_xmcv_21.csv'\n\n\n\ndata_discussed_so_far[3] = 'database_xcmm_45.csv'\n\n\ndata_discussed_so_far[3]\n\n'database_xcmm_45.csv'\n\n\n\ntype(data_discussed_so_far) # get the type\n\nlist\n\n\n\ndata_discussed_so_far[-1]\n\n'database_xcmm_45.csv'\n\n\n\ndata_discussed_so_far[1:3:1] # start stop step\n\n[1.5, True]\n\n\n\ndata_discussed_so_far[2:4] #start, stop, location of final item + 1\n\n[True, 'database_xcmm_45.csv']\n\n\nThe colon operator denotes start : end + 1. data_discussed_so_far[2:4]returns the 2nd element, and 3rd element but not the fourth even though 3 is used in the index.\n\ndata_discussed_so_far.append('database_vbnmx_25.csv')\n\n\ndata_discussed_so_far\n\n[1, 1.5, True, 'database_xcmm_45.csv', 'database_vbnmx_25.csv']\n\n\nA tuple is similar to a list, but it is immutable. Once a tuple is created, you cannot change its elements. To create a tuple in Python, you can use parentheses () and separate the elements by commas.\n\nmy_numbers = (1, 2, 3, 4)\ntype(my_numbers)\n\ntuple\n\n\n\nmy_numbers[3]\n\n4\n\n\n\n\n\n\n\n\n\nList Methods\nDescription\n\n\n\n\nappend()\nAdds an element at the end of the list\n\n\nclear()\nRemoves all the elements from the list\n\n\ncopy()\nReturns a copy of the list\n\n\ncount()\nReturns the number of elements with the specified value\n\n\nextend()\nAdd the elements of a list (or any iterable), to the end of the current list\n\n\nindex()\nReturns the index of the first element with the specified value\n\n\ninsert()\nAdds an element at the specified position\n\n\npop()\nRemoves the element at the specified position\n\n\nremove()\nRemoves the first item with the specified value\n\n\nreverse()\nReverses the order of the list\n\n\nsort()\nSorts the list\n\n\n\n\n\n\n\n\n\n\nTuple Methods\nDescription\n\n\n\n\ncount()\nReturns the number of times a specified value occurs in a tuple\n\n\nindex()\nSearches the tuple for a specified value and returns the position of where it was found\n\n\n\n\n\n2.2.5 Dictionary\nDictionaries as the name suggests is similar to the classical definition of a dictionary. Given a ‘key’ piece of information, like a word, the detailed meaning of this word can be obtained. Similarly, we can organise data in the form of key:value pairs. A dictionary data type in python is a collection of key-value pairs. Each key in a dictionary must be unique, and the values can be of any data type. To create a dictionary in Python, you can use curly braces {} and separate the key-value pairs by colons (:).\n\n\n\n\n\n\nNote\n\n\n\nIn Python, lists and tuples are organized and accessed based on position. Dictionaries in Python are organized and accessed using keys and values. The location of a pair of keys and values stored in a Python dictionary is irrelevant.\n\n\nKeys can be a string, number or even tuple (but not a list). In contrast to the list where data is indexed by integer values denoting thier position in the list, the dictionary can be indexed using the keys. Dictionaries can be used to organize data and avoid errors while indexing and extracting information.\n\nmaterial_properties = {'viscosity':[2, 2, 3, 4], 'stiffness':5} # create a dictionary\n\n\nmaterial_properties\n\n{'viscosity': [2, 2, 3, 4], 'stiffness': 5}\n\n\n\nmaterial_properties['density'] = 1 # Add new item into the dictionary through initialization\n\n\nmaterial_properties # look at the dictionary\n\n{'viscosity': [2, 2, 3, 4], 'stiffness': 5, 'density': 1}\n\n\n\nmaterial_properties['viscosity'][-1] # extract the value of the key 'density'\n\n4\n\n\n\ntype(material_properties)\n\ndict\n\n\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\nclear()\nRemoves all the elements from the dictionary\n\n\ncopy()\nReturns a copy of the dictionary\n\n\nfromkeys()\nReturns a dictionary with the specified keys and value\n\n\nget()\nReturns the value of the specified key\n\n\nitems()\nReturns a list containing a tuple for each key value pair\n\n\nkeys()\nReturns a list containing the dictionary’s keys\n\n\npop()\nRemoves the element with the specified key\n\n\npopitem()\nRemoves the last inserted key-value pair\n\n\nsetdefault()\nReturns the value of the specified key. If the key does not exist: insert the key, with the specified value\n\n\nupdate()\nUpdates the dictionary with the specified key-value pairs\n\n\nvalues()\nReturns a list of all the values in the dictionary\n\n\n\n\n\n2.2.6 Set\nA set is an unordered collection of unique elements. Sets are mutable, which means that you can add or remove elements from them. To create a set in Python, you can use curly braces {} or the set() function. Set theoretical rules like union, intersection and difference can be applied on this data type. It is specified by comma-seperated data in curly braces. The command set() creates a set.\n\nmy_integers = {1, 2, 3, 4}\ntype(my_integers)\n\nset\n\n\nThe following methods are defined for sets !\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\nadd()\nAdds an element to the set\n\n\nclear()\nRemoves all the elements from the set\n\n\ncopy()\nReturns a copy of the set\n\n\ndifference()\nReturns a set containing the difference between two or more sets\n\n\ndifference_update()\nRemoves the items in this set that are also included in another, specified set\n\n\ndiscard()\nRemove the specified item\n\n\nintersection()\nReturns a set, that is the intersection of two or more sets\n\n\nintersection_update()\nRemoves the items in this set that are not present in other, specified set(s)\n\n\nisdisjoint()\nReturns whether two sets have a intersection or not\n\n\nissubset()\nReturns whether another set contains this set or not\n\n\nissuperset()\nReturns whether this set contains another set or not\n\n\npop()\nRemoves an element from the set\n\n\nremove()\nRemoves the specified element\n\n\nsymmetric_difference()\nReturns a set with the symmetric differences of two sets\n\n\nsymmetric_difference_update()\ninserts the symmetric differences from this set and another\n\n\nunion()\nReturn a set containing the union of sets\n\n\nupdate()\nUpdate the set with another set, or any other iterable",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Representation</span>"
    ]
  },
  {
    "objectID": "02_representing_data.html#input-and-output",
    "href": "02_representing_data.html#input-and-output",
    "title": "2  Data Representation",
    "section": "2.3 Input and Output",
    "text": "2.3 Input and Output\nIn Python, you can get input from the user through the console using the input() function. This function takes a string argument, which is used as a prompt to ask the user for input.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Representation</span>"
    ]
  },
  {
    "objectID": "02_representing_data.html#saving-data",
    "href": "02_representing_data.html#saving-data",
    "title": "2  Data Representation",
    "section": "2.4 Saving data",
    "text": "2.4 Saving data\nThe pickle module in Python is used for serializing and deserializing Python objects. Serialization is the process of converting an object into a byte stream, and deserialization is the process of converting a byte stream back into an object.\nHere are some basic steps for using the pickle module in Python:\n\nimport pickle\n\n\nmaterial_properties = {'Density [kg/m^3]': 1000, 'viscosity [Pa s]': 25}\n\n\nmaterial_properties\n\n{'Density [kg/m^3]': 1000, 'viscosity [Pa s]': 25}\n\n\n\nwith open('my_material_properties.pkl', 'wb') as my_file:\n    pickle.dump(material_properties, my_file) \n\n\nwith open('my_material_properties.pkl', 'rb') as my_file:\n    material_properties_imported = pickle.load(my_file)\n\n\nmaterial_properties_imported\n\n{'Density [kg/m^3]': 1000, 'viscosity [Pa s]': 25}\n\n\nNote that the pickle module can be used to serialize and deserialize any Python object, including lists, tuples, sets, and custom objects. However, it is important to note that the pickle module can be unsafe if you are unpickling data from an untrusted source, as it can execute arbitrary code.\nThe second argument in the open() function determines the mode in which the file will be opened. In particular, it specifies whether the file should be opened for reading or writing, and whether it should be opened in text mode or binary mode. Here’s a summary of the different modes that can be specified:\n\nr (default): Open the file for reading in text mode.\nw: Open the file for writing in text mode. If the file already exists, it will be truncated (i.e., emptied).\nx: Open the file for exclusive creation in text mode. If the file already exists, the operation will fail.\na: Open the file for writing in text mode. If the file already exists, new data will be appended to it.\nb: Open the file in binary mode, regardless of whether it is being opened for reading or writing. This mode should be used for non-text files, such as images, audio, or serialized data.\nt: Open the file in text mode, regardless of whether it is being opened for reading or writing. This is the default mode.\n+: Open the file for updating (i.e., both reading and writing).\n\nCombining these modes allows you to specify more complex options. For example, if you want to open a binary file for reading and writing, you would use ‘rb+’ or wb+. Similarly, if you want to open a text file for appending, you would use ‘at’.\nIn the context of the pickle module, you would typically use ‘wb’ to open a file for writing in binary mode, and ‘rb’ to open a file for reading in binary mode. This is because pickle serializes Python objects into a binary format, which is not compatible with text mode. The reason why it’s called serialization and not just copying is because serialization involves more than just making a copy of an object. When we serialize an object, we’re actually taking all of its data (like its properties, values, and attributes) and converting it into a format that can be easily saved or transmitted.\nThis format is typically a sequence of bytes, which is a series of numbers that represent the object’s data in binary code. This sequence of bytes is what gets saved or transmitted, rather than the original object itself. So serialization is more than just copying an object - it’s actually a process of transforming an object’s data into a format that can be saved or transmitted. And deserialization is the process of transforming that saved or transmitted data back into an object with all of its original properties and attributes.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Representation</span>"
    ]
  },
  {
    "objectID": "02_representing_data.html#help",
    "href": "02_representing_data.html#help",
    "title": "2  Data Representation",
    "section": "2.5 Help",
    "text": "2.5 Help\nApplying the function help on any python object, the details of the object can be retrieved.\n\nhelp(print)\n\nHelp on built-in function print in module builtins:\n\nprint(*args, sep=' ', end='\\n', file=None, flush=False)\n    Prints the values to a stream, or to sys.stdout by default.\n    \n    sep\n      string inserted between values, default a space.\n    end\n      string appended after the last value, default a newline.\n    file\n      a file-like object (stream); defaults to the current sys.stdout.\n    flush\n      whether to forcibly flush the stream.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Representation</span>"
    ]
  },
  {
    "objectID": "02_representing_data.html#worked-example-1-climate-change-indicators",
    "href": "02_representing_data.html#worked-example-1-climate-change-indicators",
    "title": "2  Data Representation",
    "section": "2.6 Worked Example 1: Climate Change Indicators",
    "text": "2.6 Worked Example 1: Climate Change Indicators\nLet’s consider a scenario related to climate change, focusing on data points that are commonly discussed in environmental studies: average global temperature change (float), carbon dioxide (CO2) emissions (int, measured in gigatons), and a boolean indicating whether renewable energy usage is increasing year-over-year.\nFrom these inputs, we aim to derive properties that can provide insights into the progress towards mitigating climate change. These could include:\n\nTemperature Anomaly Risk (boolean): Indicates if the change in average global temperature is beyond a certain threshold, suggesting a high risk to global climates.\nEmissions Trend (boolean): Determines if CO2 emissions are within a target reduction path.\n\n\n\n\n\n\n\n\n\nProperty\ntype\nValue\n\n\n\n\naverage_temperature_change (°C)\nfloat\ninput\n\n\nco2_emissions (Gt)\nint\ninput\n\n\nrenewable_energy_increasing (-)\nbool\ninput\n\n\ntemperature_risk_threshold (°C)\nfloat\n1.5\n\n\ntarget_co2_emissions (Gt)\nbool\n35\n\n\ntemperature_anomaly_risk\nbool\naverage_temperature_change &gt; temperature_risk_threshold\n\n\nemissions_trend\nbool\nco2_emissions &lt; target_co2_emissions\n\n\n\n\n# Input data\naverage_temperature_change = 1.2  # Example change in degrees Celsius\nco2_emissions = 38  # CO2 emissions in gigatons for the current year\nrenewable_energy_increasing = True  # Whether the use of renewable energy is increasing\n\n# Constants for calculations\ntemperature_risk_threshold = 1.5  # Degrees Celsius\ntarget_co2_emissions = 35  # Target emissions in gigatons\n\n# Deriving additional properties\n\n# Temperature Anomaly Risk (true if average_temperature_change exceeds threshold)\ntemperature_anomaly_risk = average_temperature_change &gt; temperature_risk_threshold\n\n# Emissions Trend (true if emissions are below or equal to the target)\nemissions_trend = co2_emissions &lt;= target_co2_emissions\n\n# Display the derived properties\nprint(f\"Temperature Anomaly Risk: {temperature_anomaly_risk}\")\nprint(f\"Emissions Trend: {emissions_trend}\")\n\nTemperature Anomaly Risk: False\nEmissions Trend: False\n\n\nThis example synthesizes basic climate-related data into actionable insights. The Temperature Anomaly Risk signals when immediate action is needed to curb global warming. The Emissions Trend offers a quick check against set targets for CO2 emissions, indicating whether more aggressive measures are needed.\nSuch calculations, though simplified here, are vital in real-world policy-making and environmental science, helping to monitor and guide efforts against climate change.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Representation</span>"
    ]
  },
  {
    "objectID": "02_representing_data.html#worked-example-2-creating-an-environmental-monitoring-database",
    "href": "02_representing_data.html#worked-example-2-creating-an-environmental-monitoring-database",
    "title": "2  Data Representation",
    "section": "2.7 Worked Example 2: Creating an Environmental Monitoring Database",
    "text": "2.7 Worked Example 2: Creating an Environmental Monitoring Database\nConsider the environmental monitoring scenario. Using sensor data, we can derive additional properties that provide more nuanced insights into the environment. These insights can be critical for different applications, such as agricultural planning, public health advisories, and even automated home systems. Assuming the user provides the temperature, humidity and information if it is raining, a recommendation system can be setup that also logs the data.\n\n\n\n\n\n\n\n\nProperty\ntype\nValue\n\n\n\n\ndate and time\nstr\nsystem\n\n\ntemperature (°C)\nint\ninput\n\n\nhumidity (%)\nint\ninput\n\n\nis_raining (-)\nbool\ninput\n\n\nsuitable_for_plant_growth (-)\nbool\n(18 &lt; temperature &lt; 25) & humidity &gt; 50 & ¬ is_raining\n\n\nrisk_of_equipment_damage (-)\nbool\nhumidity &gt; 75\n\n\nadditional_watering_needed (-)\nbool\n¬ is_raining & humidity &lt; 65\n\n\nfrost warning (-)\nbool\ntemperature &lt; 5 & ¬ is_raining\n\n\ninspection needed (-)\nbool\nrisk_of_equipment_damage\n\n\n\n\nenvironmental_data = []\n\n\nimport math\nimport datetime as dt\nimport pickle\n\nproperties = {}\n\n# Given inputs remain the same\ndate = dt.datetime.now()\nproperties['date and time'] = (date.strftime(\"%m/%d/%Y, %H:%M:%S\"), date.weekday())\nproperties['temperature'] = float('33')  \nproperties['humidity'] = int('65')      \nproperties['is_raining'] = bool('True') \n\n# Existing derived properties\nproperties['suitable_for_plant_growth'] = 18 &lt; properties['temperature'] &lt; 25 and properties['humidity'] &gt; 50 and not properties['is_raining']\nproperties['risk_of_equipment_damage'] = properties['humidity'] &gt; 75\nproperties['additional_watering_needed'] = not properties['is_raining'] and properties['humidity'] &lt; 65\n\n# Frost Warning (assuming frost risk if temperature is close to 0°C and not raining)\nproperties['frost_warning'] = properties['temperature'] &lt; 5 and not properties['is_raining']\nproperties['inspection_needed'] = properties['risk_of_equipment_damage'] or properties['frost_warning']\n\n# Add the newly derived properties\nenvironmental_data.append(properties)\n\n# Save the data point in a database\nwith open('environmental_state.dbs', 'wb') as my_file:\n    pickle.dump(environmental_data, my_file) \n\nImport the database and view it !\n\nwith open('environmental_state.dbs', 'rb') as my_file:\n    my_data_that_is_imported = pickle.load(my_file)\nprint(my_data_that_is_imported)\n\n[{'date and time': ('07/13/2024, 23:06:06', 5), 'temperature': 33.0, 'humidity': 65, 'is_raining': True, 'suitable_for_plant_growth': False, 'risk_of_equipment_damage': False, 'additional_watering_needed': False, 'frost_warning': False, 'inspection_needed': False}]",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Representation</span>"
    ]
  },
  {
    "objectID": "02_representing_data.html#exercises",
    "href": "02_representing_data.html#exercises",
    "title": "2  Data Representation",
    "section": "2.8 Exercises",
    "text": "2.8 Exercises\n\n2.8.1 Theory\n\nWhat is the difference between a list and a tuple in Python?\nWhat is the difference between an int and a float in Python?\nWhat is the purpose of type conversion in Python? Give an example.\nHow do you declare a variable in Python, and what are the rules for naming variables?\nWe have the average temperature data for each day of the week for one week. Which is the most suitable data structure to represent this data ?\n\n\n\n2.8.2 Coding\n\nCreate a program that prompts the user to enter a sentence. Your program should convert the sentence to a list of words and then sort the list in alphabetical order. Finally, print the sorted list to the console.\nGet the largest number from a list of integers.\nCreate a program that prompts the user to enter a string. Your program should then check if the string is a palindrome (i.e., it reads the same forward and backward). If the string is a palindrome, print “Palindrome” to the console. Otherwise, print “Not a palindrome” to the console.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Representation</span>"
    ]
  },
  {
    "objectID": "02_representing_data.html#further-reading",
    "href": "02_representing_data.html#further-reading",
    "title": "2  Data Representation",
    "section": "2.9 Further Reading",
    "text": "2.9 Further Reading\n\nhttps://docs.python.org/3/tutorial/datastructures.html\nhttps://docs.python.org/3/library/stdtypes.html#",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Representation</span>"
    ]
  },
  {
    "objectID": "03_control_structures.html",
    "href": "03_control_structures.html",
    "title": "3  Control Structures",
    "section": "",
    "text": "3.1 Conditionals\nOften a certain process needs to executed if a certain condition is fulfilled. The result of this conditions has to be of the Boolean data type.\na = 0\nb = 1100\na &gt; b\n\nFalse\nif a &gt; b:\n    print('a is bigger than b')\n    print(a**2)\nelse:\n    print('b is bigger than a')\n    print(b**2)\n\nb is bigger than a\n1210000",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Control Structures</span>"
    ]
  },
  {
    "objectID": "03_control_structures.html#conditionals",
    "href": "03_control_structures.html#conditionals",
    "title": "3  Control Structures",
    "section": "",
    "text": "Important\n\n\n\nPlease do not forget to add the colon after the condition and also after the else statement. The indentation is used to specify the sub-process that the program executes when the condition is either satisfied or not satisfied.\n\n\n\n3.1.1 Extended Conditions\nThe keyword elif is used to add additional conditions.\n\nif a &gt; b:\n    print('a is bigger than b')\nelif a == 0:\n    print('a is 0')\nelse:\n    print('a is neither zero or bigger than b')\n\na is 0\n\n\n\nOne Liners\nThe conditional statements can also be included as one-liners !\n\nif a &lt; 1: print('a is less than 1') # One liner if\n\na is less than 1\n\n\n\nprint('a is less than one') if a &lt; 1 else print('a greater than 1') # One liner if.. else\n\na is less than one\n\n\n\n\nand, or\nIf multiple conditions have to be tested, and and or keywords can be used !\n\nif b &gt; a and a == 0: print('b is greater than a and a is equal to 0')\n\nb is greater than a and a is equal to 0\n\n\n\nif b &gt; a or a == 0: print('b is greater than a and a is equal to 0') # short-circuiting\n\nb is greater than a and a is equal to 0\n\n\n\nx = 50\n\nif x &gt; 10:\n    print(\"Above ten,\")\n    if x &gt; 20:\n        print(\"and also above 20!\")\n        print(x**2)\n    else:\n        print(\"but not above 20.\")\n\nAbove ten,\nand also above 20!\n2500",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Control Structures</span>"
    ]
  },
  {
    "objectID": "03_control_structures.html#loop-constructs",
    "href": "03_control_structures.html#loop-constructs",
    "title": "3  Control Structures",
    "section": "3.2 Loop Constructs",
    "text": "3.2 Loop Constructs\nLoop constructs are used to repeatedly execute a block of code as long as a specific condition is met. Python provides two main types of loop constructs: the “for” loop and the “while” loop. These loop constructs are fundamental for iterating over sequences, performing repetitive tasks, and controlling the flow of your programs.\n\n3.2.1 While Loop:\nThe “while” loop in Python repeatedly executes a block of code as long as a specified condition remains true. It’s often used when you don’t know in advance how many times the loop will run.\nHere’s the basic structure of a “while” loop in Python:\nwhile condition:\n    # Code to be executed as long as the condition is true\n\ncondition: The loop continues executing as long as this condition evaluates to True.\n\nIn addition to these basic loop constructs, Python also supports control statements like break and continue to control the flow within loops. The break statement allows you to exit a loop prematurely based on a certain condition, while the continue statement allows you to skip the rest of the current iteration and move to the next one.\n\nk = 1\nwhile k &lt; 6: # the code in the intedentation is executed until the condition is true !\n    print('in loop') \n    print(k)\n    k = k + 1\n\nin loop\n1\nin loop\n2\nin loop\n3\nin loop\n4\nin loop\n5\n\n\nSometimes it maybe wise to stop the computation in the framework of a while loop if a certain condition is met.\n\nk = 1\nwhile k &lt; 1000:\n    if k &gt; 20:\n        break\n    print('The value of k is: {k_value}'.format(k_value=k)) # format is used to inject data into a string !\n    k = k + 1\n\nThe value of k is: 1\nThe value of k is: 2\nThe value of k is: 3\nThe value of k is: 4\nThe value of k is: 5\nThe value of k is: 6\nThe value of k is: 7\nThe value of k is: 8\nThe value of k is: 9\nThe value of k is: 10\nThe value of k is: 11\nThe value of k is: 12\nThe value of k is: 13\nThe value of k is: 14\nThe value of k is: 15\nThe value of k is: 16\nThe value of k is: 17\nThe value of k is: 18\nThe value of k is: 19\nThe value of k is: 20\n\n\nWithout the break statement, the while loop would continue until the final value of 1000 !\n\ncount = 1\nwhile count &lt;= 10:\n    if count == 5:\n        count += 1\n        continue  # Skip printing 5\n    print(count)\n    count += 1\n\n1\n2\n3\n4\n6\n7\n8\n9\n10\n\n\nWe initialize a counter count to 1 and iterate while count is less than or equal to 10. When count is equal to 5, we use continue to skip the current iteration, so 5 is not printed. For all other values of count, we print the number and increment count by 1.\n\n\n\n3.2.2 For Loop:\nThe “for” loop in Python is primarily used for iterating over sequences like lists, tuples, strings, and dictionaries, as well as other iterable objects. It iterates over each element in the sequence and executes a specified block of code for each element.\nHere’s the basic structure of a “for” loop in Python:\nfor variable in iterable:\n    # Code to be executed for each element\n\nvariable: This is a variable that represents the current element in the iterable.\niterable: The sequence or iterable object over which the loop iterates.\n\nThe for keyword is used to loop over a sequence (list, tuple, dictionary, set, or a string).\nIn Python, the for loop can be used with various types of iterables. An iterable is an object that can be iterated upon, meaning that you can loop over its elements one at a time.\n\nmy_list_of_data = [1, 'test', 3, 4]\n\n\nfor d in my_list_of_data:\n    print(d)\n\n1\ntest\n3\n4\n\n\nIn case a certain value in the sequence needs to be skipped from processing, the keyword continue can be used.\n\nspecimens = ['M50', 'XM20 ', 'YM50', 'M20', 'M56']\n\n\ncleaned_specimens = []\n\n\nfor specimen in specimens:\n    if specimen[0] == 'M':\n        continue\n    print(specimen)\n    cleaned_specimens.append(specimen)\n\nXM20 \nYM50\n\n\nThe break keyword can be used to exit the loop !\n\ncleaned_specimens\n\n['XM20 ', 'YM50']\n\n\n\nspecimens = ['M50', 'M30', 'M20', 'M56']\nfor specimen in specimens:\n    if specimen == 'M30':\n        break\n    print(specimen)\n\nM50\n\n\nTuples inside lists can be accessed through the for loop.\n\nlist_of_tuples = [(1, 3), (10, 30), (100, 300)]\n\n\nfor small, big in list_of_tuples:\n    print('This is the small number:' + str(small))\n    print('This is the big number:' + str(big))\n\nThis is the small number:1\nThis is the big number:3\nThis is the small number:10\nThis is the big number:30\nThis is the small number:100\nThis is the big number:300\n\n\nYou can iterate over the characters of a string using a for loop.\n\nmy_text = 'data_file.xls'\nfile_extension = []\nfor character in my_text:  \n    if character == '.':\n        file_extension = []\n    file_extension.append(character)\n    \nempty_delimiter = ''         \nprint(empty_delimiter.join(file_extension))\n\n.xls\n\n\nYou can iterate over the keys, values or items of a dictionary using a for loop.\n\nmaterial = {'name': 'Iron', \n            'Symbol': 'Fe', \n            'Atomic radius (pm)': 126}\n\n\nfor key, value in material.items():\n    \n    print(key, ':', value)\n\nname : Iron\nSymbol : Fe\nAtomic radius (pm) : 126\n\n\n\n\n\n\n\n\nTip\n\n\n\nOne can quickly loop over integer sequences using the range function. A range object represents a sequence of numbers. You can iterate over the numbers in a range object using a for loop.\n\n\nThe command range() is often used to generate a list when performing iterative computations ! range(n) generates an iterator starting at 0 and ending at n-1.\n\n# prints a function\nfor x in range(6):\n    y = x + x**2 + x**0.3\n    print(x, y)\n\n0 0.0\n1 3.0\n2 7.231144413344916\n3 13.39038917031591\n4 21.5157165665104\n5 31.62065659669276\n\n\nIn case the increment does not need to be in steps of one but in steps of another fixed value, the range(start, stop, step) specification can be used !\n\nmy_data = []\nfor z in range(0, 101, 10): # range(start:stop:step) 100 items starting at 0 ends at 99 ! \n    y = z + z**2 + z**0.3\n    my_tuple = (z, y)\n    my_data.append(my_tuple)\n\n\nmy_data\n\n[(0, 0.0),\n (10, 111.99526231496888),\n (20, 422.4564560522316),\n (30, 932.7741911146721),\n (40, 1643.0242521453322),\n (50, 2553.233635032887),\n (60, 3663.41542989238),\n (70, 4973.5770862508725),\n (80, 6483.723291133272),\n (90, 8193.857205282227),\n (100, 10103.981071705535)]\n\n\n\nimport pickle\nwith open('my_new_data.pkl', 'wb') as my_file:\n    pickle.dump(my_data, my_file) \n\nWhen iterating over items, sometimes, the counter is also required. In that case use enumerate(iterator)\n\na_more_newer_list = [1, 4, 16, 32, 64, 128, 256, 512, 1024]\n\n\nfor counter, value in enumerate(a_more_newer_list):\n    y = value**0.3\n    print(counter, value, y)\n\n0 1 1.0\n1 4 1.515716566510398\n2 16 2.2973967099940698\n3 32 2.82842712474619\n4 64 3.4822022531844965\n5 128 4.2870938501451725\n6 256 5.278031643091577\n7 512 6.498019170849884\n8 1024 7.999999999999999\n\n\n\nmy_new_list_1 = [1, 4, 16, 32, 64, 128, 256, 512, 1024]\nmy_new_list_2 = [1*3, 4*3, 16*3, 32*3, 64*3, 128*3, 256*3, 512*3, 1024*3]\n\nIn case we have two lists and we want to loop over them simultaneously then use zip:\n\nfor l1, l2 in zip(my_new_list_1, my_new_list_2):\n    print(l1, l2)\n\n1 3\n4 12\n16 48\n32 96\n64 192\n128 384\n256 768\n512 1536\n1024 3072",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Control Structures</span>"
    ]
  },
  {
    "objectID": "03_control_structures.html#generator-expressions",
    "href": "03_control_structures.html#generator-expressions",
    "title": "3  Control Structures",
    "section": "3.3 Generator expressions:",
    "text": "3.3 Generator expressions:\nA generator expression is a concise way to create a generator object, which is an iterable that generates values on-the-fly. You can iterate over the values generated by a generator expression using a for loop.\n\nsquares = (x**2 for x in range(1, 6))\n\n\nsquares\n\n&lt;generator object &lt;genexpr&gt; at 0x12af94d40&gt;\n\n\n\ntype(squares)\n\ngenerator\n\n\n\n# define a generator for generating squares\nfor square in squares:\n    print(square)\n\n1\n4\n9\n16\n25",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Control Structures</span>"
    ]
  },
  {
    "objectID": "03_control_structures.html#iterators",
    "href": "03_control_structures.html#iterators",
    "title": "3  Control Structures",
    "section": "3.4 Iterators",
    "text": "3.4 Iterators\nIn Python, an iterator is an object that represents a sequence of values. Iterators can be used to loop over a sequence of values one at a time, without loading the entire sequence into memory at once. This can be especially useful for working with large datasets or for situations where memory is limited.\nHistorically, the concept of iterators has been important in computer science because it helps programmers optimize their code and improve its performance. Prior to the development of iterators, programmers would often use loops and conditionals to work with sequences of values. However, this approach could be inefficient and lead to performance issues when working with large datasets.\nIn Python, iterators are implemented using the iter() function, which takes a sequence object and returns an iterator object. You can then use the next() function to retrieve the next value from the iterator, or use a for loop to iterate over all the values in the sequence.\n\nmy_list = [1, 2, 3]\nmy_iter = iter(my_list)\n\n\ntype(my_iter)\n\nlist_iterator\n\n\n\nprint(next(my_iter))\n\n1\n\n\n\nfor item in my_iter:\n    print(item); # 3\n\n2\n3\n\n\nIn this example, we create a list of values called my_list, and then use the iter() function to create an iterator object called my_iter. We then use the next() function to retrieve the first three values from the iterator, and use a for loop to iterate over the remaining values. Iterators are an important concept in Python and can be used in a variety of contexts, including working with files, databases, and other data sources. By understanding iterators and how they work, programmers can write more efficient and effective Python code.\n\n\n\n\n\n\nNote\n\n\n\nThe for loop actually creates an iterator object and executes the next() method for each loop.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Control Structures</span>"
    ]
  },
  {
    "objectID": "03_control_structures.html#itertools",
    "href": "03_control_structures.html#itertools",
    "title": "3  Control Structures",
    "section": "3.5 Itertools",
    "text": "3.5 Itertools\nThe itertools module in Python provides a set of tools for working with iterable objects like lists, tuples, and iterators. These tools are designed to be fast and memory-efficient, and can be used to perform complex tasks with minimal code.\nHere is a brief description on some of the most commonly used tools in the itertools module:\ncount(start=0, step=1) returns an iterator that generates a sequence of numbers starting from start and incrementing by step at each iteration.\n\nimport itertools\n\n# Generate a sequence of numbers starting from 0 and incrementing by 2\nfor i in itertools.count(0, 2):\n    if i &gt; 10:\n        break\n    print(i)\n\n0\n2\n4\n6\n8\n10\n\n\ncycle(iterable) returns an iterator that cycles through the elements of iterable indefinitely.\n\nmy_list = [1, 2, 3, 4]\ncounter = 0\nfor i in itertools.cycle(my_list):\n    counter += 1\n    if counter &gt; 10:\n        break\n    print(i)\n\n1\n2\n3\n4\n1\n2\n3\n4\n1\n2\n\n\nrepeat(elem, n=None) returns an iterator that generates the elem value n times, or indefinitely if n is not specified.\n\nfor i in itertools.repeat(5, 5):\n    print(i)\n\n5\n5\n5\n5\n5\n\n\nchain(*iterables) takes multiple iterables as arguments and returns a single iterator that produces the elements of each iterable in sequence.\n\nlist1 = [1, 2, 3]\nlist2 = [4, 5, 6]\nlist3 = [7, 8, 9]\nfor i in itertools.chain(list1, list2, list3):\n    print(i)\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nproduct(*iterables, repeat=1) returns an iterator that produces the Cartesian product of the input iterables, with repeat specifying the number of repetitions of each input iterable.\n\nlist1 = ['a', 'b']\nlist2 = [1, 2, 3]\nfor pair in itertools.product(list1, list2):\n    print(pair)\n\n('a', 1)\n('a', 2)\n('a', 3)\n('b', 1)\n('b', 2)\n('b', 3)",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Control Structures</span>"
    ]
  },
  {
    "objectID": "03_control_structures.html#error-handling-in-python",
    "href": "03_control_structures.html#error-handling-in-python",
    "title": "3  Control Structures",
    "section": "3.6 Error Handling in Python",
    "text": "3.6 Error Handling in Python\nError handling in Python is a technique used to gracefully handle unexpected or exceptional situations that may arise during the execution of a program. Python provides a way to catch and manage errors or exceptions using try and except blocks. Here’s a brief introduction to error handling in Python with an example:\nIn Python, exceptions are raised when an error occurs during program execution. These exceptions can be built-in errors (e.g., ValueError, IndexError) or custom exceptions defined by the programmer.\nThe basic syntax for error handling in Python is as follows:\ntry:\n    # Code that may raise an exception\nexcept ExceptionType1:\n    # Code to handle ExceptionType1\nexcept ExceptionType2:\n    # Code to handle ExceptionType2\nelse:\n    # Code to execute if no exceptions are raised\nfinally:\n    # Code to execute regardless of whether an exception occurred or not\n\ntry: This block contains the code where you anticipate an exception might occur.\nexcept: If an exception of the specified type occurs within the try block, the corresponding except block will be executed. You can have multiple except blocks to handle different types of exceptions.\nelse (optional): This block is executed if no exceptions occur in the try block.\nfinally (optional): This block is always executed, whether an exception occurred or not. It is typically used for cleanup operations, such as closing files or releasing resources.\n\nHere’s an example that demonstrates error handling in Python:\n\ntry:\n    num1 = 25\n    num2 = 0\n    result = num1 / num2\nexcept ZeroDivisionError:\n    print(\"Error: Division by zero is not allowed.\")\nexcept ValueError:\n    print(\"Error: Please enter valid numeric values.\")\nelse:\n    print(f\"Result of division: {result}\")\nfinally:\n    print(\"Program execution completed.\")\n\nError: Division by zero is not allowed.\nProgram execution completed.\n\n\nIn this example:\n\nWe attempt to get two integer inputs from the user and perform division in the try block.\nIf the user enters non-numeric values, a ValueError exception is caught in the first except block.\nIf the user enters a denominator of zero, a ZeroDivisionError exception is caught in the second except block.\nIf no exceptions occur, the else block calculates and prints the result.\nThe finally block is always executed, providing a message that the program execution is completed.\n\nError handling allows your program to handle exceptional conditions without crashing, making your code more robust and user-friendly. It’s an essential part of writing reliable Python programs.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Control Structures</span>"
    ]
  },
  {
    "objectID": "03_control_structures.html#examples-pythogoras-collatz-and-erastothenes",
    "href": "03_control_structures.html#examples-pythogoras-collatz-and-erastothenes",
    "title": "3  Control Structures",
    "section": "3.7 Examples: Pythogoras, Collatz and Erastothenes:",
    "text": "3.7 Examples: Pythogoras, Collatz and Erastothenes:\nLet us solve three classical math problems using control structures.\n\n3.7.1 Pythogorean Triples:\nThe goal is to generate a sequence of Pythagorean triples, which are sets of three positive integers \\((a, b, c)\\) that satisfy the Pythagorean theorem \\(a^2 + b^2 = c^2\\).\n\n# Generate Pythagorean triples\nlimit = 12\npythagorean_triples = ((a, b, c) for c in range(1, limit) for b in range(1, c) for a in range(1, b) if a**2 + b**2 == c**2)\n# Iterate over the iterator and print Pythagorean triples\nfor triple in pythagorean_triples:\n    print(triple)\n\n(3, 4, 5)\n(6, 8, 10)\n\n\nIn this example: - The expression iterates over all possible values of \\(a\\), \\(b\\), and \\(c\\) within the specified limit. - We check if each combination satisfies the Pythagorean theorem. - If a combination satisfies the theorem, it is yielded as a Pythagorean triple. - We then iterate over the iterator of Pythagorean triples and print each triple.\n\n\nShow the code\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Significantly increase the limit for generating a lot more Pythagorean triples\nlimit = 250\npythagorean_triples = [(a, b, c) for c in range(1, limit) for b in range(1, c) for a in range(1, b) if a**2 + b**2 == c**2]\n\n# Extract a, b, and c from the triples\na_values = [triple[0] for triple in pythagorean_triples]\nb_values = [triple[1] for triple in pythagorean_triples]\nc_values = [triple[2] for triple in pythagorean_triples]\n\n# Normalize c values for colormap\nc_normalized = np.array(c_values) / float(max(c_values))\n\n# Create scatter plot\nplt.figure(figsize=(8, 8))\nscatter = plt.scatter(a_values, b_values, c=c_normalized, cmap='Spectral', s=50, alpha=0.9, edgecolor='k')\n\n# Add colorbar\nplt.colorbar(scatter, label='Normalized c value')\n\n# Set labels and title\nplt.xlabel('a')\nplt.ylabel('b')\n\n# Show plot\nplt.show()\n\n\n\n\nPythagorean triples\n\n\n\n\n\n\n\n3.7.2 Collatz Conjecture\nLet’s create a Python example that demonstrates the Collatz conjecture, also known as the \\(3n + 1\\) problem. This problem involves taking any positive integer \\(n\\). If \\(n\\) is even, you divide it by 2, and if n is odd, you multiply it by 3 and add 1. You repeat the process with the resulting number. The conjecture is that no matter what number you start with, you will always eventually reach 1.\nThe mathematical representation of the Collatz function, \\(C(n)\\), can be defined as:\n\\[\nC(n) =\n\\begin{cases}\n\\frac{n}{2} & \\text{if } n \\text{ is even} \\\\\n3n + 1 & \\text{if } n \\text{ is odd}\n\\end{cases}\n\\]\nThe process is then repeated with the resulting value, forming a sequence of numbers. The conjecture asserts that for any positive integer \\(n\\), the sequence will always reach 1. Despite being simple to state and verify for any particular \\(n\\), the Collatz conjecture remains an open problem in mathematics, meaning it has not been proven or disproven for all positive integers. Here’s a basic implementation in Python using a while loop:\n\n\nShow the code\nstarting_number = 27\nsequence = [starting_number]\nn = starting_number\nwhile n != 1:\n    if n % 2 == 0:\n        n = n // 2\n    else:\n        n = 3 * n + 1\n    sequence.append(n)\n\nprint(\"Collatz sequence starting from\", starting_number, \"is:\", sequence)\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Generate the plot\nplt.figure(figsize=(8, 6))\nx = np.arange(len(sequence))\ny = np.array(sequence)\n\n# Plot the sequence\nplt.plot(x, y, label='Collatz sequence', color='black')\n\n# Create a colormap\nnorm = plt.Normalize(vmin=min(y), vmax=max(y))\ncmap = plt.get_cmap('Spectral')\n\n# Fill the area below the curve with Spectral colormap\nfor i in range(len(x) - 1):\n    plt.fill_between(x[i:i + 2], 0, y[i:i + 2], color=cmap(norm(y[i])))\n\n# Add color bar\nsm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\nsm.set_array([])\n\n# Set labels and title\nplt.xlabel('Iteration')\nplt.ylabel('n')\n\nplt.show()\n\n\nCollatz sequence starting from 27 is: [27, 82, 41, 124, 62, 31, 94, 47, 142, 71, 214, 107, 322, 161, 484, 242, 121, 364, 182, 91, 274, 137, 412, 206, 103, 310, 155, 466, 233, 700, 350, 175, 526, 263, 790, 395, 1186, 593, 1780, 890, 445, 1336, 668, 334, 167, 502, 251, 754, 377, 1132, 566, 283, 850, 425, 1276, 638, 319, 958, 479, 1438, 719, 2158, 1079, 3238, 1619, 4858, 2429, 7288, 3644, 1822, 911, 2734, 1367, 4102, 2051, 6154, 3077, 9232, 4616, 2308, 1154, 577, 1732, 866, 433, 1300, 650, 325, 976, 488, 244, 122, 61, 184, 92, 46, 23, 70, 35, 106, 53, 160, 80, 40, 20, 10, 5, 16, 8, 4, 2, 1]\n\n\n\n\nThe Collatz Sequence\n\n\n\n\n\n\n\n3.7.3 Sieve of Eratosthenes\nA prime number is defined as a natural number greater than 1 that has only two distinct divisors: 1 and itself. To identify all prime numbers up to a specified integer n using the Sieve of Eratosthenes method, follow these steps:\n\nGenerate a sequential list of numbers from 2 up to \\(n\\): (2, 3, 4, …, n).\nStart with \\(p\\) set to 2, the first prime number.\nFor each multiple of \\(p\\), starting from \\(2p\\) up to \\(n\\), mark these multiples in the list (which includes \\(2p, 3p, 4p\\), etc., but not \\(p\\) itself).\nLocate the smallest number in the list that is larger than \\(p\\) and unmarked. If there is no such number, the process ends. If found, set \\(p\\) to this new number (the next prime) and repeat from step 3.\nAt the end of the process, the unmarked numbers in the list represent all the prime numbers less than or equal to \\(n\\).\n\n\n\nShow the code\nlimit = 100\nprimes = [True] * (limit + 1)\nprimes[0], primes[1] = False, False  # 0 and 1 are not prime\n\np = 2\nwhile p * p &lt;= limit:\n    if primes[p]:\n        for i in range(p * p, limit + 1, p):\n            primes[i] = False\n    p += 1\n\n# Create an iterator for prime numbers\nprime_iterator = (num for num in range(limit + 1) if primes[num])\n\n# Extract the prime numbers into a list\nprime_numbers = list(prime_iterator)\n\nprint(\"Prime numbers up to\", limit, \"are:\", prime_numbers)\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Generate the plot\nplt.figure(figsize=(8, 6))\nx = np.arange(len(prime_numbers))\ny = np.array(prime_numbers)\n\n# Create a colormap\nnorm = plt.Normalize(vmin=min(y), vmax=max(y))\ncmap = plt.get_cmap('Spectral')\n\n# Scatter plot with colormap\nsc = plt.scatter(x, y, c=y, cmap=cmap, norm=norm)\n\n# Fill the area below the curve with Spectral colormap\nfor i in range(len(x) - 1):\n    plt.fill_between(x[i:i + 2], 0, y[i:i + 2], color=cmap(norm(y[i])))\n\n# Add color bar\nsm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\nsm.set_array([])\n#plt.colorbar(sm, label='Prime Number')\n\n# Set labels and title\nplt.xlabel('Index')\nplt.ylabel('Prime Number')\n\nplt.show()\n\n\nPrime numbers up to 100 are: [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]\n\n\n\n\nThe Sieve of Eratosthenes",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Control Structures</span>"
    ]
  },
  {
    "objectID": "03_control_structures.html#example-from-data-hours-of-sunshine",
    "href": "03_control_structures.html#example-from-data-hours-of-sunshine",
    "title": "3  Control Structures",
    "section": "3.8 Example from data: Hours of Sunshine",
    "text": "3.8 Example from data: Hours of Sunshine\nSunshine hours play a crucial role in assessing the potential for renewable energy investment, particularly in solar power. Essentially, sunshine hours refer to the duration of time during which sunlight reaches the Earth’s surface. This metric is pivotal for determining the viability and effectiveness of solar energy generation in a particular region.\nRegions with higher sunshine hours generally have greater solar energy potential. By analyzing historical data on sunshine hours, investors and policymakers can identify areas where solar energy projects are likely to yield optimal results. This information enables strategic decision-making regarding the allocation of resources for renewable energy infrastructure.\nMoreover, sunshine hours serve as a key parameter for evaluating the economic feasibility of solar energy projects. Higher sunshine hours typically translate to increased energy production, which can lead to greater returns on investment over the project’s lifespan. Additionally, areas with abundant sunshine hours may benefit from reduced reliance on fossil fuels, thereby contributing to environmental sustainability and mitigating climate change.\nThe csv file with the following data-structure is available in the data folder. This is a short excert from the file.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\nCity\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nNov\nDec\nYear\n\n\n\n\nFinland\nHelsinki\n38.0\n70.0\n138.0\n194.0\n284.0\n297.0\n291.0\n238.0\n150.0\n93.0\n36.0\n29.0\n1858\n\n\nFrance\nLyon\n74.0\n101.0\n170.0\n191.0\n221.0\n254.0\n283.0\n253.0\n195.0\n130.0\n76.0\n54.0\n2002\n\n\nFrance\nMarseille\n150.0\n156.0\n215.0\n245.0\n293.0\n326.0\n366.0\n327.0\n254.0\n205.0\n156.0\n143.0\n2836\n\n\nFrance\nNice\n156.7\n166.1\n218.0\n229.2\n270.9\n309.8\n349.3\n223.2\n249.8\n191.1\n151.5\n145.2\n2760.5\n\n\nFrance\nParis\n63.0\n79.0\n129.0\n166.0\n194.0\n202.0\n212.0\n212.0\n168.0\n118.0\n68.0\n51.0\n1662\n\n\nGeorgia\nTbilisi\n99.0\n102.0\n142.0\n171.0\n213.0\n249.0\n256.0\n248.0\n206.0\n164.0\n103.0\n93.0\n2046\n\n\nGermany\nBerlin\n47.0\n74.0\n121.0\n159.0\n220.0\n222.0\n217.0\n211.0\n156.0\n112.0\n51.0\n37.0\n1626\n\n\nGermany\nFrankfurt\n50.0\n80.0\n121.0\n178.0\n211.0\n219.0\n233.0\n219.0\n156.0\n103.0\n51.0\n41.0\n1662\n\n\nGreece\nAthens\n130.0\n134.0\n183.0\n231.0\n291.0\n336.0\n363.0\n341.0\n276.0\n208.0\n153.0\n127.0\n2773\n\n\nHungary\nBudapest\n62.0\n93.0\n137.0\n177.0\n234.0\n250.0\n271.0\n255.0\n187.0\n141.0\n69.0\n52.0\n1988\n\n\nIceland\nReykjavik\n20.0\n60.0\n109.0\n164.0\n201.0\n174.0\n168.0\n155.0\n120.0\n93.0\n41.0\n22.0\n1326\n\n\nIreland\nDublin\n59.0\n75.0\n109.0\n160.0\n195.0\n179.0\n164.0\n157.0\n129.0\n103.0\n71.0\n53.0\n1453\n\n\nItaly\nCagliari\n150.0\n163.0\n209.0\n218.0\n270.0\n311.0\n342.0\n321.0\n243.0\n209.0\n150.0\n127.0\n2726\n\n\nItaly\nMilan\n59.0\n96.0\n152.0\n177.0\n211.0\n243.0\n285.0\n251.0\n186.0\n130.0\n66.0\n59.0\n1915\n\n\nItaly\nNaples\n115.0\n128.0\n158.0\n189.0\n245.0\n279.0\n313.0\n295.0\n234.0\n189.0\n126.0\n105.0\n2375\n\n\nItaly\nRome\n121.0\n133.0\n167.0\n201.0\n264.0\n285.0\n332.0\n298.0\n237.0\n195.0\n129.0\n112.0\n2473\n\n\n\n\n3.8.1 Identify the top 10 cities with the highest sunlight hours per year\n\nimport csv\n\n# Path to your CSV file\ncsv_file_path = 'data/Sunshine hours for cities in the world.csv'\n\nimport csv\n\nwith open(csv_file_path, mode='r') as file:\n    csv_reader = csv.reader(file)\n\n    # Read data into a list of lists\n    data = []\n\n    # Skip the header if your CSV has one\n    # headers = data.pop(0)\n\n    # Ensure the last column is numeric (int or float)\n    for row in csv_reader:\n        try:\n            row[-1] = float(row[-1])  # Convert to float\n            data.append(row)\n        except ValueError:\n            pass  # Handle the error or skip rows with non-numeric last column\n\n    \n    # Sorting in descending order\n    sorted_data = sorted(data, key=lambda x: x[-1], reverse=True)\n    city_data = []\n    # Print the 10 highest sun\n    counter = 1\n    for row in sorted_data:\n        \n        city_data.append((row[0] + '-' + row[1], row[-1]))\n        counter += 1\n        if counter &gt; 10:\n            break\ncity_data        \n\n[('United States-Yuma', 4015.3),\n ('Egypt-Marsa Alam', 3958.0),\n ('Egypt-Dakhla Oasis', 3943.4),\n ('Chile-Calama', 3926.2),\n ('United States-Phoenix', 3871.6),\n ('Namibia-Keetmanshoop', 3870.0),\n ('United States-Las Vegas', 3825.3),\n ('United States-Tucson', 3806.0),\n ('United States-El Paso', 3762.5),\n ('Sudan-Khartoum', 3737.1)]\n\n\n\n\n3.8.2 Get the average sunlight a country recieves per year and plot this data\n\nimport csv\n\n# Initialize an empty dictionary for the data\ncountry_city_sunlight = {}\n\n# Open the CSV file\nwith open(csv_file_path, 'r') as file:\n    csv_reader = csv.reader(file)\n    \n    # Skip the header row\n    next(csv_reader)\n    \n    # Iterate over each row in the CSV\n    for row in csv_reader:\n        country, city, *sunlight_hours = row\n        sunlight_hours = tuple(map(float, sunlight_hours))  # Convert sunlight hours to float and make a tuple\n        \n        # Check if the country is already in the dictionary\n        if country not in country_city_sunlight:\n            country_city_sunlight[country] = {}\n        \n        # Add the city and its sunlight hours to the country's dictionary\n        country_city_sunlight[country][city] = sunlight_hours[-1]\n\ncountry_sunlight = {}\n\nfor country, city_data in country_city_sunlight.items():\n    country_sunlight[country] = 0\n    for city, sunlight in city_data.items():\n        country_sunlight[country] += sunlight\n    country_sunlight[country] = country_sunlight[country]/len(city_data.items()) \n        \n        \ncountry_sunlight = sorted(country_sunlight.items(), key=lambda x: x[1], reverse=True)\n\n\n\nShow the code\nimport matplotlib.pyplot as plt\n\n# Unpacking the tuples into two lists\nlabels, values = zip(*country_sunlight)\n\n# Normalize values for colormap\nnorm = plt.Normalize(vmin=min(values), vmax=max(values))\ncmap = plt.get_cmap('Spectral_r') # Use 'Spectral_r' to reverse the colormap\ncolors = [cmap(norm(value)) for value in values]\n\n# Creating the plot\nplt.figure(figsize=(6, 18))\nbars = plt.barh(labels, values, color=colors)\n\n\n# Adding some labels and title for clarity\nplt.xlabel('Average Sunlight per Year [Hours]')\nplt.ylabel('Country')\n\nplt.tight_layout()  # Adjust layout to make room for the horizontal bar labels\nplt.show()\n\n\n\n\nSunshine hours per country",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Control Structures</span>"
    ]
  },
  {
    "objectID": "03_control_structures.html#exercises",
    "href": "03_control_structures.html#exercises",
    "title": "3  Control Structures",
    "section": "3.9 Exercises",
    "text": "3.9 Exercises\n\n3.9.1 Theory\n\nWrite a brief explanation of the difference between a “for” loop and a “while” loop in Python.\nExplain the purpose of the “break” and “continue” statements in Python.\nDescribe the concept of “nested” control flow in Python, and provide an example.\nWhat is the difference between an “if” statement and an “if-else” statement in Python? Provide an example of when you would use each.\nExplain the concept of “short-circuiting” in Python and provide an example.\n\n\n\n3.9.2 Coding\nWrite a Python code that:\n\ntakes a list of numbers as input and returns the sum of all the even numbers in the list.\nreads in a list of integers from the user and prints the maximum value in the list, as well as the index at which it occurs.\nprompts the user to enter a number and then uses a “for” loop to print out the first 10 multiples of that number.\nreads in a list of integers and then removes all duplicates from the list. The program should print the modified list.\nGenerate a list of prime numbers upto 1000 ! Hint: Use append() function to add items to the list !\nGenerate a list of the Fibonacci numbers ! Hint: \\(f_n = f_{n-1} + f_{n-2}\\)",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Control Structures</span>"
    ]
  },
  {
    "objectID": "03_control_structures.html#further-reading",
    "href": "03_control_structures.html#further-reading",
    "title": "3  Control Structures",
    "section": "3.10 Further Reading",
    "text": "3.10 Further Reading\n\nhttps://docs.python.org/3/tutorial/controlflow.html",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Control Structures</span>"
    ]
  },
  {
    "objectID": "04_writing_programs.html",
    "href": "04_writing_programs.html",
    "title": "4  Programs and Functions",
    "section": "",
    "text": "4.1 Programming Paradigms\nProgramming paradigms are fundamental styles or approaches to writing computer programs. They represent a set of principles, concepts, and techniques that guide how software is structured, organized, and executed. Each programming paradigm has its own philosophy and methodology for solving problems and building software. Here are some of the most commonly recognized programming paradigms:\nImperative Programming:\nImperative programming is a paradigm that focuses on changing a program’s state through sequences of statements or commands. In this paradigm, programs maintain mutable state variables that can be modified during execution. Control structures like loops and conditionals are commonly used to manage program flow.\nMathematically, imperative programming can be abstractly represented as a sequence of commands that modify a program’s state. For example, you might have an initial state \\(S\\) and then update it with a command like \\(S' = \\text{updateState}(S)\\), where \\(S\\) and \\(S'\\) represent the program state before and after executing a command, and \\(\\text{updateState}\\) is a command that modifies the state.\nKey concepts in imperative programming include variables for storing data, loops (e.g., for, while, do-while) for repetitive tasks, conditionals (e.g., if, else if, else) for decision-making, and procedures/functions for organizing code.\nFunctional Programming:\nFunctional programming is a paradigm that emphasizes immutability, meaning that once data is created, it cannot be changed. In functional programming, functions are pure, meaning they have no side effects and return consistent results for the same inputs. Functions are treated as first-class citizens, allowing them to be treated as values in the code.\nMathematically, functional programming can be represented as compositions of pure functions. For instance, you might have an equation like \\(Y = f(g(X), h(Z))\\), where \\(Y\\) represents the result, and \\(f\\), \\(g\\), and \\(h\\) are pure functions operating on inputs \\(X\\) and \\(Z\\).\nKey concepts in functional programming include pure functions, immutability (data cannot be changed once created), higher-order functions (functions that take other functions as arguments or return them), and recursion (often used instead of loops).\nObject-Oriented Programming (OOP):\nObject-oriented programming is a paradigm that revolves around objects, which encapsulate both data (attributes) and behavior (methods). Objects are instances of classes, which define blueprints for creating objects with shared attributes and methods. OOP also incorporates concepts like inheritance, where classes can inherit attributes and methods from parent classes, and encapsulation, which involves hiding internal details and exposing a public interface.\nMathematically, OOP can be represented as interactions between objects and classes. For example, you might have an equation like \\(Y = X.\\text{method}()\\), where \\(Y\\) represents the result, \\(X\\) is an object, and \\(\\text{method}()\\) is a method of the object.\nKey concepts in OOP include objects (instances of classes with attributes and methods), classes (blueprints for creating objects), inheritance (a mechanism for sharing attributes and methods between classes), and encapsulation (hiding internal implementation details and exposing a public interface).",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Programs and Functions</span>"
    ]
  },
  {
    "objectID": "04_writing_programs.html#building-blocks-of-a-program",
    "href": "04_writing_programs.html#building-blocks-of-a-program",
    "title": "4  Programs and Functions",
    "section": "4.2 Building blocks of a Program",
    "text": "4.2 Building blocks of a Program\nThe building blocks of programs are fundamental components and concepts that are used to create software and instruct computers to perform specific tasks. These building blocks can vary somewhat depending on the programming language, but they generally include the following key elements:\n\nVariables: Variables are used to store and manipulate data in a program. They can hold various types of information, such as numbers, text, or complex data structures. Variables have names and values that can change during the execution of a program.\nData Types: Programming languages have different data types, such as integers, floating-point numbers, strings, booleans, and more. Data types define the kind of values that variables can hold and the operations that can be performed on them.\nOperators: Operators are symbols or keywords used to perform operations on data. Common operators include addition (+), subtraction (-), multiplication (*), division (/), comparison (==, !=, &lt;, &gt;, etc.), and logical operations (&&, ||, !).\nArrays and Collections: These data structures allow you to group multiple pieces of data into a single variable. Arrays and collections make it easier to work with large sets of related data.\nInput and Output (I/O): Programs often need to interact with the outside world. Input mechanisms like keyboard input or reading from files, and output mechanisms like printing to the console or writing to files, enable programs to communicate with users and external devices.\nControl Structures: Control structures determine the flow of a program’s execution. They include:\n\nConditional Statements: These allow you to make decisions in your code. Common conditional statements include if, else if, else, and switch.\nLoops: Loops, such as for, while, and do-while, enable you to repeat a block of code multiple times.\nBranching: Branching mechanisms like break and continue can control the flow within loops and switch statements.\n\nFunctions/Methods: Functions (or methods, depending on the language) are reusable blocks of code that perform a specific task. They encapsulate logic, accept input (parameters), and can return results. Functions help modularize code and make it more maintainable.\nComments: Comments are not executed by the program but provide explanations and documentation for code. They are essential for making code more readable and understandable for developers and maintainers.\nError Handling: Programs need to handle errors and exceptions gracefully. Exception handling constructs allow you to catch and manage errors to prevent crashes and provide user-friendly error messages.\nClasses and Objects: In object-oriented programming languages like Java and Python, classes and objects are fundamental. Classes define blueprints for creating objects, which are instances of those classes. They encapsulate data and behavior into reusable, organized structures.\nLibraries and APIs: Programs often leverage pre-built libraries and application programming interfaces (APIs) to access external functionality. These resources provide a wide range of capabilities, from working with graphics to handling network communications.\nDocumentation: Proper documentation, including comments, inline documentation, and external documentation files, is crucial for making code understandable and maintainable.\n\nThese building blocks, when combined and structured effectively, allow programmers to design and create complex software solutions for a wide range of applications. The choice of programming language may influence how these building blocks are used, but the fundamental concepts remain consistent across most programming paradigms and languages.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Programs and Functions</span>"
    ]
  },
  {
    "objectID": "04_writing_programs.html#functions",
    "href": "04_writing_programs.html#functions",
    "title": "4  Programs and Functions",
    "section": "4.3 Functions",
    "text": "4.3 Functions\nIn programming, a function is a reusable piece of code that performs a specific task. It can take input, perform operations on that input, and then return output. Functions are essential building blocks of any program, and they allow programmers to create modular, reusable code that can be called from different parts of a program.\nIn Python, functions are defined using the def keyword, followed by the function name and any input parameters in parentheses. The function body is then indented below the function definition. Here’s an example of a simple function that takes two numbers as input and returns their sum:\n\nTask: Compute the area of circular disks for radius from 1mm to 20mm !\n\n\ndef area_of_disk(r=2, pressure=20): # r is the argument, default value is 2\n    \"\"\"\n    This is a function for computing the area of a disk !\n    \"\"\"\n    a = pressure * 3.14 * r**2\n    return a\n\n\nmy_new_disk = area_of_disk(r=10, pressure=30)\n\n\nmy_new_disk\n\n9420.0\n\n\nHaving specified the function, we can now use the function in a variety of ways ! This piece of code can be re-used multiple times by simply specifying the identifier i.e. the function name. We do not have the write the full code again.\n\n# use the function defined above inside a loop\nfor r in range(1, 4, 1):\n    print(r, area_of_disk(r))\n\n1 62.800000000000004\n2 251.20000000000002\n3 565.2\n\n\nWe could have also directly put the formula inside the for loop. However, in case we want to use the formula again in our program, then we have to type the formula. By using functions, our formula becomes portable.\nParameters and variables defined inside a function are not available outside of the function. Hence, they have a local scope and the return statement is required to return the processed data !\nHistorically, the concept of functions can be traced back to the earliest days of computer programming. Early programming languages like FORTRAN and COBOL introduced the concept of subroutines, which were essentially functions that could be called from different parts of a program. Later languages like C and Pascal expanded on this concept, introducing functions that could take parameters and return values.\nPython was first released in 1991 and quickly gained popularity due to its ease of use and readability. The concept of functions has been a fundamental part of the language since its inception. Python’s support for functions has made it a popular choice for scientific computing, web development, and many other domains.\nIn the future, the concept of functions will continue to be an important part of programming, as it allows developers to create modular, reusable code. As programming languages continue to evolve and new technologies emerge, the concept of functions will likely remain a fundamental building block of software development.\n\n4.3.1 args and kwargs\nIn Python, args and kwargs are special parameters that allow you to pass a variable number of arguments to a function. args stands for “arguments” and is used to pass a variable number of non-keyword arguments to a function. It is represented by a tuple of values. kwargs stands for “keyword arguments” and is used to pass a variable number of keyword arguments to a function. It is represented by a dictionary of key-value pairs.\n\ndef my_function(*args, **kwargs):\n    \"\"\"\n    a function that prints args and kwargs!\n    \"\"\"\n    print(args) # args is a tuple with a list of elements\n    print(kwargs) # kwargs is a dictionary with key value pairs\n\n\nmy_function(1, 2, 3, a='hello', b='world')\n\n(1, 2, 3)\n{'a': 'hello', 'b': 'world'}\n\n\nIn this example, *args collects any number of non-keyword arguments passed to the function and packs them into a tuple. **kwargs collects any number of keyword arguments passed to the function and packs them into a dictionary. Note that args and kwargs are just conventions, and you can use any other variable names instead. However, using these conventions makes it easier for other developers to understand your code.\nThe single star * and double star ** in front of args and kwargs, respectively, are known as the “unpacking operators” in Python. They are used to unpack sequences and dictionaries, respectively, into separate arguments when calling a function.\nWhen you use *args in a function definition, it tells Python to accept any number of positional arguments (i.e., arguments that are not passed as key-value pairs) and pack them into a tuple. Similarly, when you use **kwargs, it tells Python to accept any number of keyword arguments (i.e., arguments that are passed as key-value pairs) and pack them into a dictionary.\nWhen you call a function that uses *args and **kwargs, you can use the unpacking operators to pass a sequence or dictionary as separate arguments to the function. Here’s an example:\n\ndef my_function(a, b, *args, **kwargs):\n    \"\"\"\n    a function that prints two non-keyword parameters and the args and kwargs\n    \"\"\"\n    print(f'a={a}, b={b}')\n    print(f'args={args}')\n    print(f'kwargs={kwargs}')\n\n\nmy_tuple = (10, 20, 30)\nmy_dict = {'x': 4, 'y': 5, 'z': 6}\nmy_function(0, 9, *my_tuple, **my_dict)\n\na=0, b=9\nargs=(10, 20, 30)\nkwargs={'x': 4, 'y': 5, 'z': 6}\n\n\n\ndef my_function_1(parameter_1=2, parameter_2=100, parameter_3=30):\n    \"\"\"\n    this function takes in two parameters and computes the product and sum of the parameters\n    \"\"\"\n    product_of_parameters = parameter_1 * parameter_2 * parameter_3\n    sum_of_parameters = parameter_1 + parameter_2 + parameter_3\n    return (product_of_parameters, sum_of_parameters)\n\n\nvariable_1 = my_function_1(parameter_1=1650, parameter_2=1420, parameter_3=50)\n\n\nvariable_1\n\n(117150000, 3120)",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Programs and Functions</span>"
    ]
  },
  {
    "objectID": "04_writing_programs.html#lambda-and-special-functions",
    "href": "04_writing_programs.html#lambda-and-special-functions",
    "title": "4  Programs and Functions",
    "section": "4.4 Lambda and special functions",
    "text": "4.4 Lambda and special functions\nLambda functions are a way to create small functions in Python. They are defined using the lambda keyword and are often used as a quick way to define a function that will only be used once.\nHere’s an example of a lambda function that takes a single argument and returns its square:Lambda functions are one-line functions ! Also called anonymous functions. Often used to specify functions within another function !\n\nimport math\n\n\narea = lambda r : math.pi * r * r  # function to generate the area of a circle given the area\n\n\nprint(area(2))\n\n12.566370614359172\n\n\n\n4.4.1 Map\nThe map() function in Python takes a function and an iterable as input, and returns a new iterable where each element has been transformed by the function. Here’s an example:\n\nnumbers = [1, 2, 3, 4, 5]\n\n\ndef my_function_test(x):\n    \"\"\"\n    a function to return the square of the input scalar\n    \"\"\"\n    return x**2\n\n\nsquares_function = map(my_function_test, numbers)\n\n\nlist(squares_function)\n\n[1, 4, 9, 16, 25]\n\n\n\nsquares_lambda = map(lambda x: x**2, numbers)\n\n\nlist(squares_lambda)\n\n[1, 4, 9, 16, 25]\n\n\nIn this example, numbers is an iterable containing the numbers 1 through 5. The map() function applies the lambda function lambda x: x**2 to each element in the iterable, returning a new iterable containing the squares of each number. The squares variable in this example will contain the iterable [1, 4, 9, 16, 25].\n\n\n4.4.2 Filter\nThe filter() function in Python takes a function and an iterable as input, and returns a new iterable containing only the elements for which the function returns True. Here’s an example:\n\nnumbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1000, 1200, 1201]\n\n\n# demonstrate the functionality of the filter function ! filter(condition, data structure)\neven_numbers = filter(lambda x: x % 2 == 0, numbers)\nlist(even_numbers)\n\n[2, 4, 6, 8, 10, 1000, 1200]\n\n\nIn this example, numbers is an iterable containing the numbers 1 through 5. The filter() function applies the lambda function lambda x: x % 2 == 0 to each element in the iterable, returning a new iterable containing only the even numbers. The even_numbers variable in this example will contain the iterable [2, 4].\n\n\n4.4.3 Reduce\nThe reduce() function in Python takes a function and an iterable as input, and returns a single value that is the result of applying the function to the iterable in a cumulative way. Here’s an example:\n\n# demonstrate the functionality of the reduce function\nfrom functools import reduce\n\nnumbers = [1, 2, 3, 4, 5]\ndifference = reduce(lambda x, y: x - y, numbers) # (((1 - 2) - 3) - 4) - 5\nprint(difference)\n\n-13\n\n\nIn this example, numbers is an iterable containing the numbers 1 through 5. The reduce() function applies the lambda function lambda x, y: x * y to the first two elements in the iterable (1 and 2), then applies the same function to the result and the next element in the iterable (3), and so on, until all elements in the iterable have been processed.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Programs and Functions</span>"
    ]
  },
  {
    "objectID": "04_writing_programs.html#decorators",
    "href": "04_writing_programs.html#decorators",
    "title": "4  Programs and Functions",
    "section": "4.5 Decorators",
    "text": "4.5 Decorators\nDecorators in Python are a powerful feature that allow you to modify the behavior of a function or method without changing its code. They are widely used in scientific and engineering applications for purposes such as timing functions, caching results, or enforcing type checks. Here’s a practical example related to scientific computing where decorators can be particularly useful:\n\nThese are higher-order functions that take a function as an argument and return a new function with enhanced functionality.\nDecorators wrap a function, modifying its behavior.\nDefined with the @ symbol, followed by the decorator name, placed above the function definition.\nA decorator is just a callable Python object that is used to modify a function or a class.\nExample of a simple decorator:\n\n\ndef my_decorator(func):\n    def wrapper():\n        print(\"Something is happening before the function is called.\")\n        func()\n        print(\"Something is happening after the function is called.\")\n    return wrapper\n\n@my_decorator\ndef say_hello():\n    print(\"Hello!\")\n\nsay_hello()\n\nSomething is happening before the function is called.\nHello!\nSomething is happening after the function is called.\n\n\n\nimport time\n\n# Define the decorator\ndef log_execution_time(func):\n    def wrapper(*args, **kwargs):\n        start_time = time.time()  # Record the start time\n        result = func(*args, **kwargs)  # Call the original function\n        end_time = time.time()  # Record the end time\n        execution_time = end_time - start_time  # Calculate execution time\n        print(f\"{func.__name__} executed in {execution_time:.4f} seconds\")\n        return result\n    return wrapper\n\n# Example usage with the decorator\n@log_execution_time\ndef my_expensive_computation(n):\n    # Example expensive operation: calculate the sum of squares up to n\n    return sum(i**2 for i in range(n))\n\n# Now calling the decorated function will display its execution time\nresult = my_expensive_computation(1000000)\n\nmy_expensive_computation executed in 0.0389 seconds\n\n\n\n4.5.1 Finding Square Root\nThe square-root of a number \\(S\\) can be computed by iteration as follows:\n\ndef square_root(n, iterations=10):\n    x = n\n    for _ in range(iterations):\n        x = 0.5 * (x + n / x)\n    return x\n\n# Example usage\nn = 500\nprint(\"Square root of\", n, \":\", square_root(n))\n\nSquare root of 500 : 22.360679774997898",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Programs and Functions</span>"
    ]
  },
  {
    "objectID": "04_writing_programs.html#classes",
    "href": "04_writing_programs.html#classes",
    "title": "4  Programs and Functions",
    "section": "4.6 Classes",
    "text": "4.6 Classes\nPython is an object oriented programming language. Everything in Python is an object.\n\nA class in Python defines the structure and behavior of an object. It’s like a blueprint from which individual objects are created.\nEach object created from a class is known as an instance of that class.\nA class encapsulates, or bundles together, data and the functions that operate on that data.\nThe data in a class is held in attributes, which are variables that belong to the class.\nThe functions inside a class are called methods. They define the behavior of the class and can manipulate the class attributes or perform operations relevant to the class.\nIn Python, you define a class using the class keyword, followed by the class name and a colon. For example:\n\n\nclass Experiment:\n    pass\n\n\nOnce a class is defined, you can create objects (instances) from it. For the Experiment class, creating an instance would look like this:\n\n\nmy_experiment = Experiment()\n\n\nAttributes and Methods:\n\nAttributes can be added to a class to store information about the state of an instance. For example, a Experiment class might have attributes like name and type.\nMethods are functions defined within a class and are used to define the behaviors of an instance. For instance, an Experiment class might have methods like analyse or visualize.\nClass attributes and methods are crucial to Python classes, with attributes being shared variables among all instances, and methods as functions that act on these attributes to define object behaviors. Class attributes, set within the class but outside methods, are accessible by both the class and its instances, ideal for constants or default values shared by all instances. In contrast, instance attributes, defined within the __init__ method, are specific to each object, allowing for customization. Methods, needing at least one parameter (self), manipulate both class and instance attributes, highlighting the class design’s flexibility to accommodate shared and unique object data. This distinction enables both commonality through class attributes and individuality via instance attributes, with methods facilitating interactions and behaviors across this framework.\n\n\n\n4.6.1 Inheritance in Python\nInheritance is a fundamental concept in object-oriented programming (OOP). It allows us to define a class that inherits all the methods and properties from another class.\n\nInheritance enables new classes, known as subclasses, to receive and extend the properties and methods of existing classes, known as parent or base classes.\nIt’s used to create a new class with little or no modification to an existing class. The new class can add new methods and properties or modify existing ones.\nCreating a Subclass: In Python, you create a subclass by simply declaring a new class and putting the name of the parent class in parentheses.\n\n\nclass BaseClass:\n    pass\n\nclass SubClass(BaseClass):\n    pass\n\n\nInheriting Features: The subclass inherits all methods and properties from the parent class.\nPython supports multiple inheritance, where a subclass can inherit from multiple parent classes.\nMethod Resolution Order (MRO): In the case of multiple inheritance, Python uses a specific order (MRO) to look up methods. This order is defined in a tuple called __mro__ in the class.\nIf you want to change the behavior of a method in your subclass that is defined in its parent class, you simply redefine it. This is known as method overriding.\n\n\nclass BaseClass:\n    def print_message(self):\n       print(\"This is a message from the Base Class\")\n\nclass SubClass(BaseClass):\n    def print_message(self):\n       print(\"This is a message from the Sub Class\")\n\n\nSometimes you want to extend rather than entirely replace a parent class method. You can do this using super() to call the parent class method.\n\n\nclass SubClass(BaseClass):\n    def print_message(self):\n        super().print_message()\n        print(\"This is an additional message from the Sub Class\")\n\n\ntest = SubClass()\ntest.print_message()\n\nThis is a message from the Base Class\nThis is an additional message from the Sub Class\n\n\n\n\n4.6.2 Class Decorators\n@staticmethod is used to declare a method within a class as a static method, which means it doesn’t require a reference to a class or instance.\n\nclass MyClass:\n    @staticmethod\n    def my_static_method():\n        print(\"This is a static method\")\n\nMyClass.my_static_method()\n\nThis is a static method\n\n\n\n\n\n\n\n\n\n\nDecorator\nMeaning\n\n\n\n\n\n@classmethod\nConverts a method into a class method, which means it receives the class as the first argument instead of an instance. It can access class attributes but not instance attributes.\n\n\n\n@staticmethod\nConverts a method into a static method, which does not receive an implicit first argument (neither self nor cls). It’s a way to namespace functions in a class.\n\n\n\n@property\nConverts a method into a property, allowing you to access it as an attribute instead of calling it as a method. Useful for defining getters.\n\n\n\n@&lt;property&gt;.setter\nUsed in conjunction with @property to define the setter method for a property, allowing you to set the value of a property.\n\n\n\n@&lt;property&gt;.deleter\nUsed alongside @property to define the deleter method of a property, enabling you to delete a property.\n\n\n\n@functools.wraps\nUsed in decorator definitions to preserve the wrapped function’s metadata, such as its name and docstring.\n\n\n\n@functools.lru_cache\nCaches the results of a function, storing the result of expensive function calls and using the cached value when the same inputs occur again.\n\n\n\n@functools.singledispatch\nTransforms a function into a single-dispatch generic function, allowing it to have different behaviors based upon the type of the first argument.\n\n\n\n\n\n\n4.6.3 __ Double Underscore methods\nMagic methods in Python, also known as dunder (double underscore) methods, are special methods with fixed names that Python calls in certain circumstances. They allow us to define how instances of a class behave under different operations like when they’re printed, added together, or have their length checked.\n\n4.6.3.1 The __init__ Method\nThe __init__ method in Python is a special method used for initializing new objects of a class. It’s often referred to as a constructor in other programming languages. Here’s a brief description:\n\nThe __init__ method is automatically invoked when a new instance of a class is created. Its primary role is to assign values to the object’s properties or perform any other necessary initialization.\nIt is defined within a class, and its first parameter is always self, which represents the instance of the class. Additional parameters can be added to pass data to initialize the object.\nExample:\n\n\nclass Experiment:\n    def __init__(self, name, date):\n        self.name = name  # instance attribute\n        self.date = date  # instance attribute\n\n# Creating an instance \nmy_Experiment = Experiment('Temperature_flux', '5/March/2050')\n\nIn this example, when Experiment('Temperature_flux', '5/March/2050') is executed, the __init__ method is called with self being the newly created object and name, date being ‘Temperature_flux’, 5/March/2050 respectively.\n\nWhile __init__ is commonly used, it’s not mandatory. If not defined, Python provides a default __init__ that does nothing.\nThe __init__ method cannot return anything other than None. Its purpose is purely initialization.\n\nHere’s an overview of some common magic methods:\n\n\n\n\n\n\n\n\nDunder Method\nMeaning\n\n\n\n\n\ninit(self, …)\nConstructor method for initializing a new instance of a class.\n\n\n\ndel(self)\nCalled when an instance is about to be destroyed. Useful for cleanup operations.\n\n\n\nrepr(self)\nCalled by the repr() built-in function and by string conversions to produce a string representation of an object for debugging.\n\n\n\nstr(self)\nCalled by the str() function and by the print statement to produce a more user-friendly string representation of an object.\n\n\n\ncall(self, …)\nAllows an instance of a class to be called as a function.\n\n\n\ngetattr(self, name)\nCalled when an attribute lookup has not found the attribute in the usual places.\n\n\n\nsetattr(self, name, value)\nCalled when an attribute assignment is attempted.\n\n\n\ndelattr(self, name)\nCalled when an attribute deletion is attempted.\n\n\n\nlt(self, other)\nDefines behavior for the less than operator &lt;.\n\n\n\nle(self, other)\nDefines behavior for the less than or equal to operator &lt;=.\n\n\n\neq(self, other)\nDefines behavior for the equality operator ==.\n\n\n\nne(self, other)\nDefines behavior for the inequality operator !=.\n\n\n\ngt(self, other)\nDefines behavior for the greater than operator &gt;.\n\n\n\nge(self, other)\nDefines behavior for the greater than or equal to operator &gt;=.\n\n\n\nadd(self, other)\nDefines behavior for the addition operator +.\n\n\n\nsub(self, other)\nDefines behavior for the subtraction operator -.\n\n\n\nmul(self, other)\nDefines behavior for the multiplication operator *.\n\n\n\ntruediv(self, other)\nDefines behavior for the division operator /.\n\n\n\nfloordiv(self, other)\nDefines behavior for the floor division operator //.\n\n\n\nmod(self, other)\nDefines behavior for the modulus operator %.\n\n\n\npow(self, other)\nDefines behavior for the exponent operator **.\n\n\n\ngetitem(self, key)\nCalled to retrieve an item from the object for the given key (like in a dictionary or list).\n\n\n\nsetitem(self, key, value)\nCalled to set an item on the object for the given key.\n\n\n\ndelitem(self, key)\nCalled to delete an item from the object for the given key.\n\n\n\niter(self)\nShould return an iterator for the object.\n\n\n\nnext(self)\nCalled to produce the next value in a sequence during iteration.\n\n\n\n\n\n\n\n4.6.4 Encapsulation\nIn Python, private and protected members are used to enforce encapsulation, a fundamental concept in object-oriented programming. Encapsulation refers to the bundling of data with the methods that operate on that data, and restricting direct access to some of the object’s components. This concept is not enforced by the language itself but by a convention respected among programmers. Here’s how private and protected members work in Python:\n\nIndicated by a double underscore __ prefix (e.g., __privateAttribute).\nNot actually private; it’s a convention to treat them as non-public parts of the API.\nPython performs name mangling: any identifier with two leading underscores is textually replaced with _classname__identifier, making it harder (but not impossible) to access from outside the class.\n\n\nclass MyClass:\n    def __init__(self):\n        self.__privateAttribute = 42\n\n    def __privateMethod(self):\n        print(\"This is a private method\")\n\nobj = MyClass()\n#obj.__privateAttribute  # This will raise an AttributeError",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Programs and Functions</span>"
    ]
  },
  {
    "objectID": "04_writing_programs.html#a-functioning-program",
    "href": "04_writing_programs.html#a-functioning-program",
    "title": "4  Programs and Functions",
    "section": "4.7 A functioning program:",
    "text": "4.7 A functioning program:\n\nimport datetime\n\n\nclass Experiment:\n    university = 'TUM'  # Class attribute\n    \n    def __init__(self, name):\n        \"\"\"\n        A constructor initialized with name!\n        \"\"\"\n        self.name = name\n        self.measurements = []\n        self.location = None\n        self.person = None\n        self.cost = None\n    \n    \n    def update_measurements(self, data):\n        \"\"\"\n        this function updates the measurements !\n        \"\"\"\n        print('data updated !')\n        current_time =  datetime.datetime.now()\n        self.measurements.append([data, current_time.strftime(\"%c\")])\n        \n    def update_location(self, location_name):\n        \"\"\"\n        this function updates the location\n        \"\"\"\n        self.location = location_name \n        \n    def cost_in_dollars(self, currency_exchange_rate):\n        return self.cost * currency_exchange_rate \n\nHaving implemented the class Experiment, we can start constructing objects of the type Experiment. This objects can be manipulated / updated using the functions defined int he class!\n\ne1 = Experiment('XVBjhjN1')\n\n\ne1\n\n&lt;__main__.Experiment at 0x107d80750&gt;\n\n\n\nprint(e1.person)\n\nNone\n\n\n\ne2 = Experiment('new_exp')\n\n\ne2.update_location('Arcisstr 21')\n\nNow let us update the location of the object e1\n\ne1.update_location('Pasing')\n\n\nprint(e2.location)\n\nArcisstr 21\n\n\nIn case we have measurements, then we can put these measurements in an array and then insert this array into the object using the update_measurements function.\n\nnew_data = [1, 2, 4, 8]\n\n\ne1.update_measurements(new_data)\nprint(e1.measurements)\n\ndata updated !\n[[[1, 2, 4, 8], 'Sat Jul 13 23:06:14 2024']]\n\n\n\ne1.update_measurements([4, 5, 6, 7])\n\ndata updated !\n\n\n\nprint(e1.measurements)\n\n[[[1, 2, 4, 8], 'Sat Jul 13 23:06:14 2024'], [[4, 5, 6, 7], 'Sat Jul 13 23:06:14 2024']]\n\n\n\nprint(e1.location)\n\nPasing\n\n\n\nprint(e2.location)\n\nArcisstr 21\n\n\nCommon pitfalls:\n\nOveruse of classes: It’s important to use classes judiciously, as overusing them can lead to code that is difficult to understand and maintain. If a simpler approach is sufficient, it’s often better to use functions or modules instead of classes.\nInconsistent naming conventions: It’s important to follow consistent naming conventions when defining classes and their attributes and methods. This can help to improve code readability and maintainability.\nTight coupling: Classes can become tightly coupled, which means that changes to one class can have unintended consequences on other parts of the code. It’s important to design classes with loose coupling in mind, which means that they should be independent and not rely too much on other classes.\nPoor design: Poorly designed classes can be difficult to use and maintain. It’s important to design classes with a clear purpose and a well-defined public interface. Additionally, classes should be tested thoroughly to ensure that they work as intended.\n\nBenefits:\n\nObject-oriented programming: Python is an object-oriented programming (OOP) language, and classes are the building blocks of OOP. Classes allow you to define objects with their own attributes and methods, which makes it easier to organize and structure your code.\nCode reusability: With classes, you can create objects that can be reused in different parts of your code, which can save time and effort.\nInheritance: Classes in Python support inheritance, which means that you can create a new class by inheriting from an existing class. This can save time and effort, as you can reuse the existing code and only modify or add what is necessary.\nEncapsulation: Classes allow you to encapsulate data and methods, which means that you can hide implementation details and only expose a public interface. This can help to reduce complexity and improve code maintainability.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Programs and Functions</span>"
    ]
  },
  {
    "objectID": "04_writing_programs.html#a-program-in-three-paradigms",
    "href": "04_writing_programs.html#a-program-in-three-paradigms",
    "title": "4  Programs and Functions",
    "section": "4.8 A Program in three Paradigms",
    "text": "4.8 A Program in three Paradigms\nA simple program that calculates the factorial of a number using three different programming paradigms: procedural, object-oriented, and functional programming.\n\n# Procedural Programming:\n\ndef factorial_procedural(n):\n    result = 1\n    for i in range(1, n + 1):\n        result *= i\n    return result\n\nnum = 25\nprint(f\"Factorial (Procedural): {factorial_procedural(num)}\")\n\nFactorial (Procedural): 15511210043330985984000000\n\n\n\n# Object-Oriented Programming:\n\nclass FactorialCalculator:\n    def __init__(self, n):\n        self.n = n\n\n    def calculate(self):\n        result = 1\n        for i in range(1, self.n + 1):\n            result *= i\n        return result\n\nnum = 25\ncalculator = FactorialCalculator(num)\nprint(f\"Factorial (Object-Oriented): {calculator.calculate()}\")\n\nFactorial (Object-Oriented): 15511210043330985984000000\n\n\n\n# Functional Programming:\n\n\nfrom functools import reduce\n\ndef factorial_functional(n):\n    return reduce(lambda x, y: x * y, range(1, n + 1), 1)\n\nnum = 25\nprint(f\"Factorial (Functional): {factorial_functional(num)}\")\n\nFactorial (Functional): 15511210043330985984000000\n\n\nThese programs all calculate the factorial of a number entered by the user, but they do so using different programming paradigms. The procedural version uses a loop, the object-oriented version encapsulates the functionality in a class, and the functional version uses the reduce function to calculate the factorial.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Programs and Functions</span>"
    ]
  },
  {
    "objectID": "04_writing_programs.html#exercises",
    "href": "04_writing_programs.html#exercises",
    "title": "4  Programs and Functions",
    "section": "4.9 Exercises",
    "text": "4.9 Exercises\n\n4.9.1 Theory\n\nWhat is the difference between a function and a method in Python?\nWhat is the purpose of the “self” parameter in a class method?\nWhat is the difference between the “map” and “filter” functions in Python?\nWhat is the purpose of the “reduce” function in Python?\nWhat is a lambda function, and how is it different from a regular function?\n\n\n\n4.9.2 Coding\n\nWrite a Python function that takes a list of integers as input and returns the sum of all the even numbers in the list.\nWrite a Python class that represents a rectangle, with methods for calculating its area and perimeter.\nUse the “map” function to create a new list that contains the squares of all the numbers in an existing list.\nUse the “filter” function to create a new list that contains only the numbers smaller than 4 from a list that also has numbers larger than 4.\nUse the “reduce” function to calculate the cumulative differences of all the numbers in an existing list.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Programs and Functions</span>"
    ]
  },
  {
    "objectID": "04_writing_programs.html#further-reading",
    "href": "04_writing_programs.html#further-reading",
    "title": "4  Programs and Functions",
    "section": "4.10 Further Reading",
    "text": "4.10 Further Reading\n\nhttps://docs.python.org/3/tutorial/classes.html\nhttps://docs.python.org/3/howto/functional.html?highlight=lambda\nhttps://rszalski.github.io/magicmethods/",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Programs and Functions</span>"
    ]
  },
  {
    "objectID": "05_numpy.html",
    "href": "05_numpy.html",
    "title": "5  Arrays and Array Operations using NumPy",
    "section": "",
    "text": "5.1 Generating an Array from lists and tuples\nFor example, to create new vector and matrix arrays from Python lists we can use the numpy.array function.\nl = [1, 2, 3, 4] # list mutable\nt = (1, 2, 3, 4) # tuple immutable\n\nv = np.array(l) # Numpy Array using l or t\n\nv\n\narray([1, 2, 3, 4])\nConsider the following matrix, a two dimensional data structure. Where data is related by thier positions in a two dimensional grid !\n\\[ \\begin{bmatrix}\n1 & 2 & 3 \\\\\n2 & 4 & 5 \\\\\n3 & 5 & 6\n\\end{bmatrix}  \\]\nl_2d = [[1.0, 2, 3], [2, 4, 5], [3, 5, 6]]\n\nM = np.array(l_2d)\n\nM\n\narray([[1., 2., 3.],\n       [2., 4., 5.],\n       [3., 5., 6.]])\nThe v and M belong to the ndarray type as you can find out from the following test !\ntype(v), type(M)\n\n(numpy.ndarray, numpy.ndarray)\nWe can get the shape of an array by using the ndarray.shape property.\nM.shape\n\n(3, 3)\nThe number of elements in the array is available through the ndarray.size property:\nM.size\n\n9\nEquivalently, we could use the function numpy.shape and numpy.size\nnp.shape(M)\n\n(3, 3)\nnp.size(M)\n\n9\nWhat is the benefit of using NumPy instead of using Python lists ?\nUsing the numpy specific attribute dtype (data type), we can see what type the data of an array is:\nM.dtype\n\ndtype('float64')\nIf we update a value inside the array as a floating point, the value will be reverted to an integer version.\nprint(np.pi)\n\n3.141592653589793\nM[1, 1] = np.pi\nM\n\narray([[1.        , 2.        , 3.        ],\n       [2.        , 3.14159265, 5.        ],\n       [3.        , 5.        , 6.        ]])\nIf we try to introduce a string type, the operation fails. Thus in contrast to a Python list, Numpy arrays are homogeneous ! We can also explicitly define the type of the array data when we create it, using the dtype keyword argument:\nM = np.array(l_2d, dtype=complex)\n\nM\n\narray([[1.+0.j, 2.+0.j, 3.+0.j],\n       [2.+0.j, 4.+0.j, 5.+0.j],\n       [3.+0.j, 5.+0.j, 6.+0.j]])\nCommon data types that can be used with dtype are: int, float, complex, bool, object, etc. Specifying the datatype can save memory ! Here is the list of numeric data types and the associated memory footprint !\nimport sys\nprint('Size of the Matrix Array is '+ str(sys.getsizeof(M)) + ' bytes')\n\nSize of the Matrix Array is 272 bytes",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Arrays and Array Operations using NumPy</span>"
    ]
  },
  {
    "objectID": "05_numpy.html#generating-an-array-from-lists-and-tuples",
    "href": "05_numpy.html#generating-an-array-from-lists-and-tuples",
    "title": "5  Arrays and Array Operations using NumPy",
    "section": "",
    "text": "Note:\n\n\n\nThe package name is required if the variable is passed to the function. Using the dot notation, the function already knows the data type !\n\n\n\n\nLists and Tuples can contain any kind of object but in contrast the Numpy arrays are homogeneous and all items in a numpy array are of the same type and hence creation, manipulation of Numpy arrays etc. are efficient\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumpy data type\nStorage Size\nDescription\n\n\n\n\nnp.bool_\n1 byte\ncan hold boolean values, like (True or False) or (0 or 1)\n\n\nnp.byte\n1 byte\ncan hold values from 0 to 255\n\n\nnp.ubyte\n1 byte\ncan hold values from -128 to 127\n\n\nnp.short\n2 bytes\ncan hold values from -32,768 to 32,767\n\n\nnp.ushort\n2 bytes\ncan hold values from 0 to 65,535\n\n\nnp.uintc\n2 or 4 bytes\ncan hold values from 0 to 65,535 or 0 to 4,294,967,295\n\n\nnp.int_\n8 bytes\ncan hold values from -9223372036854775808 to 9223372036854775807\n\n\nnp.uint\n8 bytes\n0 to 18446744073709551615\n\n\nnp.longlong\n8 bytes\ncan hold values from -9223372036854775808 to 9223372036854775807\n\n\nnp.ulonglong\n8 bytes\n0 to 18446744073709551615\n\n\nnp.half / np.float16\n\nallows half float precision with Format: sign bit, 5 bits exponent, 10 bits mantissa\n\n\nnp.single\n4 bytes\nallows single float precision Format: sign bit, 8 bits exponent, 23 bits mantissa\n\n\nnp.double\n8 bytes\nallows double float precision Format: sign bit, 11 bits exponent, 52 bits mantissa.\n\n\nnp.longdouble\n8 bytes\nextension of float\n\n\nnp.csingle\n8 bytes\ncan hold complex with real and imaginary parts up to single-precision float\n\n\nnp.cdouble\n16 bytes\ncan hold complex with real and imaginary parts up to double-precision float\n\n\nnp.clongdouble\n16 bytes\nextension of float for complex number\n\n\nnp.int8\n1 byte\ncan hold values from -128 to 127\n\n\nnp.int16\n2 bytes\ncan hold values from -32,768 to 32,767\n\n\nnp.int32\n4 bytes\ncan hold values from -2,147,483,648 to 2,147,483,647\n\n\nnp.int64\n8 bytes\ncan hold values from -9223372036854775808 to 9223372036854775807\n\n\nnp.uint8\n1 byte\ncan hold values from 0 to 255\n\n\nnp.uint16\n2 bytes\ncan hold values from 0 to 65,535\n\n\nnp.uint32\n4 bytes\ncan hold values from 0 to 4,294,967,295\n\n\nnp.uint64\n8 bytes\ncan hold values from 0 to 18446744073709551615\n\n\nnp.intp\n4 bytes\na signed integer used for indexing\n\n\nnp.uintp\n4 bytes\nan unsigned integer used for holding a pointer\n\n\nnp.float32\n4 bytes\nsingle float precision\n\n\nnp.float64\n8 bytes\ndouble float precision\n\n\nnp.complex64\n8 bytes\nsingle float precision in complex numbers\n\n\nnp.complex128\n16 bytes\ndouble float precision in complex numbers",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Arrays and Array Operations using NumPy</span>"
    ]
  },
  {
    "objectID": "05_numpy.html#creating-an-array-using-array-generating-functions",
    "href": "05_numpy.html#creating-an-array-using-array-generating-functions",
    "title": "5  Arrays and Array Operations using NumPy",
    "section": "5.2 4.2 Creating an Array using array-generating functions",
    "text": "5.2 4.2 Creating an Array using array-generating functions\nFor larger arrays it is impractical to initialize the data manually, using explicit python lists. Instead we can use one of the many functions in numpy that generate arrays of different forms. Some of the more common are:\n\n5.2.1 4.2.1 arange\n\n# create a range of data starting at 0 and ending at(15-1) and incremented by 1\n\nx = np.arange(0, 15, 1) # arguments: start, stop, step \n\nx\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])\n\n\nAlso floating point values can be generated. Let us create a list of real numbers. Let the list be some x.\n\nx = np.arange(-1, 1.1, 0.1)\n\nx\n\narray([-1.00000000e+00, -9.00000000e-01, -8.00000000e-01, -7.00000000e-01,\n       -6.00000000e-01, -5.00000000e-01, -4.00000000e-01, -3.00000000e-01,\n       -2.00000000e-01, -1.00000000e-01, -2.22044605e-16,  1.00000000e-01,\n        2.00000000e-01,  3.00000000e-01,  4.00000000e-01,  5.00000000e-01,\n        6.00000000e-01,  7.00000000e-01,  8.00000000e-01,  9.00000000e-01,\n        1.00000000e+00])\n\n\nHaving defined x, we can then generate functions using the inbuilt numpy function library of mathematical functions !\nhttps://numpy.org/doc/stable/reference/routines.math.html\n\\(f(x) = x^4\\)\nWe can make plots using the matplotlib.pyplot library and using the the syntax as given below ! Commands that start with % in Jupyter are specific to the Jupyter notebook. Here we use the matplotlib inline to tell Jupyter to plot the images in this notebook !\n\n%matplotlib inline \nimport matplotlib.pyplot as plt\n\n\nx\n\narray([-1.00000000e+00, -9.00000000e-01, -8.00000000e-01, -7.00000000e-01,\n       -6.00000000e-01, -5.00000000e-01, -4.00000000e-01, -3.00000000e-01,\n       -2.00000000e-01, -1.00000000e-01, -2.22044605e-16,  1.00000000e-01,\n        2.00000000e-01,  3.00000000e-01,  4.00000000e-01,  5.00000000e-01,\n        6.00000000e-01,  7.00000000e-01,  8.00000000e-01,  9.00000000e-01,\n        1.00000000e+00])\n\n\n\nx**4\n\narray([1.00000000e+00, 6.56100000e-01, 4.09600000e-01, 2.40100000e-01,\n       1.29600000e-01, 6.25000000e-02, 2.56000000e-02, 8.10000000e-03,\n       1.60000000e-03, 1.00000000e-04, 2.43086534e-63, 1.00000000e-04,\n       1.60000000e-03, 8.10000000e-03, 2.56000000e-02, 6.25000000e-02,\n       1.29600000e-01, 2.40100000e-01, 4.09600000e-01, 6.56100000e-01,\n       1.00000000e+00])\n\n\n\nplt.plot(x, x**4)\n\n\n\n\n\n\n\n\n\n\n5.2.2 linspace\nUsing linspace (linear space) we can generate a specified number of data points within a given range. The range end points are also included.\n\nnp.linspace(0, 10, 50) # start, end, number of items\n\narray([ 0.        ,  0.20408163,  0.40816327,  0.6122449 ,  0.81632653,\n        1.02040816,  1.2244898 ,  1.42857143,  1.63265306,  1.83673469,\n        2.04081633,  2.24489796,  2.44897959,  2.65306122,  2.85714286,\n        3.06122449,  3.26530612,  3.46938776,  3.67346939,  3.87755102,\n        4.08163265,  4.28571429,  4.48979592,  4.69387755,  4.89795918,\n        5.10204082,  5.30612245,  5.51020408,  5.71428571,  5.91836735,\n        6.12244898,  6.32653061,  6.53061224,  6.73469388,  6.93877551,\n        7.14285714,  7.34693878,  7.55102041,  7.75510204,  7.95918367,\n        8.16326531,  8.36734694,  8.57142857,  8.7755102 ,  8.97959184,\n        9.18367347,  9.3877551 ,  9.59183673,  9.79591837, 10.        ])\n\n\n\n\n5.2.3 logspace\nUsing logspace we can generate logarithmically spaced points !\n\\[ base^{start} \\rightarrow base^{end}\\]\n\nlgspace = np.logspace(0, 10, 10, base=2) # start, end, number of items, base\n\n\nlgspace\n\narray([1.00000000e+00, 2.16011948e+00, 4.66611616e+00, 1.00793684e+01,\n       2.17726400e+01, 4.70315038e+01, 1.01593667e+02, 2.19454460e+02,\n       4.74047853e+02, 1.02400000e+03])\n\n\n\nplt.plot(lgspace)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n5.2.4 mgrid\nSimilar to creating a one dimensional data (series data), two dimensional data can also be generated !\n\nx, y = np.mgrid[0:3, 0:3] # similar to the arange. : is used to demarcate the ranges. \n\n\nx\n\narray([[0, 0, 0],\n       [1, 1, 1],\n       [2, 2, 2]])\n\n\n\ny\n\narray([[0, 1, 2],\n       [0, 1, 2],\n       [0, 1, 2]])\n\n\n\n\n5.2.5 random data\nwe can also generate an array with random data ! The function random.rand\nhttps://numpy.org/doc/stable/reference/random/index.html\n\n# uniform random numbers in [0, 1]\nnp.random.rand(3, 3)\n\narray([[0.27926165, 0.29280165, 0.92964172],\n       [0.21822349, 0.52725384, 0.53024695],\n       [0.53060045, 0.99729133, 0.05160608]])\n\n\n\n# standard normal distributed random numbers\nnp.random.randn(3, 3)\n\narray([[ 1.28641476,  0.44659509,  0.56486354],\n       [ 1.53333885, -0.40620511, -0.06698893],\n       [ 0.65498179, -0.94716061,  0.15440762]])\n\n\nWe can visualize 2D arrays using imshow.\n\nnp.random.randn(10, 10)\n\narray([[ 0.272612  ,  0.12900753,  1.03297864,  0.01553192,  1.80569372,\n         0.58751616, -0.46620437, -0.73458003,  1.50693552,  0.66747466],\n       [-1.21993923, -0.70079558,  0.53497929, -0.31056667,  1.31449615,\n         0.27379522,  0.0157995 ,  0.6582899 ,  1.40615358,  0.9024235 ],\n       [ 0.87396037, -0.91110323,  1.00454261,  0.38244355, -1.30397122,\n         0.96364739, -0.47070071, -0.76002391, -2.15711318, -0.43962416],\n       [-0.44708413, -2.20861898,  0.13293909,  1.54677203,  0.11245678,\n        -1.01450762, -0.68922839, -0.97819329, -2.46668074,  2.12067715],\n       [-1.2363228 ,  2.29176671, -0.27107855, -1.26831679, -0.50761262,\n        -1.95392975, -0.40843299,  0.81919849,  0.15124877, -0.00535356],\n       [ 0.47151344,  0.79500398, -1.43430062,  0.05804562,  0.26859904,\n        -1.03876563, -0.91019898, -0.47965021, -0.01028352, -0.11518135],\n       [-0.30922564, -1.77920142,  0.27069504,  1.71749944, -0.27361155,\n        -1.48580266, -1.31568599,  0.14148534, -0.37542447, -0.40173894],\n       [-0.18864898,  0.35934124, -0.7854029 , -0.28226907,  0.13679394,\n        -1.44431038,  1.94040407,  0.52611622, -0.78914174, -0.83438789],\n       [-0.07536164, -0.38344457,  0.77218362,  0.40438254,  0.49404312,\n         0.58970989, -0.73003329, -3.08389741,  0.16931622, -0.37544222],\n       [ 0.14960236, -1.61223848,  2.11246195, -0.59952886,  0.17279068,\n        -0.39116369, -0.31130655,  0.65250912, -1.01924418, -0.13093366]])\n\n\n\nplt.imshow(np.random.randn(100, 100))\nplt.show()\n\n\n\n\n\n\n\n\n\n\n5.2.6 zeros and ones\n\nnp.zeros((3, 3))\n\narray([[0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.]])\n\n\n\nnp.ones((3, 3))\n\narray([[1., 1., 1.],\n       [1., 1., 1.],\n       [1., 1., 1.]])",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Arrays and Array Operations using NumPy</span>"
    ]
  },
  {
    "objectID": "05_numpy.html#importing-and-exporting-files",
    "href": "05_numpy.html#importing-and-exporting-files",
    "title": "5  Arrays and Array Operations using NumPy",
    "section": "5.3 Importing and Exporting files",
    "text": "5.3 Importing and Exporting files\n\n5.3.1 Comma-separated values (CSV)\nOfter after processing data, we want to save them. They can be saved as a common CSV or the python internal npy format.\nUsing np.savetxt we can store a Numpy array to a file in CSV format:\n\nM = np.random.rand(100, 100)\n\nM\n\narray([[0.34742718, 0.32204441, 0.02861444, ..., 0.54758665, 0.16711838,\n        0.69777839],\n       [0.84679405, 0.71768981, 0.39605933, ..., 0.07405639, 0.96522275,\n        0.78170769],\n       [0.90210204, 0.22113346, 0.0144142 , ..., 0.02915867, 0.4414601 ,\n        0.11328183],\n       ...,\n       [0.63975736, 0.76066135, 0.46493847, ..., 0.332485  , 0.05114495,\n        0.2852046 ],\n       [0.76028776, 0.33883261, 0.23616102, ..., 0.6497432 , 0.54388628,\n        0.22810651],\n       [0.55921595, 0.54270176, 0.80458935, ..., 0.17424062, 0.09321445,\n        0.77631272]])\n\n\nLet us first create a string with the absolute location of the folder !\n\nfolder = './data/'\n\n\nnp.savetxt(folder + 'random_array_100x100.csv', M)\n\nIf the file is stored in the same folder as that of this Jupyter Notebook, then just the filename demarcated by apostrophes are sufficient.\n\nimported_array = np.loadtxt(folder + 'random_array_100x100.csv')\n\n\nimported_array\n\narray([[0.34742718, 0.32204441, 0.02861444, ..., 0.54758665, 0.16711838,\n        0.69777839],\n       [0.84679405, 0.71768981, 0.39605933, ..., 0.07405639, 0.96522275,\n        0.78170769],\n       [0.90210204, 0.22113346, 0.0144142 , ..., 0.02915867, 0.4414601 ,\n        0.11328183],\n       ...,\n       [0.63975736, 0.76066135, 0.46493847, ..., 0.332485  , 0.05114495,\n        0.2852046 ],\n       [0.76028776, 0.33883261, 0.23616102, ..., 0.6497432 , 0.54388628,\n        0.22810651],\n       [0.55921595, 0.54270176, 0.80458935, ..., 0.17424062, 0.09321445,\n        0.77631272]])\n\n\n\n\n5.3.2 Numpy’s native file format\nIn case the data will be processed only within the python framework then use the functions numpy.save and numpy.load:\n\nnp.save(folder + 'random_array.npy', M)\n\n\nnp.load(folder + 'random_array.npy')\n\narray([[0.34742718, 0.32204441, 0.02861444, ..., 0.54758665, 0.16711838,\n        0.69777839],\n       [0.84679405, 0.71768981, 0.39605933, ..., 0.07405639, 0.96522275,\n        0.78170769],\n       [0.90210204, 0.22113346, 0.0144142 , ..., 0.02915867, 0.4414601 ,\n        0.11328183],\n       ...,\n       [0.63975736, 0.76066135, 0.46493847, ..., 0.332485  , 0.05114495,\n        0.2852046 ],\n       [0.76028776, 0.33883261, 0.23616102, ..., 0.6497432 , 0.54388628,\n        0.22810651],\n       [0.55921595, 0.54270176, 0.80458935, ..., 0.17424062, 0.09321445,\n        0.77631272]])\n\n\n\n%matplotlib inline\nimport matplotlib.pyplot as plt # Alias\n\n\nimport numpy as np",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Arrays and Array Operations using NumPy</span>"
    ]
  },
  {
    "objectID": "05_numpy.html#importing-an-external-csv-file",
    "href": "05_numpy.html#importing-an-external-csv-file",
    "title": "5  Arrays and Array Operations using NumPy",
    "section": "5.4 Importing an external csv file",
    "text": "5.4 Importing an external csv file\n\nfolder = './data/'\n\n\ntemperature_anomaly = np.loadtxt(folder + 't_ano.csv')\n\n\ntemperature_anomaly\n\narray([[ 1.880e+03, -5.000e-02],\n       [ 1.881e+03, -5.000e-02],\n       [ 1.882e+03, -6.000e-02],\n       [ 1.883e+03, -1.100e-01],\n       [ 1.884e+03, -2.800e-01],\n       [ 1.885e+03, -2.800e-01],\n       [ 1.886e+03, -2.600e-01],\n       [ 1.887e+03, -3.100e-01],\n       [ 1.888e+03, -1.600e-01],\n       [ 1.889e+03, -1.300e-01],\n       [ 1.890e+03, -3.700e-01],\n       [ 1.891e+03, -2.000e-01],\n       [ 1.892e+03, -3.300e-01],\n       [ 1.893e+03, -3.000e-01],\n       [ 1.894e+03, -2.900e-01],\n       [ 1.895e+03, -2.300e-01],\n       [ 1.896e+03, -4.000e-02],\n       [ 1.897e+03, -8.000e-02],\n       [ 1.898e+03, -2.400e-01],\n       [ 1.899e+03, -1.000e-01],\n       [ 1.900e+03, -7.000e-02],\n       [ 1.901e+03, -1.800e-01],\n       [ 1.902e+03, -2.900e-01],\n       [ 1.903e+03, -4.500e-01],\n       [ 1.904e+03, -4.400e-01],\n       [ 1.905e+03, -1.900e-01],\n       [ 1.906e+03, -2.400e-01],\n       [ 1.907e+03, -3.200e-01],\n       [ 1.908e+03, -4.500e-01],\n       [ 1.909e+03, -3.300e-01],\n       [ 1.910e+03, -3.500e-01],\n       [ 1.911e+03, -4.400e-01],\n       [ 1.912e+03, -4.600e-01],\n       [ 1.913e+03, -2.900e-01],\n       [ 1.914e+03, -2.000e-01],\n       [ 1.915e+03, -1.200e-01],\n       [ 1.916e+03, -3.200e-01],\n       [ 1.917e+03, -1.700e-01],\n       [ 1.918e+03, -3.100e-01],\n       [ 1.919e+03, -3.000e-01],\n       [ 1.920e+03, -2.400e-01],\n       [ 1.921e+03, -2.200e-01],\n       [ 1.922e+03, -3.000e-01],\n       [ 1.923e+03, -3.300e-01],\n       [ 1.924e+03, -3.100e-01],\n       [ 1.925e+03, -1.500e-01],\n       [ 1.926e+03, -1.000e-01],\n       [ 1.927e+03, -1.500e-01],\n       [ 1.928e+03, -2.000e-01],\n       [ 1.929e+03, -2.400e-01],\n       [ 1.930e+03, -9.000e-02],\n       [ 1.931e+03,  1.000e-02],\n       [ 1.932e+03, -1.900e-01],\n       [ 1.933e+03, -2.100e-01],\n       [ 1.934e+03, -5.000e-02],\n       [ 1.935e+03, -1.500e-01],\n       [ 1.936e+03, -8.000e-02],\n       [ 1.937e+03,  8.000e-02],\n       [ 1.938e+03, -5.000e-02],\n       [ 1.939e+03,  5.000e-02],\n       [ 1.940e+03,  1.300e-01],\n       [ 1.941e+03,  2.400e-01],\n       [ 1.942e+03,  0.000e+00],\n       [ 1.943e+03,  7.000e-02],\n       [ 1.944e+03,  2.700e-01],\n       [ 1.945e+03,  3.600e-01],\n       [ 1.946e+03, -1.100e-01],\n       [ 1.947e+03, -7.000e-02],\n       [ 1.948e+03, -4.000e-02],\n       [ 1.949e+03, -7.000e-02],\n       [ 1.950e+03, -1.200e-01],\n       [ 1.951e+03,  1.200e-01],\n       [ 1.952e+03,  7.000e-02],\n       [ 1.953e+03,  1.100e-01],\n       [ 1.954e+03, -9.000e-02],\n       [ 1.955e+03, -2.000e-02],\n       [ 1.956e+03, -1.700e-01],\n       [ 1.957e+03,  1.600e-01],\n       [ 1.958e+03,  9.000e-02],\n       [ 1.959e+03,  7.000e-02],\n       [ 1.960e+03,  9.000e-02],\n       [ 1.961e+03,  5.000e-02],\n       [ 1.962e+03,  8.000e-02],\n       [ 1.963e+03,  1.800e-01],\n       [ 1.964e+03, -1.600e-01],\n       [ 1.965e+03, -5.000e-02],\n       [ 1.966e+03,  5.000e-02],\n       [ 1.967e+03,  1.000e-02],\n       [ 1.968e+03,  1.000e-02],\n       [ 1.969e+03,  1.100e-01],\n       [ 1.970e+03,  2.000e-02],\n       [ 1.971e+03, -4.000e-02],\n       [ 1.972e+03,  1.000e-01],\n       [ 1.973e+03,  1.200e-01],\n       [ 1.974e+03,  4.000e-02],\n       [ 1.975e+03, -4.000e-02],\n       [ 1.976e+03, -5.000e-02],\n       [ 1.977e+03,  1.500e-01],\n       [ 1.978e+03,  1.000e-02],\n       [ 1.979e+03,  2.400e-01],\n       [ 1.980e+03,  2.100e-01],\n       [ 1.981e+03,  2.400e-01],\n       [ 1.982e+03,  1.400e-01],\n       [ 1.983e+03,  3.600e-01],\n       [ 1.984e+03,  1.900e-01],\n       [ 1.985e+03,  1.600e-01],\n       [ 1.986e+03,  2.000e-01],\n       [ 1.987e+03,  4.000e-01],\n       [ 1.988e+03,  3.400e-01],\n       [ 1.989e+03,  3.200e-01],\n       [ 1.990e+03,  3.900e-01],\n       [ 1.991e+03,  3.700e-01],\n       [ 1.992e+03,  1.100e-01],\n       [ 1.993e+03,  2.200e-01],\n       [ 1.994e+03,  3.000e-01],\n       [ 1.995e+03,  5.000e-01],\n       [ 1.996e+03,  3.400e-01],\n       [ 1.997e+03,  5.500e-01],\n       [ 1.998e+03,  7.100e-01],\n       [ 1.999e+03,  3.600e-01],\n       [ 2.000e+03,  4.600e-01],\n       [ 2.001e+03,  6.100e-01],\n       [ 2.002e+03,  5.600e-01],\n       [ 2.003e+03,  6.600e-01],\n       [ 2.004e+03,  5.200e-01],\n       [ 2.005e+03,  6.300e-01],\n       [ 2.006e+03,  6.500e-01],\n       [ 2.007e+03,  5.600e-01],\n       [ 2.008e+03,  5.700e-01],\n       [ 2.009e+03,  7.200e-01],\n       [ 2.010e+03,  6.900e-01],\n       [ 2.011e+03,  6.500e-01],\n       [ 2.012e+03,  7.000e-01],\n       [ 2.013e+03,  6.800e-01],\n       [ 2.014e+03,  8.200e-01],\n       [ 2.015e+03,  9.100e-01],\n       [ 2.016e+03,  9.800e-01],\n       [ 2.017e+03,  9.200e-01],\n       [ 2.018e+03,  7.900e-01],\n       [ 2.019e+03,  9.200e-01],\n       [ 2.020e+03,  9.300e-01],\n       [ 2.021e+03,  8.900e-01],\n       [ 2.022e+03,  9.000e-01]])\n\n\n\ntemperature_anomaly.shape\n\n(143, 2)\n\n\n\nfig, ax = plt.subplots()  # Create a figure containing a single axes.\nax.plot(temperature_anomaly[:, 0], temperature_anomaly[:, 1])\nax.set_xlabel('Years')\nax.set_ylabel('Temperature Anomaly')\nplt.show()",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Arrays and Array Operations using NumPy</span>"
    ]
  },
  {
    "objectID": "05_numpy.html#extracting-updating-and-modifying-arrays",
    "href": "05_numpy.html#extracting-updating-and-modifying-arrays",
    "title": "5  Arrays and Array Operations using NumPy",
    "section": "5.5 Extracting, updating and modifying arrays",
    "text": "5.5 Extracting, updating and modifying arrays\n\n5.5.1 Indexing\nWe can extract elements from an array by specifying the index (position) of the data required !\n\ntemperature_anomaly[0]\n\narray([ 1.88e+03, -5.00e-02])\n\n\n\ntemperature_anomaly[140, 1] # array_name[row , column]\n\n0.93\n\n\nIf we omit an index of a multidimensional array it returns the whole row (or, in general, a N-1 dimensional array)\n\ntemperature_anomaly[0, :] # first row\n\narray([ 1.88e+03, -5.00e-02])\n\n\n\ntemperature_anomaly[:, 0] # first column\n\narray([1880., 1881., 1882., 1883., 1884., 1885., 1886., 1887., 1888.,\n       1889., 1890., 1891., 1892., 1893., 1894., 1895., 1896., 1897.,\n       1898., 1899., 1900., 1901., 1902., 1903., 1904., 1905., 1906.,\n       1907., 1908., 1909., 1910., 1911., 1912., 1913., 1914., 1915.,\n       1916., 1917., 1918., 1919., 1920., 1921., 1922., 1923., 1924.,\n       1925., 1926., 1927., 1928., 1929., 1930., 1931., 1932., 1933.,\n       1934., 1935., 1936., 1937., 1938., 1939., 1940., 1941., 1942.,\n       1943., 1944., 1945., 1946., 1947., 1948., 1949., 1950., 1951.,\n       1952., 1953., 1954., 1955., 1956., 1957., 1958., 1959., 1960.,\n       1961., 1962., 1963., 1964., 1965., 1966., 1967., 1968., 1969.,\n       1970., 1971., 1972., 1973., 1974., 1975., 1976., 1977., 1978.,\n       1979., 1980., 1981., 1982., 1983., 1984., 1985., 1986., 1987.,\n       1988., 1989., 1990., 1991., 1992., 1993., 1994., 1995., 1996.,\n       1997., 1998., 1999., 2000., 2001., 2002., 2003., 2004., 2005.,\n       2006., 2007., 2008., 2009., 2010., 2011., 2012., 2013., 2014.,\n       2015., 2016., 2017., 2018., 2019., 2020., 2021., 2022.])\n\n\nThe values in the array can be changed as follows:\n\ntemperature_anomaly[0, 0] = 1879\n\n\ntemperature_anomaly\n\narray([[ 1.879e+03, -5.000e-02],\n       [ 1.881e+03, -5.000e-02],\n       [ 1.882e+03, -6.000e-02],\n       [ 1.883e+03, -1.100e-01],\n       [ 1.884e+03, -2.800e-01],\n       [ 1.885e+03, -2.800e-01],\n       [ 1.886e+03, -2.600e-01],\n       [ 1.887e+03, -3.100e-01],\n       [ 1.888e+03, -1.600e-01],\n       [ 1.889e+03, -1.300e-01],\n       [ 1.890e+03, -3.700e-01],\n       [ 1.891e+03, -2.000e-01],\n       [ 1.892e+03, -3.300e-01],\n       [ 1.893e+03, -3.000e-01],\n       [ 1.894e+03, -2.900e-01],\n       [ 1.895e+03, -2.300e-01],\n       [ 1.896e+03, -4.000e-02],\n       [ 1.897e+03, -8.000e-02],\n       [ 1.898e+03, -2.400e-01],\n       [ 1.899e+03, -1.000e-01],\n       [ 1.900e+03, -7.000e-02],\n       [ 1.901e+03, -1.800e-01],\n       [ 1.902e+03, -2.900e-01],\n       [ 1.903e+03, -4.500e-01],\n       [ 1.904e+03, -4.400e-01],\n       [ 1.905e+03, -1.900e-01],\n       [ 1.906e+03, -2.400e-01],\n       [ 1.907e+03, -3.200e-01],\n       [ 1.908e+03, -4.500e-01],\n       [ 1.909e+03, -3.300e-01],\n       [ 1.910e+03, -3.500e-01],\n       [ 1.911e+03, -4.400e-01],\n       [ 1.912e+03, -4.600e-01],\n       [ 1.913e+03, -2.900e-01],\n       [ 1.914e+03, -2.000e-01],\n       [ 1.915e+03, -1.200e-01],\n       [ 1.916e+03, -3.200e-01],\n       [ 1.917e+03, -1.700e-01],\n       [ 1.918e+03, -3.100e-01],\n       [ 1.919e+03, -3.000e-01],\n       [ 1.920e+03, -2.400e-01],\n       [ 1.921e+03, -2.200e-01],\n       [ 1.922e+03, -3.000e-01],\n       [ 1.923e+03, -3.300e-01],\n       [ 1.924e+03, -3.100e-01],\n       [ 1.925e+03, -1.500e-01],\n       [ 1.926e+03, -1.000e-01],\n       [ 1.927e+03, -1.500e-01],\n       [ 1.928e+03, -2.000e-01],\n       [ 1.929e+03, -2.400e-01],\n       [ 1.930e+03, -9.000e-02],\n       [ 1.931e+03,  1.000e-02],\n       [ 1.932e+03, -1.900e-01],\n       [ 1.933e+03, -2.100e-01],\n       [ 1.934e+03, -5.000e-02],\n       [ 1.935e+03, -1.500e-01],\n       [ 1.936e+03, -8.000e-02],\n       [ 1.937e+03,  8.000e-02],\n       [ 1.938e+03, -5.000e-02],\n       [ 1.939e+03,  5.000e-02],\n       [ 1.940e+03,  1.300e-01],\n       [ 1.941e+03,  2.400e-01],\n       [ 1.942e+03,  0.000e+00],\n       [ 1.943e+03,  7.000e-02],\n       [ 1.944e+03,  2.700e-01],\n       [ 1.945e+03,  3.600e-01],\n       [ 1.946e+03, -1.100e-01],\n       [ 1.947e+03, -7.000e-02],\n       [ 1.948e+03, -4.000e-02],\n       [ 1.949e+03, -7.000e-02],\n       [ 1.950e+03, -1.200e-01],\n       [ 1.951e+03,  1.200e-01],\n       [ 1.952e+03,  7.000e-02],\n       [ 1.953e+03,  1.100e-01],\n       [ 1.954e+03, -9.000e-02],\n       [ 1.955e+03, -2.000e-02],\n       [ 1.956e+03, -1.700e-01],\n       [ 1.957e+03,  1.600e-01],\n       [ 1.958e+03,  9.000e-02],\n       [ 1.959e+03,  7.000e-02],\n       [ 1.960e+03,  9.000e-02],\n       [ 1.961e+03,  5.000e-02],\n       [ 1.962e+03,  8.000e-02],\n       [ 1.963e+03,  1.800e-01],\n       [ 1.964e+03, -1.600e-01],\n       [ 1.965e+03, -5.000e-02],\n       [ 1.966e+03,  5.000e-02],\n       [ 1.967e+03,  1.000e-02],\n       [ 1.968e+03,  1.000e-02],\n       [ 1.969e+03,  1.100e-01],\n       [ 1.970e+03,  2.000e-02],\n       [ 1.971e+03, -4.000e-02],\n       [ 1.972e+03,  1.000e-01],\n       [ 1.973e+03,  1.200e-01],\n       [ 1.974e+03,  4.000e-02],\n       [ 1.975e+03, -4.000e-02],\n       [ 1.976e+03, -5.000e-02],\n       [ 1.977e+03,  1.500e-01],\n       [ 1.978e+03,  1.000e-02],\n       [ 1.979e+03,  2.400e-01],\n       [ 1.980e+03,  2.100e-01],\n       [ 1.981e+03,  2.400e-01],\n       [ 1.982e+03,  1.400e-01],\n       [ 1.983e+03,  3.600e-01],\n       [ 1.984e+03,  1.900e-01],\n       [ 1.985e+03,  1.600e-01],\n       [ 1.986e+03,  2.000e-01],\n       [ 1.987e+03,  4.000e-01],\n       [ 1.988e+03,  3.400e-01],\n       [ 1.989e+03,  3.200e-01],\n       [ 1.990e+03,  3.900e-01],\n       [ 1.991e+03,  3.700e-01],\n       [ 1.992e+03,  1.100e-01],\n       [ 1.993e+03,  2.200e-01],\n       [ 1.994e+03,  3.000e-01],\n       [ 1.995e+03,  5.000e-01],\n       [ 1.996e+03,  3.400e-01],\n       [ 1.997e+03,  5.500e-01],\n       [ 1.998e+03,  7.100e-01],\n       [ 1.999e+03,  3.600e-01],\n       [ 2.000e+03,  4.600e-01],\n       [ 2.001e+03,  6.100e-01],\n       [ 2.002e+03,  5.600e-01],\n       [ 2.003e+03,  6.600e-01],\n       [ 2.004e+03,  5.200e-01],\n       [ 2.005e+03,  6.300e-01],\n       [ 2.006e+03,  6.500e-01],\n       [ 2.007e+03,  5.600e-01],\n       [ 2.008e+03,  5.700e-01],\n       [ 2.009e+03,  7.200e-01],\n       [ 2.010e+03,  6.900e-01],\n       [ 2.011e+03,  6.500e-01],\n       [ 2.012e+03,  7.000e-01],\n       [ 2.013e+03,  6.800e-01],\n       [ 2.014e+03,  8.200e-01],\n       [ 2.015e+03,  9.100e-01],\n       [ 2.016e+03,  9.800e-01],\n       [ 2.017e+03,  9.200e-01],\n       [ 2.018e+03,  7.900e-01],\n       [ 2.019e+03,  9.200e-01],\n       [ 2.020e+03,  9.300e-01],\n       [ 2.021e+03,  8.900e-01],\n       [ 2.022e+03,  9.000e-01]])\n\n\n\n# Complete rows and columns can be changed !\ntemperature_anomaly[:, 1] = temperature_anomaly[:, 1] + 273\n\n\ntemperature_anomaly\n\narray([[1879.  ,  272.95],\n       [1881.  ,  272.95],\n       [1882.  ,  272.94],\n       [1883.  ,  272.89],\n       [1884.  ,  272.72],\n       [1885.  ,  272.72],\n       [1886.  ,  272.74],\n       [1887.  ,  272.69],\n       [1888.  ,  272.84],\n       [1889.  ,  272.87],\n       [1890.  ,  272.63],\n       [1891.  ,  272.8 ],\n       [1892.  ,  272.67],\n       [1893.  ,  272.7 ],\n       [1894.  ,  272.71],\n       [1895.  ,  272.77],\n       [1896.  ,  272.96],\n       [1897.  ,  272.92],\n       [1898.  ,  272.76],\n       [1899.  ,  272.9 ],\n       [1900.  ,  272.93],\n       [1901.  ,  272.82],\n       [1902.  ,  272.71],\n       [1903.  ,  272.55],\n       [1904.  ,  272.56],\n       [1905.  ,  272.81],\n       [1906.  ,  272.76],\n       [1907.  ,  272.68],\n       [1908.  ,  272.55],\n       [1909.  ,  272.67],\n       [1910.  ,  272.65],\n       [1911.  ,  272.56],\n       [1912.  ,  272.54],\n       [1913.  ,  272.71],\n       [1914.  ,  272.8 ],\n       [1915.  ,  272.88],\n       [1916.  ,  272.68],\n       [1917.  ,  272.83],\n       [1918.  ,  272.69],\n       [1919.  ,  272.7 ],\n       [1920.  ,  272.76],\n       [1921.  ,  272.78],\n       [1922.  ,  272.7 ],\n       [1923.  ,  272.67],\n       [1924.  ,  272.69],\n       [1925.  ,  272.85],\n       [1926.  ,  272.9 ],\n       [1927.  ,  272.85],\n       [1928.  ,  272.8 ],\n       [1929.  ,  272.76],\n       [1930.  ,  272.91],\n       [1931.  ,  273.01],\n       [1932.  ,  272.81],\n       [1933.  ,  272.79],\n       [1934.  ,  272.95],\n       [1935.  ,  272.85],\n       [1936.  ,  272.92],\n       [1937.  ,  273.08],\n       [1938.  ,  272.95],\n       [1939.  ,  273.05],\n       [1940.  ,  273.13],\n       [1941.  ,  273.24],\n       [1942.  ,  273.  ],\n       [1943.  ,  273.07],\n       [1944.  ,  273.27],\n       [1945.  ,  273.36],\n       [1946.  ,  272.89],\n       [1947.  ,  272.93],\n       [1948.  ,  272.96],\n       [1949.  ,  272.93],\n       [1950.  ,  272.88],\n       [1951.  ,  273.12],\n       [1952.  ,  273.07],\n       [1953.  ,  273.11],\n       [1954.  ,  272.91],\n       [1955.  ,  272.98],\n       [1956.  ,  272.83],\n       [1957.  ,  273.16],\n       [1958.  ,  273.09],\n       [1959.  ,  273.07],\n       [1960.  ,  273.09],\n       [1961.  ,  273.05],\n       [1962.  ,  273.08],\n       [1963.  ,  273.18],\n       [1964.  ,  272.84],\n       [1965.  ,  272.95],\n       [1966.  ,  273.05],\n       [1967.  ,  273.01],\n       [1968.  ,  273.01],\n       [1969.  ,  273.11],\n       [1970.  ,  273.02],\n       [1971.  ,  272.96],\n       [1972.  ,  273.1 ],\n       [1973.  ,  273.12],\n       [1974.  ,  273.04],\n       [1975.  ,  272.96],\n       [1976.  ,  272.95],\n       [1977.  ,  273.15],\n       [1978.  ,  273.01],\n       [1979.  ,  273.24],\n       [1980.  ,  273.21],\n       [1981.  ,  273.24],\n       [1982.  ,  273.14],\n       [1983.  ,  273.36],\n       [1984.  ,  273.19],\n       [1985.  ,  273.16],\n       [1986.  ,  273.2 ],\n       [1987.  ,  273.4 ],\n       [1988.  ,  273.34],\n       [1989.  ,  273.32],\n       [1990.  ,  273.39],\n       [1991.  ,  273.37],\n       [1992.  ,  273.11],\n       [1993.  ,  273.22],\n       [1994.  ,  273.3 ],\n       [1995.  ,  273.5 ],\n       [1996.  ,  273.34],\n       [1997.  ,  273.55],\n       [1998.  ,  273.71],\n       [1999.  ,  273.36],\n       [2000.  ,  273.46],\n       [2001.  ,  273.61],\n       [2002.  ,  273.56],\n       [2003.  ,  273.66],\n       [2004.  ,  273.52],\n       [2005.  ,  273.63],\n       [2006.  ,  273.65],\n       [2007.  ,  273.56],\n       [2008.  ,  273.57],\n       [2009.  ,  273.72],\n       [2010.  ,  273.69],\n       [2011.  ,  273.65],\n       [2012.  ,  273.7 ],\n       [2013.  ,  273.68],\n       [2014.  ,  273.82],\n       [2015.  ,  273.91],\n       [2016.  ,  273.98],\n       [2017.  ,  273.92],\n       [2018.  ,  273.79],\n       [2019.  ,  273.92],\n       [2020.  ,  273.93],\n       [2021.  ,  273.89],\n       [2022.  ,  273.9 ]])\n\n\n\n\n5.5.2 Extracting multiple data\nUsing the syntax M[lower:upper:step] more data can be extracted at once:\n\ntemperature_anomaly[0::10] # start, stop step\n\narray([[1879.  ,  272.95],\n       [1890.  ,  272.63],\n       [1900.  ,  272.93],\n       [1910.  ,  272.65],\n       [1920.  ,  272.76],\n       [1930.  ,  272.91],\n       [1940.  ,  273.13],\n       [1950.  ,  272.88],\n       [1960.  ,  273.09],\n       [1970.  ,  273.02],\n       [1980.  ,  273.21],\n       [1990.  ,  273.39],\n       [2000.  ,  273.46],\n       [2010.  ,  273.69],\n       [2020.  ,  273.93]])\n\n\nNot all the parameters are required - M[lower:upper:step]:\n\ntemperature_anomaly[::] # lower, upper, step all take the default values\n\narray([[1879.  ,  272.95],\n       [1881.  ,  272.95],\n       [1882.  ,  272.94],\n       [1883.  ,  272.89],\n       [1884.  ,  272.72],\n       [1885.  ,  272.72],\n       [1886.  ,  272.74],\n       [1887.  ,  272.69],\n       [1888.  ,  272.84],\n       [1889.  ,  272.87],\n       [1890.  ,  272.63],\n       [1891.  ,  272.8 ],\n       [1892.  ,  272.67],\n       [1893.  ,  272.7 ],\n       [1894.  ,  272.71],\n       [1895.  ,  272.77],\n       [1896.  ,  272.96],\n       [1897.  ,  272.92],\n       [1898.  ,  272.76],\n       [1899.  ,  272.9 ],\n       [1900.  ,  272.93],\n       [1901.  ,  272.82],\n       [1902.  ,  272.71],\n       [1903.  ,  272.55],\n       [1904.  ,  272.56],\n       [1905.  ,  272.81],\n       [1906.  ,  272.76],\n       [1907.  ,  272.68],\n       [1908.  ,  272.55],\n       [1909.  ,  272.67],\n       [1910.  ,  272.65],\n       [1911.  ,  272.56],\n       [1912.  ,  272.54],\n       [1913.  ,  272.71],\n       [1914.  ,  272.8 ],\n       [1915.  ,  272.88],\n       [1916.  ,  272.68],\n       [1917.  ,  272.83],\n       [1918.  ,  272.69],\n       [1919.  ,  272.7 ],\n       [1920.  ,  272.76],\n       [1921.  ,  272.78],\n       [1922.  ,  272.7 ],\n       [1923.  ,  272.67],\n       [1924.  ,  272.69],\n       [1925.  ,  272.85],\n       [1926.  ,  272.9 ],\n       [1927.  ,  272.85],\n       [1928.  ,  272.8 ],\n       [1929.  ,  272.76],\n       [1930.  ,  272.91],\n       [1931.  ,  273.01],\n       [1932.  ,  272.81],\n       [1933.  ,  272.79],\n       [1934.  ,  272.95],\n       [1935.  ,  272.85],\n       [1936.  ,  272.92],\n       [1937.  ,  273.08],\n       [1938.  ,  272.95],\n       [1939.  ,  273.05],\n       [1940.  ,  273.13],\n       [1941.  ,  273.24],\n       [1942.  ,  273.  ],\n       [1943.  ,  273.07],\n       [1944.  ,  273.27],\n       [1945.  ,  273.36],\n       [1946.  ,  272.89],\n       [1947.  ,  272.93],\n       [1948.  ,  272.96],\n       [1949.  ,  272.93],\n       [1950.  ,  272.88],\n       [1951.  ,  273.12],\n       [1952.  ,  273.07],\n       [1953.  ,  273.11],\n       [1954.  ,  272.91],\n       [1955.  ,  272.98],\n       [1956.  ,  272.83],\n       [1957.  ,  273.16],\n       [1958.  ,  273.09],\n       [1959.  ,  273.07],\n       [1960.  ,  273.09],\n       [1961.  ,  273.05],\n       [1962.  ,  273.08],\n       [1963.  ,  273.18],\n       [1964.  ,  272.84],\n       [1965.  ,  272.95],\n       [1966.  ,  273.05],\n       [1967.  ,  273.01],\n       [1968.  ,  273.01],\n       [1969.  ,  273.11],\n       [1970.  ,  273.02],\n       [1971.  ,  272.96],\n       [1972.  ,  273.1 ],\n       [1973.  ,  273.12],\n       [1974.  ,  273.04],\n       [1975.  ,  272.96],\n       [1976.  ,  272.95],\n       [1977.  ,  273.15],\n       [1978.  ,  273.01],\n       [1979.  ,  273.24],\n       [1980.  ,  273.21],\n       [1981.  ,  273.24],\n       [1982.  ,  273.14],\n       [1983.  ,  273.36],\n       [1984.  ,  273.19],\n       [1985.  ,  273.16],\n       [1986.  ,  273.2 ],\n       [1987.  ,  273.4 ],\n       [1988.  ,  273.34],\n       [1989.  ,  273.32],\n       [1990.  ,  273.39],\n       [1991.  ,  273.37],\n       [1992.  ,  273.11],\n       [1993.  ,  273.22],\n       [1994.  ,  273.3 ],\n       [1995.  ,  273.5 ],\n       [1996.  ,  273.34],\n       [1997.  ,  273.55],\n       [1998.  ,  273.71],\n       [1999.  ,  273.36],\n       [2000.  ,  273.46],\n       [2001.  ,  273.61],\n       [2002.  ,  273.56],\n       [2003.  ,  273.66],\n       [2004.  ,  273.52],\n       [2005.  ,  273.63],\n       [2006.  ,  273.65],\n       [2007.  ,  273.56],\n       [2008.  ,  273.57],\n       [2009.  ,  273.72],\n       [2010.  ,  273.69],\n       [2011.  ,  273.65],\n       [2012.  ,  273.7 ],\n       [2013.  ,  273.68],\n       [2014.  ,  273.82],\n       [2015.  ,  273.91],\n       [2016.  ,  273.98],\n       [2017.  ,  273.92],\n       [2018.  ,  273.79],\n       [2019.  ,  273.92],\n       [2020.  ,  273.93],\n       [2021.  ,  273.89],\n       [2022.  ,  273.9 ]])\n\n\n\ntemperature_anomaly[0::5]\n\narray([[1879.  ,  272.95],\n       [1885.  ,  272.72],\n       [1890.  ,  272.63],\n       [1895.  ,  272.77],\n       [1900.  ,  272.93],\n       [1905.  ,  272.81],\n       [1910.  ,  272.65],\n       [1915.  ,  272.88],\n       [1920.  ,  272.76],\n       [1925.  ,  272.85],\n       [1930.  ,  272.91],\n       [1935.  ,  272.85],\n       [1940.  ,  273.13],\n       [1945.  ,  273.36],\n       [1950.  ,  272.88],\n       [1955.  ,  272.98],\n       [1960.  ,  273.09],\n       [1965.  ,  272.95],\n       [1970.  ,  273.02],\n       [1975.  ,  272.96],\n       [1980.  ,  273.21],\n       [1985.  ,  273.16],\n       [1990.  ,  273.39],\n       [1995.  ,  273.5 ],\n       [2000.  ,  273.46],\n       [2005.  ,  273.63],\n       [2010.  ,  273.69],\n       [2015.  ,  273.91],\n       [2020.  ,  273.93]])\n\n\n\ntemperature_anomaly[:3] # first three elements\n\narray([[1879.  ,  272.95],\n       [1881.  ,  272.95],\n       [1882.  ,  272.94]])\n\n\n\ntemperature_anomaly[-3:] # elements from index 3\n\narray([[2020.  ,  273.93],\n       [2021.  ,  273.89],\n       [2022.  ,  273.9 ]])\n\n\nNegative indices counts from the end of the array (positive index from the begining):\n\ntemperature_anomaly[-1] # the last element in the array\n\narray([2022. ,  273.9])\n\n\nIndex slicing works exactly the same way for multidimensional arrays:\n\n# strides\nsubset_temperature_anomaly = temperature_anomaly[::2, :]\nsubset_temperature_anomaly\n\narray([[1879.  ,  272.95],\n       [1882.  ,  272.94],\n       [1884.  ,  272.72],\n       [1886.  ,  272.74],\n       [1888.  ,  272.84],\n       [1890.  ,  272.63],\n       [1892.  ,  272.67],\n       [1894.  ,  272.71],\n       [1896.  ,  272.96],\n       [1898.  ,  272.76],\n       [1900.  ,  272.93],\n       [1902.  ,  272.71],\n       [1904.  ,  272.56],\n       [1906.  ,  272.76],\n       [1908.  ,  272.55],\n       [1910.  ,  272.65],\n       [1912.  ,  272.54],\n       [1914.  ,  272.8 ],\n       [1916.  ,  272.68],\n       [1918.  ,  272.69],\n       [1920.  ,  272.76],\n       [1922.  ,  272.7 ],\n       [1924.  ,  272.69],\n       [1926.  ,  272.9 ],\n       [1928.  ,  272.8 ],\n       [1930.  ,  272.91],\n       [1932.  ,  272.81],\n       [1934.  ,  272.95],\n       [1936.  ,  272.92],\n       [1938.  ,  272.95],\n       [1940.  ,  273.13],\n       [1942.  ,  273.  ],\n       [1944.  ,  273.27],\n       [1946.  ,  272.89],\n       [1948.  ,  272.96],\n       [1950.  ,  272.88],\n       [1952.  ,  273.07],\n       [1954.  ,  272.91],\n       [1956.  ,  272.83],\n       [1958.  ,  273.09],\n       [1960.  ,  273.09],\n       [1962.  ,  273.08],\n       [1964.  ,  272.84],\n       [1966.  ,  273.05],\n       [1968.  ,  273.01],\n       [1970.  ,  273.02],\n       [1972.  ,  273.1 ],\n       [1974.  ,  273.04],\n       [1976.  ,  272.95],\n       [1978.  ,  273.01],\n       [1980.  ,  273.21],\n       [1982.  ,  273.14],\n       [1984.  ,  273.19],\n       [1986.  ,  273.2 ],\n       [1988.  ,  273.34],\n       [1990.  ,  273.39],\n       [1992.  ,  273.11],\n       [1994.  ,  273.3 ],\n       [1996.  ,  273.34],\n       [1998.  ,  273.71],\n       [2000.  ,  273.46],\n       [2002.  ,  273.56],\n       [2004.  ,  273.52],\n       [2006.  ,  273.65],\n       [2008.  ,  273.57],\n       [2010.  ,  273.69],\n       [2012.  ,  273.7 ],\n       [2014.  ,  273.82],\n       [2016.  ,  273.98],\n       [2018.  ,  273.79],\n       [2020.  ,  273.93],\n       [2022.  ,  273.9 ]])\n\n\n\n\n5.5.3 Fancy indexing\nFancy indexing is the name for when an array or list is used in-place of an index:\n\nrow_indices = [0, 2, -1]\n\n\ntemperature_anomaly[row_indices]\n\narray([[1879.  ,  272.95],\n       [1882.  ,  272.94],\n       [2022.  ,  273.9 ]])\n\n\n\n\n5.5.4 Mask\nWe can also use index masks: If the index mask is an Numpy array of data type bool, then an element is selected (True) or not (False) depending on the value of the index mask at the position of each element:\nThis feature is very useful to conditionally select elements from an array, using for example comparison operators:\n\nx = np.arange(0, 10, 0.1)\nx\n\narray([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2,\n       1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2. , 2.1, 2.2, 2.3, 2.4, 2.5,\n       2.6, 2.7, 2.8, 2.9, 3. , 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8,\n       3.9, 4. , 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5. , 5.1,\n       5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 6. , 6.1, 6.2, 6.3, 6.4,\n       6.5, 6.6, 6.7, 6.8, 6.9, 7. , 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7,\n       7.8, 7.9, 8. , 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9, 9. ,\n       9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9])\n\n\n\nmask = (x &gt; 2)\n\nmask\n\narray([False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True])",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Arrays and Array Operations using NumPy</span>"
    ]
  },
  {
    "objectID": "05_numpy.html#special-functions",
    "href": "05_numpy.html#special-functions",
    "title": "5  Arrays and Array Operations using NumPy",
    "section": "5.6 Special Functions",
    "text": "5.6 Special Functions\n\n5.6.1 where, take\nThe index mask can be converted to position index using the where function\n\nindices = np.where(mask)\n\nindices\n\n(array([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37,\n        38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n        55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88,\n        89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),)\n\n\n\nx[indices] # this indexing is equivalent to the fancy indexing x[mask]\n\narray([2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3. , 3.1, 3.2, 3.3,\n       3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4. , 4.1, 4.2, 4.3, 4.4, 4.5, 4.6,\n       4.7, 4.8, 4.9, 5. , 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9,\n       6. , 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8, 6.9, 7. , 7.1, 7.2,\n       7.3, 7.4, 7.5, 7.6, 7.7, 7.8, 7.9, 8. , 8.1, 8.2, 8.3, 8.4, 8.5,\n       8.6, 8.7, 8.8, 8.9, 9. , 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8,\n       9.9])\n\n\nThe take function is similar to fancy indexing described above:\n\nv2 = np.arange(-10, 10)\nv2\n\narray([-10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,\n         3,   4,   5,   6,   7,   8,   9])\n\n\n\nrow_indices = [1, 3, 5]\nv2[row_indices] # fancy indexing\n\narray([-9, -7, -5])\n\n\n\nv2.take(row_indices)\n\narray([-9, -7, -5])\n\n\nBut take also works on lists and other objects:\n\nnp.take(np.arange(-4, 4), row_indices)\n\narray([-3, -1,  1])",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Arrays and Array Operations using NumPy</span>"
    ]
  },
  {
    "objectID": "05_numpy.html#linear-algebra",
    "href": "05_numpy.html#linear-algebra",
    "title": "5  Arrays and Array Operations using NumPy",
    "section": "5.7 Linear algebra",
    "text": "5.7 Linear algebra\nVectorizing code is the key to writing efficient numerical calculation with Python/Numpy. That means that as much as possible of a program should be formulated in terms of matrix and vector operations, like matrix-matrix multiplication.\n\n5.7.1 Scalar-array operations\nWe can use the usual arithmetic operators to multiply, add, subtract, and divide arrays with scalar numbers.\n\nv1 = np.arange(0, 7)\nv1\nv1.shape\n\n(7,)\n\n\n\nv1\n\narray([0, 1, 2, 3, 4, 5, 6])\n\n\n\nv_my_vector = v1 * 200\nv_my_vector\n\narray([   0,  200,  400,  600,  800, 1000, 1200])\n\n\n\nv1 + v_my_vector\n\narray([   0,  201,  402,  603,  804, 1005, 1206])\n\n\n\n\n5.7.2 Element-wise array-array operations\nWhen we add, subtract, multiply and divide arrays with each other, the default behaviour is element-wise operations:\n\nX, Y = np.mgrid[0:4, 0:4]\nX, Y\n\n(array([[0, 0, 0, 0],\n        [1, 1, 1, 1],\n        [2, 2, 2, 2],\n        [3, 3, 3, 3]]),\n array([[0, 1, 2, 3],\n        [0, 1, 2, 3],\n        [0, 1, 2, 3],\n        [0, 1, 2, 3]]))\n\n\n\nmat = X**2 + Y**2\nmat\n\narray([[ 0,  1,  4,  9],\n       [ 1,  2,  5, 10],\n       [ 4,  5,  8, 13],\n       [ 9, 10, 13, 18]])\n\n\n\nmat * mat # element-wise multiplication\n\narray([[  0,   1,  16,  81],\n       [  1,   4,  25, 100],\n       [ 16,  25,  64, 169],\n       [ 81, 100, 169, 324]])\n\n\nIf we multiply arrays with compatible shapes, we get an element-wise multiplication of each row:\n\nvec = np.array([0, 0, 1, 0])\n\n\nvec\n\narray([0, 0, 1, 0])\n\n\n\nmat.shape, vec.shape\n\n((4, 4), (4,))\n\n\n\nmat * vec\n\narray([[ 0,  0,  4,  0],\n       [ 0,  0,  5,  0],\n       [ 0,  0,  8,  0],\n       [ 0,  0, 13,  0]])\n\n\nNumpy supports broadcasting i.e automatically reshaping of the dimensions when performing element-wise operations:\n\nimport numpy as np\n\n# create two arrays with different shapes\nx = np.array([1, 2, 3])\ny = np.array([4, 5, 6]).reshape((3, 1))\ny.shape\n\n(3, 1)\n\n\n\ny\n\narray([[4],\n       [5],\n       [6]])\n\n\n\nx\n\narray([1, 2, 3])\n\n\n\nx.shape\n\n(3,)\n\n\n\nx_new = np.array([1, 2, 3, 4, 5, 6])\nx_new.shape\n\n(6,)\n\n\n\nx\n\narray([1, 2, 3])\n\n\n\ny\n\narray([[4],\n       [5],\n       [6]])\n\n\n\nmy_new_array_with_new_axis = x[np.newaxis, :]\n\n\nmy_new_array_with_new_axis\n\narray([[1, 2, 3]])\n\n\n\nmy_new_array_with_new_axis.shape\n\n(1, 3)\n\n\n\n# perform broadcasting\nz =  my_new_array_with_new_axis + y\n# print the result\nprint(z)\n\n[[5 6 7]\n [6 7 8]\n [7 8 9]]\n\n\n\n\n5.7.3 5.4.3 Matrix algebra\nWhat about matrix mutiplication? There are two ways. We can use the dot function, which applies a matrix-matrix, matrix-vector, or inner vector multiplication to its two arguments:\n\nmat\n\narray([[ 0,  1,  4,  9],\n       [ 1,  2,  5, 10],\n       [ 4,  5,  8, 13],\n       [ 9, 10, 13, 18]])\n\n\n\nnp.dot(mat, mat)\n\narray([[ 98, 112, 154, 224],\n       [112, 130, 184, 274],\n       [154, 184, 274, 424],\n       [224, 274, 424, 674]])\n\n\n\nmat\n\narray([[ 0,  1,  4,  9],\n       [ 1,  2,  5, 10],\n       [ 4,  5,  8, 13],\n       [ 9, 10, 13, 18]])\n\n\n\nmat.T\n\narray([[ 0,  1,  4,  9],\n       [ 1,  2,  5, 10],\n       [ 4,  5,  8, 13],\n       [ 9, 10, 13, 18]])\n\n\n\nmat@vec # short form for matrix multiplication\n\narray([ 4,  5,  8, 13])\n\n\n\nv1\n\narray([0, 1, 2, 3, 4, 5, 6])\n\n\n\nnp.dot(v1, v1)\n\n91\n\n\n\nv1\n\narray([0, 1, 2, 3, 4, 5, 6])\n\n\n\n\n5.7.4 Matrix computations\n\n5.7.4.1 Inverse\n\nnp.linalg.inv(mat) # not recommended for very large matrices ! Use Linear Solvers \n\narray([[ 5.07905958e+15, -3.60287970e+15, -3.37769972e+15,\n         1.90151984e+15],\n       [-4.10327966e+15,  1.80143985e+15,  4.50359963e+15,\n        -2.20175982e+15],\n       [-2.57705979e+15,  3.60287970e+15, -1.12589991e+15,\n         1.00079992e+14],\n       [ 1.60127987e+15, -1.80143985e+15, -0.00000000e+00,\n         2.00159983e+14]])\n\n\n\n\n5.7.4.2 Determinant\n\nnp.linalg.det(mat)\n\n4.437342591868214e-30",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Arrays and Array Operations using NumPy</span>"
    ]
  },
  {
    "objectID": "05_numpy.html#data-processing",
    "href": "05_numpy.html#data-processing",
    "title": "5  Arrays and Array Operations using NumPy",
    "section": "5.8 Data processing",
    "text": "5.8 Data processing\nNumpy provides a number of functions to calculate statistics of datasets in arrays. For example, let’s calculate some properties temperature dataset used above.\n\n# reminder, the tempeature dataset is stored in the temperature_anomaly variable:\nnp.shape(temperature_anomaly)\ntemperature_anomaly\n\narray([[1879.  ,  272.95],\n       [1881.  ,  272.95],\n       [1882.  ,  272.94],\n       [1883.  ,  272.89],\n       [1884.  ,  272.72],\n       [1885.  ,  272.72],\n       [1886.  ,  272.74],\n       [1887.  ,  272.69],\n       [1888.  ,  272.84],\n       [1889.  ,  272.87],\n       [1890.  ,  272.63],\n       [1891.  ,  272.8 ],\n       [1892.  ,  272.67],\n       [1893.  ,  272.7 ],\n       [1894.  ,  272.71],\n       [1895.  ,  272.77],\n       [1896.  ,  272.96],\n       [1897.  ,  272.92],\n       [1898.  ,  272.76],\n       [1899.  ,  272.9 ],\n       [1900.  ,  272.93],\n       [1901.  ,  272.82],\n       [1902.  ,  272.71],\n       [1903.  ,  272.55],\n       [1904.  ,  272.56],\n       [1905.  ,  272.81],\n       [1906.  ,  272.76],\n       [1907.  ,  272.68],\n       [1908.  ,  272.55],\n       [1909.  ,  272.67],\n       [1910.  ,  272.65],\n       [1911.  ,  272.56],\n       [1912.  ,  272.54],\n       [1913.  ,  272.71],\n       [1914.  ,  272.8 ],\n       [1915.  ,  272.88],\n       [1916.  ,  272.68],\n       [1917.  ,  272.83],\n       [1918.  ,  272.69],\n       [1919.  ,  272.7 ],\n       [1920.  ,  272.76],\n       [1921.  ,  272.78],\n       [1922.  ,  272.7 ],\n       [1923.  ,  272.67],\n       [1924.  ,  272.69],\n       [1925.  ,  272.85],\n       [1926.  ,  272.9 ],\n       [1927.  ,  272.85],\n       [1928.  ,  272.8 ],\n       [1929.  ,  272.76],\n       [1930.  ,  272.91],\n       [1931.  ,  273.01],\n       [1932.  ,  272.81],\n       [1933.  ,  272.79],\n       [1934.  ,  272.95],\n       [1935.  ,  272.85],\n       [1936.  ,  272.92],\n       [1937.  ,  273.08],\n       [1938.  ,  272.95],\n       [1939.  ,  273.05],\n       [1940.  ,  273.13],\n       [1941.  ,  273.24],\n       [1942.  ,  273.  ],\n       [1943.  ,  273.07],\n       [1944.  ,  273.27],\n       [1945.  ,  273.36],\n       [1946.  ,  272.89],\n       [1947.  ,  272.93],\n       [1948.  ,  272.96],\n       [1949.  ,  272.93],\n       [1950.  ,  272.88],\n       [1951.  ,  273.12],\n       [1952.  ,  273.07],\n       [1953.  ,  273.11],\n       [1954.  ,  272.91],\n       [1955.  ,  272.98],\n       [1956.  ,  272.83],\n       [1957.  ,  273.16],\n       [1958.  ,  273.09],\n       [1959.  ,  273.07],\n       [1960.  ,  273.09],\n       [1961.  ,  273.05],\n       [1962.  ,  273.08],\n       [1963.  ,  273.18],\n       [1964.  ,  272.84],\n       [1965.  ,  272.95],\n       [1966.  ,  273.05],\n       [1967.  ,  273.01],\n       [1968.  ,  273.01],\n       [1969.  ,  273.11],\n       [1970.  ,  273.02],\n       [1971.  ,  272.96],\n       [1972.  ,  273.1 ],\n       [1973.  ,  273.12],\n       [1974.  ,  273.04],\n       [1975.  ,  272.96],\n       [1976.  ,  272.95],\n       [1977.  ,  273.15],\n       [1978.  ,  273.01],\n       [1979.  ,  273.24],\n       [1980.  ,  273.21],\n       [1981.  ,  273.24],\n       [1982.  ,  273.14],\n       [1983.  ,  273.36],\n       [1984.  ,  273.19],\n       [1985.  ,  273.16],\n       [1986.  ,  273.2 ],\n       [1987.  ,  273.4 ],\n       [1988.  ,  273.34],\n       [1989.  ,  273.32],\n       [1990.  ,  273.39],\n       [1991.  ,  273.37],\n       [1992.  ,  273.11],\n       [1993.  ,  273.22],\n       [1994.  ,  273.3 ],\n       [1995.  ,  273.5 ],\n       [1996.  ,  273.34],\n       [1997.  ,  273.55],\n       [1998.  ,  273.71],\n       [1999.  ,  273.36],\n       [2000.  ,  273.46],\n       [2001.  ,  273.61],\n       [2002.  ,  273.56],\n       [2003.  ,  273.66],\n       [2004.  ,  273.52],\n       [2005.  ,  273.63],\n       [2006.  ,  273.65],\n       [2007.  ,  273.56],\n       [2008.  ,  273.57],\n       [2009.  ,  273.72],\n       [2010.  ,  273.69],\n       [2011.  ,  273.65],\n       [2012.  ,  273.7 ],\n       [2013.  ,  273.68],\n       [2014.  ,  273.82],\n       [2015.  ,  273.91],\n       [2016.  ,  273.98],\n       [2017.  ,  273.92],\n       [2018.  ,  273.79],\n       [2019.  ,  273.92],\n       [2020.  ,  273.93],\n       [2021.  ,  273.89],\n       [2022.  ,  273.9 ]])\n\n\n\n5.8.1 mean\n\nnp.mean(temperature_anomaly[:, 1])\n\n273.0862937062937\n\n\nThe daily mean temperature is 273.08\n\n\n5.8.2 standard deviations and variance\n\nnp.std(temperature_anomaly[:, 1])\n\n0.3585102788349587\n\n\n\nnp.var(temperature_anomaly[:, 1])\n\n0.1285296200303198\n\n\n\n\n5.8.3 min and max\n\ntemperature_anomaly\n\narray([[1879.  ,  272.95],\n       [1881.  ,  272.95],\n       [1882.  ,  272.94],\n       [1883.  ,  272.89],\n       [1884.  ,  272.72],\n       [1885.  ,  272.72],\n       [1886.  ,  272.74],\n       [1887.  ,  272.69],\n       [1888.  ,  272.84],\n       [1889.  ,  272.87],\n       [1890.  ,  272.63],\n       [1891.  ,  272.8 ],\n       [1892.  ,  272.67],\n       [1893.  ,  272.7 ],\n       [1894.  ,  272.71],\n       [1895.  ,  272.77],\n       [1896.  ,  272.96],\n       [1897.  ,  272.92],\n       [1898.  ,  272.76],\n       [1899.  ,  272.9 ],\n       [1900.  ,  272.93],\n       [1901.  ,  272.82],\n       [1902.  ,  272.71],\n       [1903.  ,  272.55],\n       [1904.  ,  272.56],\n       [1905.  ,  272.81],\n       [1906.  ,  272.76],\n       [1907.  ,  272.68],\n       [1908.  ,  272.55],\n       [1909.  ,  272.67],\n       [1910.  ,  272.65],\n       [1911.  ,  272.56],\n       [1912.  ,  272.54],\n       [1913.  ,  272.71],\n       [1914.  ,  272.8 ],\n       [1915.  ,  272.88],\n       [1916.  ,  272.68],\n       [1917.  ,  272.83],\n       [1918.  ,  272.69],\n       [1919.  ,  272.7 ],\n       [1920.  ,  272.76],\n       [1921.  ,  272.78],\n       [1922.  ,  272.7 ],\n       [1923.  ,  272.67],\n       [1924.  ,  272.69],\n       [1925.  ,  272.85],\n       [1926.  ,  272.9 ],\n       [1927.  ,  272.85],\n       [1928.  ,  272.8 ],\n       [1929.  ,  272.76],\n       [1930.  ,  272.91],\n       [1931.  ,  273.01],\n       [1932.  ,  272.81],\n       [1933.  ,  272.79],\n       [1934.  ,  272.95],\n       [1935.  ,  272.85],\n       [1936.  ,  272.92],\n       [1937.  ,  273.08],\n       [1938.  ,  272.95],\n       [1939.  ,  273.05],\n       [1940.  ,  273.13],\n       [1941.  ,  273.24],\n       [1942.  ,  273.  ],\n       [1943.  ,  273.07],\n       [1944.  ,  273.27],\n       [1945.  ,  273.36],\n       [1946.  ,  272.89],\n       [1947.  ,  272.93],\n       [1948.  ,  272.96],\n       [1949.  ,  272.93],\n       [1950.  ,  272.88],\n       [1951.  ,  273.12],\n       [1952.  ,  273.07],\n       [1953.  ,  273.11],\n       [1954.  ,  272.91],\n       [1955.  ,  272.98],\n       [1956.  ,  272.83],\n       [1957.  ,  273.16],\n       [1958.  ,  273.09],\n       [1959.  ,  273.07],\n       [1960.  ,  273.09],\n       [1961.  ,  273.05],\n       [1962.  ,  273.08],\n       [1963.  ,  273.18],\n       [1964.  ,  272.84],\n       [1965.  ,  272.95],\n       [1966.  ,  273.05],\n       [1967.  ,  273.01],\n       [1968.  ,  273.01],\n       [1969.  ,  273.11],\n       [1970.  ,  273.02],\n       [1971.  ,  272.96],\n       [1972.  ,  273.1 ],\n       [1973.  ,  273.12],\n       [1974.  ,  273.04],\n       [1975.  ,  272.96],\n       [1976.  ,  272.95],\n       [1977.  ,  273.15],\n       [1978.  ,  273.01],\n       [1979.  ,  273.24],\n       [1980.  ,  273.21],\n       [1981.  ,  273.24],\n       [1982.  ,  273.14],\n       [1983.  ,  273.36],\n       [1984.  ,  273.19],\n       [1985.  ,  273.16],\n       [1986.  ,  273.2 ],\n       [1987.  ,  273.4 ],\n       [1988.  ,  273.34],\n       [1989.  ,  273.32],\n       [1990.  ,  273.39],\n       [1991.  ,  273.37],\n       [1992.  ,  273.11],\n       [1993.  ,  273.22],\n       [1994.  ,  273.3 ],\n       [1995.  ,  273.5 ],\n       [1996.  ,  273.34],\n       [1997.  ,  273.55],\n       [1998.  ,  273.71],\n       [1999.  ,  273.36],\n       [2000.  ,  273.46],\n       [2001.  ,  273.61],\n       [2002.  ,  273.56],\n       [2003.  ,  273.66],\n       [2004.  ,  273.52],\n       [2005.  ,  273.63],\n       [2006.  ,  273.65],\n       [2007.  ,  273.56],\n       [2008.  ,  273.57],\n       [2009.  ,  273.72],\n       [2010.  ,  273.69],\n       [2011.  ,  273.65],\n       [2012.  ,  273.7 ],\n       [2013.  ,  273.68],\n       [2014.  ,  273.82],\n       [2015.  ,  273.91],\n       [2016.  ,  273.98],\n       [2017.  ,  273.92],\n       [2018.  ,  273.79],\n       [2019.  ,  273.92],\n       [2020.  ,  273.93],\n       [2021.  ,  273.89],\n       [2022.  ,  273.9 ]])\n\n\n\n# lowest anomaly\ntemperature_anomaly[:, 1].min()\n\n272.54\n\n\n\n# highest anomaly\ntemperature_anomaly[:, 1].max()\n\n273.98\n\n\n\ntemperature_anomaly\n\narray([[1879.  ,  272.95],\n       [1881.  ,  272.95],\n       [1882.  ,  272.94],\n       [1883.  ,  272.89],\n       [1884.  ,  272.72],\n       [1885.  ,  272.72],\n       [1886.  ,  272.74],\n       [1887.  ,  272.69],\n       [1888.  ,  272.84],\n       [1889.  ,  272.87],\n       [1890.  ,  272.63],\n       [1891.  ,  272.8 ],\n       [1892.  ,  272.67],\n       [1893.  ,  272.7 ],\n       [1894.  ,  272.71],\n       [1895.  ,  272.77],\n       [1896.  ,  272.96],\n       [1897.  ,  272.92],\n       [1898.  ,  272.76],\n       [1899.  ,  272.9 ],\n       [1900.  ,  272.93],\n       [1901.  ,  272.82],\n       [1902.  ,  272.71],\n       [1903.  ,  272.55],\n       [1904.  ,  272.56],\n       [1905.  ,  272.81],\n       [1906.  ,  272.76],\n       [1907.  ,  272.68],\n       [1908.  ,  272.55],\n       [1909.  ,  272.67],\n       [1910.  ,  272.65],\n       [1911.  ,  272.56],\n       [1912.  ,  272.54],\n       [1913.  ,  272.71],\n       [1914.  ,  272.8 ],\n       [1915.  ,  272.88],\n       [1916.  ,  272.68],\n       [1917.  ,  272.83],\n       [1918.  ,  272.69],\n       [1919.  ,  272.7 ],\n       [1920.  ,  272.76],\n       [1921.  ,  272.78],\n       [1922.  ,  272.7 ],\n       [1923.  ,  272.67],\n       [1924.  ,  272.69],\n       [1925.  ,  272.85],\n       [1926.  ,  272.9 ],\n       [1927.  ,  272.85],\n       [1928.  ,  272.8 ],\n       [1929.  ,  272.76],\n       [1930.  ,  272.91],\n       [1931.  ,  273.01],\n       [1932.  ,  272.81],\n       [1933.  ,  272.79],\n       [1934.  ,  272.95],\n       [1935.  ,  272.85],\n       [1936.  ,  272.92],\n       [1937.  ,  273.08],\n       [1938.  ,  272.95],\n       [1939.  ,  273.05],\n       [1940.  ,  273.13],\n       [1941.  ,  273.24],\n       [1942.  ,  273.  ],\n       [1943.  ,  273.07],\n       [1944.  ,  273.27],\n       [1945.  ,  273.36],\n       [1946.  ,  272.89],\n       [1947.  ,  272.93],\n       [1948.  ,  272.96],\n       [1949.  ,  272.93],\n       [1950.  ,  272.88],\n       [1951.  ,  273.12],\n       [1952.  ,  273.07],\n       [1953.  ,  273.11],\n       [1954.  ,  272.91],\n       [1955.  ,  272.98],\n       [1956.  ,  272.83],\n       [1957.  ,  273.16],\n       [1958.  ,  273.09],\n       [1959.  ,  273.07],\n       [1960.  ,  273.09],\n       [1961.  ,  273.05],\n       [1962.  ,  273.08],\n       [1963.  ,  273.18],\n       [1964.  ,  272.84],\n       [1965.  ,  272.95],\n       [1966.  ,  273.05],\n       [1967.  ,  273.01],\n       [1968.  ,  273.01],\n       [1969.  ,  273.11],\n       [1970.  ,  273.02],\n       [1971.  ,  272.96],\n       [1972.  ,  273.1 ],\n       [1973.  ,  273.12],\n       [1974.  ,  273.04],\n       [1975.  ,  272.96],\n       [1976.  ,  272.95],\n       [1977.  ,  273.15],\n       [1978.  ,  273.01],\n       [1979.  ,  273.24],\n       [1980.  ,  273.21],\n       [1981.  ,  273.24],\n       [1982.  ,  273.14],\n       [1983.  ,  273.36],\n       [1984.  ,  273.19],\n       [1985.  ,  273.16],\n       [1986.  ,  273.2 ],\n       [1987.  ,  273.4 ],\n       [1988.  ,  273.34],\n       [1989.  ,  273.32],\n       [1990.  ,  273.39],\n       [1991.  ,  273.37],\n       [1992.  ,  273.11],\n       [1993.  ,  273.22],\n       [1994.  ,  273.3 ],\n       [1995.  ,  273.5 ],\n       [1996.  ,  273.34],\n       [1997.  ,  273.55],\n       [1998.  ,  273.71],\n       [1999.  ,  273.36],\n       [2000.  ,  273.46],\n       [2001.  ,  273.61],\n       [2002.  ,  273.56],\n       [2003.  ,  273.66],\n       [2004.  ,  273.52],\n       [2005.  ,  273.63],\n       [2006.  ,  273.65],\n       [2007.  ,  273.56],\n       [2008.  ,  273.57],\n       [2009.  ,  273.72],\n       [2010.  ,  273.69],\n       [2011.  ,  273.65],\n       [2012.  ,  273.7 ],\n       [2013.  ,  273.68],\n       [2014.  ,  273.82],\n       [2015.  ,  273.91],\n       [2016.  ,  273.98],\n       [2017.  ,  273.92],\n       [2018.  ,  273.79],\n       [2019.  ,  273.92],\n       [2020.  ,  273.93],\n       [2021.  ,  273.89],\n       [2022.  ,  273.9 ]])\n\n\nFind the year when the anomaly was minimum ?\n\nmin_locations = np.argmin(temperature_anomaly, axis=0)\nmin_locations\n\narray([ 0, 32])\n\n\n\ntemperature_anomaly[32, :]\n\narray([1912.  ,  272.54])\n\n\nWhen min, max, etc. are applied to higher-dimensional arrays like 2D or 3D arrays, it is useful to evaluate the entire array or only on a row or column. Using the axis argument we can control this !\n\nm = np.random.rand(6, 6)\nm\n\narray([[0.92084587, 0.83769328, 0.87385444, 0.36796683, 0.64317798,\n        0.75648914],\n       [0.16860959, 0.64996057, 0.78340205, 0.94553299, 0.14836087,\n        0.41122111],\n       [0.91013989, 0.18931111, 0.82293422, 0.70285854, 0.7064657 ,\n        0.37610865],\n       [0.55145562, 0.12973391, 0.30979382, 0.9573351 , 0.36949913,\n        0.84352728],\n       [0.72575704, 0.11363448, 0.67097583, 0.70763189, 0.10954956,\n        0.60787496],\n       [0.29502524, 0.83435376, 0.10527079, 0.60552895, 0.76232267,\n        0.63480999]])\n\n\n\n# global max\nm.max()\n\n0.9573351026780254\n\n\n\n# max in each column\nm.max(axis=0)\n\narray([0.92084587, 0.83769328, 0.87385444, 0.9573351 , 0.76232267,\n       0.84352728])\n\n\n\n# max in each row\nm.max(axis=1)\n\narray([0.92084587, 0.94553299, 0.91013989, 0.9573351 , 0.72575704,\n       0.83435376])\n\n\nMany other functions and methods in the array and matrix classes accept the same (optional) axis keyword argument.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Arrays and Array Operations using NumPy</span>"
    ]
  },
  {
    "objectID": "05_numpy.html#reshaping-resizing-and-stacking-arrays",
    "href": "05_numpy.html#reshaping-resizing-and-stacking-arrays",
    "title": "5  Arrays and Array Operations using NumPy",
    "section": "5.9 Reshaping, resizing and stacking arrays",
    "text": "5.9 Reshaping, resizing and stacking arrays\n\n5.9.1 Reshaping\nThe shape of an Numpy array can be modified without copying the underlaying data, which makes it a fast operation even for large arrays.\n\nimport numpy as np\n\n\na_vector = np.arange(0, 16, 1)\na_vector\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n\n\n\na_vector.shape\n\n(16,)\n\n\n\na_vector.reshape((4, 4))\n\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11],\n       [12, 13, 14, 15]])\n\n\n\na_vector\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n\n\n\na_matrix = a_vector.reshape((4, 4))\na_matrix\n\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11],\n       [12, 13, 14, 15]])\n\n\n\na_matrix[2, 0:4] = - 1100 # modify the array\n\na_matrix\n\narray([[    0,     1,     2,     3],\n       [    4,     5,     6,     7],\n       [-1100, -1100, -1100, -1100],\n       [   12,    13,    14,    15]])\n\n\n\na_vector # and the original vector is also changed  !\n\narray([    0,     1,     2,     3,     4,     5,     6,     7, -1100,\n       -1100, -1100, -1100,    12,    13,    14,    15])\n\n\nWe can also use the function flatten to make a higher-dimensional array into a vector and this function creates a copy of the data. However reshape does not make a copy !\n\n\n5.9.2 5.6.2 Adding a new dimension\nWith newaxis, we can insert new dimensions in an array, for example converting a vector to a column or row matrix:\n\nv = np.array([1,2,3])\nv\n\narray([1, 2, 3])\n\n\n\nnp.shape(v)\n\n(3,)\n\n\n\nv[:, np.newaxis]\n\narray([[1],\n       [2],\n       [3]])\n\n\n\nv[:, np.newaxis].shape\n\n(3, 1)\n\n\n\nv[np.newaxis, :].shape\n\n(1, 3)\n\n\n\n\n5.9.3 Stacking and repeating arrays\n\n5.9.3.1 tile and repeat\n\na = np.array([[1, 2], [3, 4]])\na\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nnp.repeat(a, 3)\n\narray([1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4])\n\n\n\nnp.tile(a, 3)\n\narray([[1, 2, 1, 2, 1, 2],\n       [3, 4, 3, 4, 3, 4]])\n\n\n\n\n5.9.3.2 concatenate\n\nb = np.array([[5, 6]])\nb\n\narray([[5, 6]])\n\n\n\nb.shape\n\n(1, 2)\n\n\n\nnp.concatenate((a, b), axis=0)\n\narray([[1, 2],\n       [3, 4],\n       [5, 6]])\n\n\n\nnp.concatenate((a, b.T), axis=1)\n\narray([[1, 2, 5],\n       [3, 4, 6]])\n\n\n\n(b.T).shape\n\n(2, 1)\n\n\n\n\n5.9.3.3 hstack and vstack\n\nnp.vstack((a, b))\n\narray([[1, 2],\n       [3, 4],\n       [5, 6]])\n\n\n\nnp.hstack((a, b.T))\n\narray([[1, 2, 5],\n       [3, 4, 6]])",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Arrays and Array Operations using NumPy</span>"
    ]
  },
  {
    "objectID": "05_numpy.html#copy-and-deep-copy",
    "href": "05_numpy.html#copy-and-deep-copy",
    "title": "5  Arrays and Array Operations using NumPy",
    "section": "5.10 Copy and “deep copy”",
    "text": "5.10 Copy and “deep copy”\nTo conserve memory, references in Python usually do not copy the underlying objects. For example, this is important when passing objects between functions to avoid excessive copying of memory when it is not necessary (technical term: pass by reference).\n\nimport numpy as np\n\n\nA = np.reshape(np.arange(0, 9, 1), (3, 3))\n\nA\n\narray([[0, 1, 2],\n       [3, 4, 5],\n       [6, 7, 8]])\n\n\n\n# now B is referring to the same array data as A !\nB = A \n\n\n# changing B affects A\nB[0, 0] = 100\n\nB\n\narray([[100,   1,   2],\n       [  3,   4,   5],\n       [  6,   7,   8]])\n\n\n\nA\n\narray([[100,   1,   2],\n       [  3,   4,   5],\n       [  6,   7,   8]])\n\n\nIf we want to avoid this behavior, so that when we get a new completely independent object B copied from A, then we need to do a so-called “deep copy” using the function copy:\n\nB = np.copy(A)\n\n\n# now, if we modify B, A is not affected\nB[0, 0] = -5\n\nB\n\narray([[-5,  1,  2],\n       [ 3,  4,  5],\n       [ 6,  7,  8]])\n\n\n\nA\n\narray([[100,   1,   2],\n       [  3,   4,   5],\n       [  6,   7,   8]])",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Arrays and Array Operations using NumPy</span>"
    ]
  },
  {
    "objectID": "05_numpy.html#iterating-over-array-elements",
    "href": "05_numpy.html#iterating-over-array-elements",
    "title": "5  Arrays and Array Operations using NumPy",
    "section": "5.11 Iterating over array elements",
    "text": "5.11 Iterating over array elements\nFor loops accept numpy arrays !\n\nv = np.arange(1, 11, 1)\n\n\nv\n\narray([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n\n\n\nfor value in v:\n    print(value)\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\nM = np.array([[1.0, 2], [3, 4]])\nM\n\narray([[1., 2.],\n       [3., 4.]])\n\n\n\nnp.sin(M)\n\narray([[ 0.84147098,  0.90929743],\n       [ 0.14112001, -0.7568025 ]])\n\n\n\nfor row in M:\n    print('row', row)    \n    for element in row:\n        print(element)\n\nrow [1. 2.]\n1.0\n2.0\nrow [3. 4.]\n3.0\n4.0\n\n\nWhen we need to iterate over each element of an array and modify its elements, it is convenient to use the enumerate function to obtain both the element and its index in the for loop:\n\nimport math\n\nfor row_idx, row in enumerate(M):\n    print('row_index', row_idx, 'row', row)\n    \n    for col_idx, element in enumerate(row):\n        print('col_idexx', col_idx, 'element', element)\n       \n        # update the matrix M: square each element\n        print(math.sin(element))\n        M[row_idx, col_idx] = math.sin(element)\n\nrow_index 0 row [1. 2.]\ncol_idexx 0 element 1.0\n0.8414709848078965\ncol_idexx 1 element 2.0\n0.9092974268256817\nrow_index 1 row [3. 4.]\ncol_idexx 0 element 3.0\n0.1411200080598672\ncol_idexx 1 element 4.0\n-0.7568024953079283",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Arrays and Array Operations using NumPy</span>"
    ]
  },
  {
    "objectID": "05_numpy.html#conditionals",
    "href": "05_numpy.html#conditionals",
    "title": "5  Arrays and Array Operations using NumPy",
    "section": "5.12 Conditionals",
    "text": "5.12 Conditionals\nWhen using arrays in conditions, for example if statements and other boolean expressions, one needs to use any or all, which requires that any or all elements in the array evalutes to True:\n\nrandom_array = np.random.randn(10, 10)\nrandom_array\n\narray([[-0.6134998 , -0.61498391,  0.33645235, -1.82074071,  0.69096713,\n         0.03101806, -0.64281014, -0.54610706, -0.12709406,  0.49830532],\n       [ 0.34374911,  0.27346567,  0.58695865, -0.13285555, -0.77402891,\n        -0.16024065, -0.7095337 , -2.5276017 , -1.24014576,  1.85690544],\n       [-0.08776237,  0.08972077,  1.4872167 , -0.43256367,  0.32936274,\n        -0.09270388, -0.24157208, -1.25312486,  1.13374768, -0.50736087],\n       [ 1.62029448, -1.57286934,  1.7816456 ,  2.0405922 ,  2.02486901,\n        -0.61025683, -0.13590013,  0.88858846, -0.56092565,  0.31790237],\n       [ 0.62793353, -2.49321515, -1.37183219,  0.54193722, -0.45898922,\n        -0.38904427,  0.40364388, -0.62351577, -0.63277544, -0.53228619],\n       [-0.1998698 , -1.26131351, -0.62059607,  0.10504825, -0.08459757,\n        -0.1680185 ,  1.25991351, -1.58886168,  0.52847719, -0.47481283],\n       [-1.39205489,  0.84332552,  0.45859446,  1.50910174,  0.11844143,\n         1.73421922,  1.39776966, -0.99044085,  0.0995908 ,  2.16738259],\n       [-1.15132718, -0.70026338, -2.47932371,  0.2429653 , -0.04874982,\n         0.29579343, -1.21910561,  0.30848336,  0.22878713, -0.45677434],\n       [ 0.19195708, -0.51314493, -1.09765888, -0.80483466,  0.12255335,\n         0.54135198, -0.31039132,  0.94565877, -0.97101407, -0.64390854],\n       [-1.14253562, -0.38351911, -0.30864055, -0.90090609,  0.73043985,\n        -0.66122357,  0.28537238,  0.7252351 , -0.59181682,  1.27642334]])\n\n\n\nif (random_array &gt; 0.5).any():\n    print('at least one element in random_array is larger than 0.5')\nelse:\n    print('no element in random_array is larger than 0.5')\n\nat least one element in random_array is larger than 0.5\n\n\n\nif (random_array &gt; 0.5).all():\n    print('all elements in random_array are larger than 0.5')\nelse:\n    print('not all elements in random_array are not larger than 0.5')\n\nnot all elements in random_array are not larger than 0.5\n\n\n\n(random_array &gt; 0.5).all()\n\nFalse",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Arrays and Array Operations using NumPy</span>"
    ]
  },
  {
    "objectID": "05_numpy.html#type-casting",
    "href": "05_numpy.html#type-casting",
    "title": "5  Arrays and Array Operations using NumPy",
    "section": "5.13 Type casting",
    "text": "5.13 Type casting\nSince Numpy arrays are statically typed, the type of an array does not change once created. But we can explicitly cast an array of some type to another using the astype functions (see also the similar asarray function). This always creates a new array of new type:\n\nrandom_array.dtype\n\ndtype('float64')\n\n\n\nrandom_array_2 = random_array.astype(int)\n\nrandom_array_2\n\narray([[ 0,  0,  0, -1,  0,  0,  0,  0,  0,  0],\n       [ 0,  0,  0,  0,  0,  0,  0, -2, -1,  1],\n       [ 0,  0,  1,  0,  0,  0,  0, -1,  1,  0],\n       [ 1, -1,  1,  2,  2,  0,  0,  0,  0,  0],\n       [ 0, -2, -1,  0,  0,  0,  0,  0,  0,  0],\n       [ 0, -1,  0,  0,  0,  0,  1, -1,  0,  0],\n       [-1,  0,  0,  1,  0,  1,  1,  0,  0,  2],\n       [-1,  0, -2,  0,  0,  0, -1,  0,  0,  0],\n       [ 0,  0, -1,  0,  0,  0,  0,  0,  0,  0],\n       [-1,  0,  0,  0,  0,  0,  0,  0,  0,  1]])\n\n\n\nrandom_array_2.dtype\n\ndtype('int64')\n\n\n\nboolean_array = random_array_2.astype(bool)\n\nboolean_array\n\narray([[False, False, False,  True, False, False, False, False, False,\n        False],\n       [False, False, False, False, False, False, False,  True,  True,\n         True],\n       [False, False,  True, False, False, False, False,  True,  True,\n        False],\n       [ True,  True,  True,  True,  True, False, False, False, False,\n        False],\n       [False,  True,  True, False, False, False, False, False, False,\n        False],\n       [False,  True, False, False, False, False,  True,  True, False,\n        False],\n       [ True, False, False,  True, False,  True,  True, False, False,\n         True],\n       [ True, False,  True, False, False, False,  True, False, False,\n        False],\n       [False, False,  True, False, False, False, False, False, False,\n        False],\n       [ True, False, False, False, False, False, False, False, False,\n         True]])",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Arrays and Array Operations using NumPy</span>"
    ]
  },
  {
    "objectID": "05_numpy.html#exercises",
    "href": "05_numpy.html#exercises",
    "title": "5  Arrays and Array Operations using NumPy",
    "section": "5.14 Exercises",
    "text": "5.14 Exercises\n\n5.14.1 Theory\n\nWhat is NumPy and why is it important for scientific computing in Python?\nExplain the difference between a Python list and a NumPy array.\nHow can you create a new NumPy array with all values initialized to zero?\nHow can you use NumPy to perform element-wise mathematical operations on arrays?\nWhat is broadcasting in NumPy and how can it be useful?\n\n\n\n5.14.2 Coding\nWrite a NumPy program to create:\n\nan array of 10 random integers and find the sum of all elements.\na 3x3 matrix with values ranging from 0 to 8 and slice out the first row.\na 3x3 identity matrix and multiply it by a 3x2 matrix containing random values.\nan array of 6 elements and reshape it into a 2x3 matrix.\na 2x2 matrix and calculate its determinant.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Arrays and Array Operations using NumPy</span>"
    ]
  },
  {
    "objectID": "05_numpy.html#further-reading",
    "href": "05_numpy.html#further-reading",
    "title": "5  Arrays and Array Operations using NumPy",
    "section": "5.15 Further Reading",
    "text": "5.15 Further Reading\n\nhttps://numpy.org/doc/stable/user/basics.html\nhttps://numpy.org/doc/stable/user/numpy-for-matlab-users.html",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Arrays and Array Operations using NumPy</span>"
    ]
  },
  {
    "objectID": "06_pandas.html",
    "href": "06_pandas.html",
    "title": "6  Dataframes and Series for Data Wrangling",
    "section": "",
    "text": "6.1 Data creation and Selection\nThere are two core objects in pandas: the DataFrame and the Series.\nA DataFrame is a table. It contains an array of individual entries, each of which has a certain value. Each entry corresponds to a row (or record) and a column.\nWe can create a dataframe using the following explicit expression !\npd.DataFrame({'Density': [997, 8000], 'Stiffness': [0, 200]}, index=['Water', 'Steel'])\n\n\n\n\n\n\n\n\nDensity\nStiffness\n\n\n\n\nWater\n997\n0\n\n\nSteel\n8000\n200\nFor the purpose of this tutorial, let us import an excel file with some data. The data is stored in the folder. First store the data in a certain location in our PC. It is recommended that you create a folder called data in the folder where this Jupyter notebook is stored. Then save the data provided in moodle in this data folder.\nfolder = './data/'\ndata_location = folder + 'Concrete_Data.xls'\ndata_location\n\n'./data/Concrete_Data.xls'\n. represents the directory you are in and .. represents the parent directory.\nLet us now read an excel table with the following command !\ndata = pd.read_excel(data_location)\n#help(pd.read_excel)\ndata\n\n\n\n\n\n\n\n\nCement\nBlast Furnace Slag\nFly Ash\nWater\nSuperplasticizer\nCoarse Aggregate\nFine Aggregate\nAge\nStrength\n\n\n\n\n0\n540.0\n0.0\n0.0\n162.0\n2.5\n1040.0\n676.0\n28\n79.986111\n\n\n1\n540.0\n0.0\n0.0\n162.0\n2.5\n1055.0\n676.0\n28\n61.887366\n\n\n2\n332.5\n142.5\n0.0\n228.0\n0.0\n932.0\n594.0\n270\n40.269535\n\n\n3\n332.5\n142.5\n0.0\n228.0\n0.0\n932.0\n594.0\n365\n41.052780\n\n\n4\n198.6\n132.4\n0.0\n192.0\n0.0\n978.4\n825.5\n360\n44.296075\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1025\n276.4\n116.0\n90.3\n179.6\n8.9\n870.1\n768.3\n28\n44.284354\n\n\n1026\n322.2\n0.0\n115.6\n196.0\n10.4\n817.9\n813.4\n28\n31.178794\n\n\n1027\n148.5\n139.4\n108.6\n192.7\n6.1\n892.4\n780.0\n28\n23.696601\n\n\n1028\n159.1\n186.7\n0.0\n175.6\n11.3\n989.6\n788.9\n28\n32.768036\n\n\n1029\n260.9\n100.5\n78.3\n200.6\n8.6\n864.5\n761.5\n28\n32.401235\n\n\n\n\n1030 rows × 9 columns",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Dataframes and Series for Data Wrangling</span>"
    ]
  },
  {
    "objectID": "06_pandas.html#data-exploration-and-visualization",
    "href": "06_pandas.html#data-exploration-and-visualization",
    "title": "6  Dataframes and Series for Data Wrangling",
    "section": "6.2 Data Exploration and Visualization",
    "text": "6.2 Data Exploration and Visualization\nSometimes the excel table or csv file is very huge, but we can take a quick look at the data using the following command that gives us the first few lines of the table ! The head function displays the first few rows of the DataFrame, while the tail function displays the last few rows. The sample function displays a random sample of the DataFrame. For example:\n\n#data.head() # display first few rows\n#data.tail() # display last few rows\ndata.sample(10) # display a random sample of 5 rows\n\n\n\n\n\n\n\n\nCement\nBlast Furnace Slag\nFly Ash\nWater\nSuperplasticizer\nCoarse Aggregate\nFine Aggregate\nAge\nStrength\n\n\n\n\n892\n273.00\n0.00\n90.00\n199.00\n11.00\n931.00\n762.00\n28\n32.239898\n\n\n1015\n322.50\n148.60\n0.00\n185.80\n8.50\n951.00\n709.50\n28\n52.426376\n\n\n958\n259.90\n100.60\n78.40\n170.60\n10.40\n935.70\n762.90\n28\n49.773272\n\n\n817\n525.00\n0.00\n0.00\n189.00\n0.00\n1125.00\n613.00\n14\n48.401215\n\n\n244\n238.05\n0.00\n94.11\n186.66\n7.00\n949.91\n847.01\n3\n19.932751\n\n\n224\n167.95\n42.08\n163.83\n121.75\n5.72\n1058.70\n780.11\n3\n7.749710\n\n\n831\n154.00\n144.00\n112.00\n220.00\n10.00\n923.00\n658.00\n28\n16.499161\n\n\n465\n173.81\n93.37\n159.90\n172.34\n9.73\n1007.20\n746.60\n100\n50.938487\n\n\n872\n261.00\n100.00\n78.00\n201.00\n9.00\n864.00\n761.00\n28\n32.398477\n\n\n871\n159.00\n187.00\n0.00\n176.00\n11.00\n990.00\n789.00\n28\n32.763900\n\n\n\n\n\n\n\nThe data can also be sorted and explored as follows:\n\n# sort the dataframe\ndata.sort_values(by='Strength', ascending=False).head()\n\n\n\n\n\n\n\n\nCement\nBlast Furnace Slag\nFly Ash\nWater\nSuperplasticizer\nCoarse Aggregate\nFine Aggregate\nAge\nStrength\n\n\n\n\n181\n389.9\n189.0\n0.0\n145.9\n22.0\n944.7\n755.8\n91\n82.599225\n\n\n381\n315.0\n137.0\n0.0\n145.0\n5.9\n1130.0\n745.0\n28\n81.751169\n\n\n153\n323.7\n282.8\n0.0\n183.8\n10.3\n942.7\n659.9\n56\n80.199848\n\n\n0\n540.0\n0.0\n0.0\n162.0\n2.5\n1040.0\n676.0\n28\n79.986111\n\n\n159\n389.9\n189.0\n0.0\n145.9\n22.0\n944.7\n755.8\n56\n79.400056",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Dataframes and Series for Data Wrangling</span>"
    ]
  },
  {
    "objectID": "06_pandas.html#getting-and-setting-data",
    "href": "06_pandas.html#getting-and-setting-data",
    "title": "6  Dataframes and Series for Data Wrangling",
    "section": "6.3 Getting and Setting data",
    "text": "6.3 Getting and Setting data\nIndexing, similar to list indexing from the list data type and numpy can be used to access parts of the dataframe as follows:\n\n# using indexes to select data - similar to Numpy\ndata.iloc[0:2, :]\n\n\n\n\n\n\n\n\nCement\nBlast Furnace Slag\nFly Ash\nWater\nSuperplasticizer\nCoarse Aggregate\nFine Aggregate\nAge\nStrength\n\n\n\n\n0\n540.0\n0.0\n0.0\n162.0\n2.5\n1040.0\n676.0\n28\n79.986111\n\n\n1\n540.0\n0.0\n0.0\n162.0\n2.5\n1055.0\n676.0\n28\n61.887366\n\n\n\n\n\n\n\nThe data can also be filtered using boolean operators. This operation can be used as a mask to extract information from the data as follows:\n\nmy_data_mask = data['Age'] &gt; 300\n\nThe above mask can be applied as follows:\n\n# Boolean Indexing\ndata[my_data_mask]\n\n\n\n\n\n\n\n\nCement\nBlast Furnace Slag\nFly Ash\nWater\nSuperplasticizer\nCoarse Aggregate\nFine Aggregate\nAge\nStrength\n\n\n\n\n3\n332.5\n142.5\n0.0\n228.0\n0.0\n932.0\n594.0\n365\n41.052780\n\n\n4\n198.6\n132.4\n0.0\n192.0\n0.0\n978.4\n825.5\n360\n44.296075\n\n\n6\n380.0\n95.0\n0.0\n228.0\n0.0\n932.0\n594.0\n365\n43.698299\n\n\n17\n342.0\n38.0\n0.0\n228.0\n0.0\n932.0\n670.0\n365\n56.141962\n\n\n24\n380.0\n0.0\n0.0\n228.0\n0.0\n932.0\n670.0\n365\n52.516697\n\n\n30\n304.0\n76.0\n0.0\n228.0\n0.0\n932.0\n670.0\n365\n55.260122\n\n\n31\n266.0\n114.0\n0.0\n228.0\n0.0\n932.0\n670.0\n365\n52.908320\n\n\n34\n190.0\n190.0\n0.0\n228.0\n0.0\n932.0\n670.0\n365\n53.692254\n\n\n41\n427.5\n47.5\n0.0\n228.0\n0.0\n932.0\n594.0\n365\n43.698299\n\n\n42\n237.5\n237.5\n0.0\n228.0\n0.0\n932.0\n594.0\n365\n38.995384\n\n\n56\n475.0\n0.0\n0.0\n228.0\n0.0\n932.0\n594.0\n365\n41.934620\n\n\n66\n139.6\n209.4\n0.0\n192.0\n0.0\n1047.0\n806.9\n360\n44.698040\n\n\n604\n339.0\n0.0\n0.0\n197.0\n0.0\n968.0\n781.0\n365\n38.893341\n\n\n610\n236.0\n0.0\n0.0\n193.0\n0.0\n968.0\n885.0\n365\n25.083137\n\n\n616\n277.0\n0.0\n0.0\n191.0\n0.0\n968.0\n856.0\n360\n33.701587\n\n\n620\n254.0\n0.0\n0.0\n198.0\n0.0\n968.0\n863.0\n365\n29.785363\n\n\n622\n307.0\n0.0\n0.0\n193.0\n0.0\n968.0\n812.0\n365\n36.149227\n\n\n769\n331.0\n0.0\n0.0\n192.0\n0.0\n978.0\n825.0\n360\n41.244454\n\n\n792\n349.0\n0.0\n0.0\n192.0\n0.0\n1047.0\n806.0\n360\n42.126984\n\n\n814\n310.0\n0.0\n0.0\n192.0\n0.0\n970.0\n850.0\n360\n38.114233",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Dataframes and Series for Data Wrangling</span>"
    ]
  },
  {
    "objectID": "06_pandas.html#basic-statistics",
    "href": "06_pandas.html#basic-statistics",
    "title": "6  Dataframes and Series for Data Wrangling",
    "section": "6.4 Basic Statistics",
    "text": "6.4 Basic Statistics\nHaving imported the dataset into Python, the data types can be identified as follows:\n\ndata.dtypes \n\nCement                float64\nBlast Furnace Slag    float64\nFly Ash               float64\nWater                 float64\nSuperplasticizer      float64\nCoarse Aggregate      float64\nFine Aggregate        float64\nAge                     int64\nStrength              float64\ndtype: object\n\n\n\ndata.columns\n\nIndex(['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water ', 'Superplasticizer',\n       'Coarse Aggregate', 'Fine Aggregate', 'Age', 'Strength'],\n      dtype='object')\n\n\nUsing the function unique the unique data in a column can be extracted.\n\npd.unique(data['Age']) \n\narray([ 28, 270, 365, 360,  90, 180,   3,   7,  56,  91,  14, 100, 120,\n         1])\n\n\nWe often want to calculate summary statistics grouped by subsets or attributes within fields of our data.\nWe can calculate basic statistics for all records in a single column using the syntax below:\n\ndata['Strength'].describe()\n\ncount    1030.000000\nmean       35.817836\nstd        16.705679\nmin         2.331808\n25%        23.707115\n50%        34.442774\n75%        46.136287\nmax        82.599225\nName: Strength, dtype: float64\n\n\nWe can also group data by the unique values in a certain column. Let us compute the statistics for each unique age !\n\ngrouped_data = data.groupby('Age')\n\n\ngrouped_data\n\n&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x127db9c10&gt;\n\n\n\n# Summary statistics for all numeric columns by Age\ngrouped_data.describe()\n\n\n\n\n\n\n\n\nCement\nBlast Furnace Slag\n...\nFine Aggregate\nStrength\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\ncount\nmean\n...\n75%\nmax\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\nAge\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2.0\n442.500000\n81.317280\n385.0\n413.750\n442.50\n471.250\n500.0\n2.0\n0.000000\n...\n725.500\n763.0\n2.0\n9.452716\n4.504806\n6.267337\n7.860026\n9.452716\n11.045406\n12.638095\n\n\n3\n134.0\n286.577910\n105.660611\n102.0\n202.375\n254.50\n362.600\n540.0\n134.0\n65.977090\n...\n850.200\n992.6\n134.0\n18.981082\n9.862666\n2.331808\n11.884843\n15.716261\n25.092740\n41.637456\n\n\n7\n126.0\n312.923810\n104.695368\n102.0\n236.375\n317.45\n384.375\n540.0\n126.0\n92.943651\n...\n808.750\n992.6\n126.0\n26.050623\n14.583168\n7.507015\n14.553115\n21.650236\n37.650561\n59.094988\n\n\n14\n62.0\n246.174839\n81.533315\n165.0\n191.680\n226.02\n269.380\n540.0\n62.0\n18.589194\n...\n856.300\n905.9\n62.0\n28.751038\n8.638231\n12.838043\n22.371773\n26.541379\n33.615402\n59.763780\n\n\n28\n425.0\n265.443388\n104.670527\n102.0\n160.200\n261.00\n323.700\n540.0\n425.0\n86.285012\n...\n811.500\n992.6\n425.0\n36.748480\n14.711211\n8.535713\n26.227667\n33.762261\n44.388465\n81.751169\n\n\n56\n91.0\n294.168571\n100.281523\n165.0\n213.035\n252.31\n377.750\n531.3\n91.0\n55.221209\n...\n852.130\n992.6\n91.0\n51.890061\n14.308495\n23.245191\n39.427685\n51.724490\n62.694053\n80.199848\n\n\n90\n54.0\n284.140741\n113.490767\n102.0\n193.650\n288.50\n347.250\n540.0\n54.0\n88.524074\n...\n828.875\n945.0\n54.0\n40.480809\n9.818518\n21.859147\n32.971087\n39.681067\n47.765174\n69.657760\n\n\n91\n22.0\n392.263636\n57.227986\n286.3\n362.600\n384.05\n425.000\n531.3\n22.0\n148.809091\n...\n885.425\n992.6\n22.0\n69.806938\n7.697526\n56.495663\n65.196851\n67.947860\n76.474954\n82.599225\n\n\n100\n52.0\n220.900769\n43.204927\n165.0\n188.265\n213.75\n250.000\n376.0\n52.0\n22.164038\n...\n857.700\n905.9\n52.0\n47.668780\n8.401802\n33.543007\n40.822150\n46.984342\n53.717075\n66.948120\n\n\n120\n3.0\n330.000000\n19.519221\n310.0\n320.500\n331.00\n340.000\n349.0\n3.0\n0.000000\n...\n825.500\n830.0\n3.0\n39.647168\n1.103039\n38.700288\n39.041578\n39.382869\n40.120608\n40.858348\n\n\n180\n26.0\n331.334615\n100.627543\n139.6\n268.750\n326.50\n372.500\n540.0\n26.0\n49.319231\n...\n815.750\n885.0\n26.0\n41.730376\n10.929730\n24.104081\n34.928682\n40.905232\n48.254702\n71.622767\n\n\n270\n13.0\n376.884615\n112.197214\n190.0\n304.000\n380.00\n475.000\n540.0\n13.0\n72.346154\n...\n670.000\n670.0\n13.0\n51.272511\n10.644666\n38.407950\n42.131120\n51.732763\n55.064311\n74.166933\n\n\n360\n6.0\n267.533333\n82.069012\n139.6\n218.200\n293.50\n325.750\n349.0\n6.0\n56.966667\n...\n843.875\n856.0\n6.0\n40.696895\n4.169238\n33.701587\n38.896789\n41.685719\n43.753802\n44.698040\n\n\n365\n14.0\n319.321429\n79.534851\n190.0\n257.000\n319.75\n370.500\n475.0\n14.0\n67.178571\n...\n753.250\n885.0\n14.0\n43.557843\n9.620127\n25.083137\n38.918852\n42.816460\n52.810414\n56.141962\n\n\n\n\n14 rows × 64 columns\n\n\n\n\n# Provide the mean for each numeric column by Age\ngrouped_data.mean()\n\n\n\n\n\n\n\n\nCement\nBlast Furnace Slag\nFly Ash\nWater\nSuperplasticizer\nCoarse Aggregate\nFine Aggregate\nStrength\n\n\nAge\n\n\n\n\n\n\n\n\n\n\n\n\n1\n442.500000\n0.000000\n0.000000\n193.000000\n0.000000\n1045.500000\n688.000000\n9.452716\n\n\n3\n286.577910\n65.977090\n57.162313\n176.187388\n6.614754\n977.247239\n796.109478\n18.981082\n\n\n7\n312.923810\n92.943651\n12.642857\n183.287302\n3.751667\n983.814286\n768.103175\n26.050623\n\n\n14\n246.174839\n18.589194\n97.850806\n173.387258\n6.672048\n1023.908548\n800.114032\n28.751038\n\n\n28\n265.443388\n86.285012\n62.794706\n183.059082\n6.994605\n956.059129\n764.376635\n36.748480\n\n\n56\n294.168571\n55.221209\n85.041209\n167.446264\n9.853593\n979.634396\n798.487582\n51.890061\n\n\n90\n284.140741\n88.524074\n0.000000\n200.768519\n0.000000\n966.137037\n758.662963\n40.480809\n\n\n91\n392.263636\n148.809091\n0.000000\n157.763636\n15.154545\n918.940909\n802.336364\n69.806938\n\n\n100\n220.900769\n22.164038\n116.668269\n169.442500\n7.955135\n1025.294808\n809.443654\n47.668780\n\n\n120\n330.000000\n0.000000\n0.000000\n192.000000\n0.000000\n1031.000000\n820.000000\n39.647168\n\n\n180\n331.334615\n49.319231\n0.000000\n207.038462\n0.000000\n979.900000\n725.438462\n41.730376\n\n\n270\n376.884615\n72.346154\n0.000000\n218.615385\n0.000000\n976.538462\n627.615385\n51.272511\n\n\n360\n267.533333\n56.966667\n0.000000\n191.833333\n0.000000\n998.066667\n828.233333\n40.696895\n\n\n365\n319.321429\n67.178571\n0.000000\n218.642857\n0.000000\n942.285714\n690.071429\n43.557843\n\n\n\n\n\n\n\nIf we wanted to, we could perform math on an entire column of our data. A more practical use of this might be to normalize the data according to a mean, area, or some other value calculated from our data.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Dataframes and Series for Data Wrangling</span>"
    ]
  },
  {
    "objectID": "06_pandas.html#plotting",
    "href": "06_pandas.html#plotting",
    "title": "6  Dataframes and Series for Data Wrangling",
    "section": "6.5 Plotting",
    "text": "6.5 Plotting\n\n# Make sure figures appear inline in Ipython Notebook\n%matplotlib inline\n# Create a quick bar chart\ngrouped_data.mean().plot(kind='bar', title='Mean Attributes')",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Dataframes and Series for Data Wrangling</span>"
    ]
  },
  {
    "objectID": "06_pandas.html#analysis",
    "href": "06_pandas.html#analysis",
    "title": "6  Dataframes and Series for Data Wrangling",
    "section": "6.6 Analysis",
    "text": "6.6 Analysis\nGiven the full data-set, we can compute the correlation between the columns given in the dataset.\n\ncorrelation_data = data.corr(method='spearman')\n\n\n#correlation_data\n\n\nimport seaborn as sns # seaborn is an alternative to Matplotlib with additional plotting options !\n\nsns.heatmap(correlation_data)",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Dataframes and Series for Data Wrangling</span>"
    ]
  },
  {
    "objectID": "06_pandas.html#data-cleaning",
    "href": "06_pandas.html#data-cleaning",
    "title": "6  Dataframes and Series for Data Wrangling",
    "section": "6.7 Data Cleaning",
    "text": "6.7 Data Cleaning\nNot all datasets are clean due to several reasons, making data preprocessing a critical step in data analysis. Raw data often contains inconsistencies, errors, and missing values that can significantly impact the performance and accuracy of analytical models. Here are some reasons why datasets are often not clean and require preprocessing:\n\nData Collection Errors: During data collection, errors can occur due to manual entry mistakes, sensor malfunctions, or software bugs. These errors introduce inaccuracies and noise into the dataset.\nMissing Values: Datasets frequently have missing values caused by incomplete data collection, errors in data storage, or non-responses in surveys. Handling these missing values is essential to ensure the dataset’s integrity.\nInconsistent Data Formats: Data collected from multiple sources may have varying formats, units, or scales. For example, dates might be recorded in different formats, or measurements could be in different units (e.g., meters vs. feet), necessitating standardization.\nOutliers and Anomalies: Outliers can skew the results of data analysis and modeling. These extreme values may arise from measurement errors or genuine variations in the data, and identifying and handling them appropriately is crucial.\nDuplicate Records: Duplicates can occur due to errors in data entry or merging multiple datasets. They inflate the dataset and can lead to biased or incorrect conclusions.\nNoise and Irrelevant Data: Raw data often contains noise and irrelevant information that can obscure meaningful patterns. Filtering out this noise is necessary to enhance the signal-to-noise ratio in the dataset.\nData Imbalance: In classification problems, imbalanced datasets, where some classes are underrepresented, can lead to biased models that perform poorly on minority classes. Preprocessing steps such as resampling or generating synthetic data can help address this issue.\nInconsistent Data Entry: Human-entered data may have inconsistencies in spelling, abbreviations, or terminology. For instance, the same category might be labeled differently (e.g., “NYC” vs. “New York City”), requiring normalization.\nComplex Data Structures: Datasets with nested or hierarchical structures, such as JSON or XML files, require flattening or transformation into a tabular format for analysis.\n\nPreprocessing transforms raw data into a clean and usable format, addressing these issues through techniques such as data cleaning, normalization, transformation, and augmentation. This step is vital to ensure the quality and reliability of the subsequent data analysis or machine learning models, ultimately leading to more accurate and actionable insights.\nSome of the important functions used for data cleaning using pandas are:\ndropna(): This function is used to remove missing or null values from a DataFrame.\n\nfillna(): This function is used to fill missing or null values in a DataFrame with a specified value or method.\n\nreplace(): This function is used to replace a specific value in a DataFrame with another value.\n\nduplicated(): This function is used to check for and remove duplicated rows in a DataFrame.\n\ndrop_duplicates(): This function is used to remove duplicated rows from a DataFrame.\n\nastype(): This function is used to convert the data type of a column in a DataFrame to another data type.\n\nstr.strip(): This function is used to remove leading and trailing whitespace from strings in a DataFrame.\n\nstr.lower(): This function is used to convert all strings in a DataFrame to lowercase.\n\nstr.upper(): This function is used to convert all strings in a DataFrame to uppercase.\n\nrename(): This function is used to rename columns or indexes in a DataFrame.\nThe further options to clean data is discussed in this short subsection !\n\nimport pandas as pd\nimport numpy as np\n\n# create a sample DataFrame\ndf = pd.DataFrame({'property': [100, 222, np.nan, 500, 500], \n                   'info 1': [' velocity', 'distance   ', 'temperature ', 'weight', 'weight '],\n                   'info 2': ['M/S', 'm', np.nan, 'KG', 'KG']})\n\nprint(df)\n\n   property        info 1 info 2\n0     100.0      velocity    M/S\n1     222.0   distance         m\n2       NaN  temperature     NaN\n3     500.0        weight     KG\n4     500.0       weight      KG\n\n\nThe next step is to clean the data by removing missing values:\n\n# remove missing values\ndf = df.dropna()\nprint(df)\n\n   property       info 1 info 2\n0     100.0     velocity    M/S\n1     222.0  distance         m\n3     500.0       weight     KG\n4     500.0      weight      KG\n\n\nNext we perform some basic data cleaning operations:\n\n# remove leading and trailing whitespace from strings\ndf['info 1'] = df['info 1'].str.strip()\nprint(df)\n\n# convert all strings to lowercase\ndf['info 2'] = df['info 2'].str.lower()\nprint(df)\n\n# remove duplicates\ndf = df.drop_duplicates()\nprint(df)\n\n# rename column names\ndf = df.rename(columns={'property': 'Value', 'info 1': 'Property', 'info 2': 'SI Units'})\nprint(df)\n\n   property    info 1 info 2\n0     100.0  velocity    M/S\n1     222.0  distance      m\n3     500.0    weight     KG\n4     500.0    weight     KG\n   property    info 1 info 2\n0     100.0  velocity    m/s\n1     222.0  distance      m\n3     500.0    weight     kg\n4     500.0    weight     kg\n   property    info 1 info 2\n0     100.0  velocity    m/s\n1     222.0  distance      m\n3     500.0    weight     kg\n   Value  Property SI Units\n0  100.0  velocity      m/s\n1  222.0  distance        m\n3  500.0    weight       kg\n\n\n\n6.7.1 Data import\nHowever, most of the time, we already have data that is generated by another process and we need to import this data into a DataFrame !\nHere’s a list of some commonly used functions in Pandas for reading data into a DataFrame:\nread_csv: Reads a comma-separated values (CSV) file into a DataFrame. Can handle other delimiters as well.\n\nread_excel: Reads an Excel file into a DataFrame.\n\nread_json: Reads a JSON file into a DataFrame.\n\nread_sql: Reads data from a SQL query or database table into a DataFrame.\n\nread_html: Reads HTML tables into a list of DataFrame objects.\n\nread_clipboard: Reads the contents of the clipboard into a DataFrame.\n\nread_pickle: Reads a pickled object (serialized Python object) into a DataFrame.\nThese functions have various parameters to customize how data is read, such as specifying the file path or URL, specifying the delimiter or encoding, skipping rows or columns, and more. They also have several options to handle missing or malformed data.\n\n6.7.1.1 Delimiter Options:\nWhen reading data from a file, Pandas assumes that the values are separated by a comma by default. However, it provides various delimiter options to handle other separators such as tabs, semicolons, and pipes. Some of the delimiter-related options include:\ndelimiter or sep: Specifies the delimiter used in the file. For example, delimiter='\\t' or sep='|' specifies tab-separated or pipe-separated values.\n\nheader: Specifies the row number(s) to use as the column names. By default, the first row is used as the column names.\n\nskiprows: Specifies the number of rows to skip from the top of the file.\n\nusecols: Specifies which columns to include in the DataFrame. It can be a list of column indices or names.\n\n\n6.7.1.2 Encoding Options:\nData files may be encoded in various formats, such as ASCII, UTF-8, or UTF-16, and Pandas provides several encoding options to handle them. Some of the encoding-related options include:\nencoding: Specifies the encoding of the file. For example, encoding='utf-8' or encoding='latin1'.\n\nna_values: Specifies a list of values to consider as missing values. For example, na_values=['-', 'NA', 'null'].\nna_values: This parameter allows you to specify a list of values that should be treated as missing or NaN values. For example, you might have a dataset where missing values are represented by the string ‘NA’. By passing na_values=[‘NA’] to the read_csv() method, Pandas will recognize this string as a missing value and replace it with a NaN value in the resulting DataFrame.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Dataframes and Series for Data Wrangling</span>"
    ]
  },
  {
    "objectID": "06_pandas.html#exercises",
    "href": "06_pandas.html#exercises",
    "title": "6  Dataframes and Series for Data Wrangling",
    "section": "6.8 Exercises",
    "text": "6.8 Exercises\n\n6.8.1 Theory\n\nWhat is the difference between a Pandas Series and a DataFrame?\nHow do you handle missing data in Pandas?\nWhat is the purpose of the groupby() function in Pandas?\nHow do you merge two DataFrames in Pandas?\n\n\n\n6.8.2 Coding\n\nLoad the “iris” dataset from scikit-learn into a Pandas DataFrame. Then, group the data by the “species” column, and calculate the mean value of each column for each species.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Dataframes and Series for Data Wrangling</span>"
    ]
  },
  {
    "objectID": "06_pandas.html#further-reading",
    "href": "06_pandas.html#further-reading",
    "title": "6  Dataframes and Series for Data Wrangling",
    "section": "6.9 Further Reading",
    "text": "6.9 Further Reading\n\nhttps://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\nhttps://pandas.pydata.org/docs/getting_started/intro_tutorials/index.html",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Dataframes and Series for Data Wrangling</span>"
    ]
  }
]